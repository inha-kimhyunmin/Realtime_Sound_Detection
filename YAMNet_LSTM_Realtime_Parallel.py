"""
ì‹¤ì‹œê°„ ìœ„í—˜ì†Œë¦¬ ê°ì§€ ì‹œìŠ¤í…œ (ë³‘ë ¬ ì²˜ë¦¬ ë²„ì „)
================================================

ì˜¤ë””ì˜¤ ì…ë ¥ ìˆ˜ì§‘ê³¼ ëª¨ë¸ ì¶”ë¡ ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•˜ì—¬ ë” íš¨ìœ¨ì ì¸ ì‹¤ì‹œê°„ ê°ì§€ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

ì£¼ìš” íŠ¹ì§•:
- ì§€ì†ì ì¸ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ìˆ˜ì§‘ (ë³„ë„ ìŠ¤ë ˆë“œ)
- ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ ë‹¬ì„±ì‹œ ìë™ ëª¨ë¸ ì¶”ë¡  (ë³„ë„ ìŠ¤ë ˆë“œ)
- ë…¼ë¸”ë¡œí‚¹ ë°©ì‹ìœ¼ë¡œ ëŠê¹€ì—†ëŠ” ì‹¤ì‹œê°„ ì²˜ë¦¬
- ìˆœí™˜ ë²„í¼ ë°©ì‹ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ê´€ë¦¬

ì‚¬ìš©ë²•:
1. ë¨¼ì € LSTM_Train_5Class.pyë¡œ ëª¨ë¸ í›ˆë ¨
2. ìƒì„±ëœ ëª¨ë¸ íŒŒì¼ ê²½ë¡œë¥¼ MODEL_PATHì— ì„¤ì •
3. python YAMNet_LSTM_Realtime_Parallel.py ì‹¤í–‰
"""

import numpy as np
import librosa
import tensorflow as tf
import tensorflow_hub as hub
import sounddevice as sd
import threading
import queue
import time
import pickle
import os
import glob
from datetime import datetime
from collections import deque
from scipy import signal

# ================================
# ì„¤ì • íŒŒë¼ë¯¸í„°
# ================================
SAMPLE_RATE = 16000           # ìƒ˜í”Œë§ ì£¼íŒŒìˆ˜ (YAMNet ê¸°ë³¸ê°’)
SEGMENT_DURATION = 10.0       # ë¶„ì„í•  ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ (ì´ˆ)
CHUNK_DURATION = 0.5          # ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì§‘ ê°„ê²© (ì´ˆ)
DANGER_THRESHOLD = 0.7        # ìœ„í—˜ ê°ì§€ í™•ë¥  ì„ê³„ê°’
OVERLAP_RATIO = 0.5           # ì„¸ê·¸ë¨¼íŠ¸ ê°„ ê²¹ì¹¨ ë¹„ìœ¨ (0.5 = 50% ê²¹ì¹¨)

# ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (ìë™ íƒìƒ‰ ë˜ëŠ” ìˆ˜ë™ ì„¤ì •)
MODEL_PATH = None  # Noneì´ë©´ ìë™ìœ¼ë¡œ ìµœì‹  ëª¨ë¸ íƒìƒ‰
MODEL_INFO_PATH = None  # Noneì´ë©´ ìë™ìœ¼ë¡œ íƒìƒ‰

# ë§ˆì´í¬ ë° ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì„¤ì •
AUTO_CALIBRATION_MODE = True    # True: ìë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜, False: ìˆ˜ë™ ì„¤ì • ì‚¬ìš©
CALIBRATION_SILENCE_DURATION = 5.0      # ë¬´ìŒ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹œê°„ (ì´ˆ)
CALIBRATION_FACTORY_DURATION = 3.0      # ê³µì¥ì†Œë¦¬ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë…¹ìŒ ì‹œê°„ (ì´ˆ)
CALIBRATION_MAX_ATTEMPTS = 10           # ê³µì¥ì†Œë¦¬ ì¸ì‹ ìµœëŒ€ ì‹œë„ íšŸìˆ˜
CALIBRATION_MIN_GAIN = 1.0              # ìµœì†Œ ë§ˆì´í¬ ê°ë„
CALIBRATION_MAX_GAIN = 10.0             # ìµœëŒ€ ë§ˆì´í¬ ê°ë„
CALIBRATION_GAIN_STEP = 0.5             # ê°ë„ ì¦ê°€ ë‹¨ê³„

# ë§ˆì´í¬ ë° ë¬´ìŒ ê°ì§€ ì„¤ì • (ìˆ˜ë™ ëª¨ë“œìš©)
MIC_GAIN = 3.0              # ë§ˆì´í¬ ì…ë ¥ ê°ë„ (1.0 = ê¸°ë³¸, 2.0 = 2ë°° ì¦í­)
SILENCE_RMS_THRESHOLD = 0.005   # ë¬´ìŒ íŒë‹¨ RMS ì„ê³„ê°’ (ë‚®ì„ìˆ˜ë¡ ë” ì‘ì€ ì†Œë¦¬ë„ ê°ì§€)
SILENCE_MAX_THRESHOLD = 0.01    # ë¬´ìŒ íŒë‹¨ ìµœëŒ€ê°’ ì„ê³„ê°’

# ë¬´ìŒ ì²˜ë¦¬ ëª¨ë“œ ì„¤ì •
SILENCE_PROCESSING_MODE = True  # True: ì‘ì€ ì†Œë¦¬ë¥¼ ë¬´ìŒìœ¼ë¡œ ê°•ì œ ì²˜ë¦¬, False: ë¹„í™œì„±í™”
SILENCE_FORCE_RMS_THRESHOLD = 0.02  # ì´ ê°’ë³´ë‹¤ ì‘ìœ¼ë©´ ë¬´ìŒìœ¼ë¡œ ê°•ì œ ë¶„ë¥˜ (ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹œ ë™ì  ë³€ê²½ë¨)
SILENCE_FORCE_MAX_THRESHOLD = 0.05  # ì´ ê°’ë³´ë‹¤ ì‘ìœ¼ë©´ ë¬´ìŒìœ¼ë¡œ ê°•ì œ ë¶„ë¥˜ (ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹œ ë™ì  ë³€ê²½ë¨)

# ê³µì¥ ì†Œë¦¬ ê¸°ì¤€ ë¬´ìŒ ì²˜ë¦¬ ì„¤ì •
FACTORY_BASED_SILENCE_MODE = True   # True: ê³µì¥ ì†Œë¦¬ í¬ê¸° ê¸°ì¤€ ë¬´ìŒ ì²˜ë¦¬, False: ë¹„í™œì„±í™”
FACTORY_SILENCE_RATIO = 0.5         # ê³µì¥ ì†Œë¦¬ì˜ ëª‡ % ì´í•˜ë¥¼ ë¬´ìŒìœ¼ë¡œ ì²˜ë¦¬í• ì§€ (0.5 = 50%)
FACTORY_SILENCE_RMS_THRESHOLD = 0.0 # ê³µì¥ ì†Œë¦¬ RMS ê¸°ì¤€ê°’ (ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹œ ë™ì  ì„¤ì •ë¨)
FACTORY_SILENCE_MAX_THRESHOLD = 0.0 # ê³µì¥ ì†Œë¦¬ Max ê¸°ì¤€ê°’ (ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹œ ë™ì  ì„¤ì •ë¨)

# í´ë˜ìŠ¤ ì •ë³´
CLASS_NAMES = ['ë¬´ìŒ', 'ì •ìƒ(ê³µì¥)', 'í™”ì¬', 'ê°€ìŠ¤ëˆ„ì¶œ', 'ë¹„ëª…']
DANGER_CLASSES = [2, 3, 4]  # í™”ì¬, ê°€ìŠ¤ëˆ„ì¶œ, ë¹„ëª…
CLASS_COLORS = {
    0: 'ğŸ”‡',  # ë¬´ìŒ
    1: 'ğŸŸ¢',  # ì •ìƒ(ê³µì¥)
    2: 'ğŸ”¥',  # í™”ì¬
    3: 'âš ï¸',  # ê°€ìŠ¤ëˆ„ì¶œ
    4: 'ğŸ˜±'   # ë¹„ëª…
}

class RealTimeAudioDetector:
    def __init__(self):
        """ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ê°ì§€ê¸° ì´ˆê¸°í™”"""
        self.sample_rate = SAMPLE_RATE
        self.segment_length = int(SAMPLE_RATE * SEGMENT_DURATION)
        self.chunk_length = int(SAMPLE_RATE * CHUNK_DURATION)
        self.overlap_length = int(self.segment_length * OVERLAP_RATIO)
        self.step_length = self.segment_length - self.overlap_length
        
        # ì˜¤ë””ì˜¤ ë²„í¼ (ìˆœí™˜ í ë°©ì‹)
        self.audio_buffer = deque(maxlen=int(SAMPLE_RATE * SEGMENT_DURATION * 2))  # 2ë°° ë²„í¼
        self.buffer_lock = threading.Lock()
        
        # ëª¨ë¸ ì¶”ë¡  í
        self.inference_queue = queue.Queue(maxsize=5)  # ìµœëŒ€ 5ê°œ ì„¸ê·¸ë¨¼íŠ¸ ëŒ€ê¸°
        
        # ì œì–´ í”Œë˜ê·¸
        self.is_running = False
        self.audio_thread = None
        self.inference_thread = None
        
        # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê²°ê³¼ ì €ì¥
        self.calibration_results = None
        self.current_mic_gain = MIC_GAIN
        self.current_silence_rms_threshold = SILENCE_RMS_THRESHOLD
        self.current_silence_max_threshold = SILENCE_MAX_THRESHOLD
        self.current_force_rms_threshold = SILENCE_FORCE_RMS_THRESHOLD
        self.current_force_max_threshold = SILENCE_FORCE_MAX_THRESHOLD
        self.current_factory_rms_threshold = FACTORY_SILENCE_RMS_THRESHOLD
        self.current_factory_max_threshold = FACTORY_SILENCE_MAX_THRESHOLD
        
        # ëª¨ë¸ ë° YAMNet ë¡œë“œ
        self.load_models()
        
        # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìˆ˜í–‰
        self.perform_calibration()
        
        print("ğŸ§ ì‹¤ì‹œê°„ ìœ„í—˜ì†Œë¦¬ ê°ì§€ ì‹œìŠ¤í…œ (ë³‘ë ¬ ì²˜ë¦¬ ë²„ì „)")
        print(f"ğŸ“ ëª¨ë¸: {self.model_path}")
        print(f"ğŸ¯ í´ë˜ìŠ¤: {CLASS_NAMES}")
        print(f"âš™ï¸ ì„¤ì •: ì„¸ê·¸ë¨¼íŠ¸ {SEGMENT_DURATION}ì´ˆ, ì²­í¬ {CHUNK_DURATION}ì´ˆ, ê²¹ì¹¨ {OVERLAP_RATIO*100}%")
        print(f"ğŸš¨ ìœ„í—˜ ì„ê³„ê°’: {DANGER_THRESHOLD*100}%")
        print(f"ğŸ¤ ë§ˆì´í¬ ê°ë„: {self.current_mic_gain:.1f}x")
        print("-" * 60)
    
    def find_latest_model(self):
        """ê°€ì¥ ìµœì‹  ëª¨ë¸ íŒŒì¼ì„ ìë™ìœ¼ë¡œ ì°¾ê¸°"""
        model_folders = glob.glob("model_results_*")
        if not model_folders:
            raise FileNotFoundError("ëª¨ë¸ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € LSTM_Train_5Class.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í›ˆë ¨í•˜ì„¸ìš”.")
        
        # ê°€ì¥ ìµœì‹  í´ë” ì„ íƒ (íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ì¤€)
        latest_folder = max(model_folders, key=lambda x: os.path.getctime(x))
        
        # ëª¨ë¸ íŒŒì¼ ì°¾ê¸°
        model_files = glob.glob(os.path.join(latest_folder, "yamnet_lstm_model_*.h5"))
        info_files = glob.glob(os.path.join(latest_folder, "model_info_*.pkl"))
        
        if not model_files:
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {latest_folder}")
        if not info_files:
            raise FileNotFoundError(f"ëª¨ë¸ ì •ë³´ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {latest_folder}")
        
        return model_files[0], info_files[0]
    
    def load_models(self):
        """ëª¨ë¸ ë° YAMNet ë¡œë“œ"""
        global MODEL_PATH, MODEL_INFO_PATH
        
        # ëª¨ë¸ ê²½ë¡œ ìë™ íƒìƒ‰ ë˜ëŠ” ìˆ˜ë™ ì„¤ì •
        if MODEL_PATH is None or MODEL_INFO_PATH is None:
            print("ğŸ” ìµœì‹  ëª¨ë¸ ìë™ íƒìƒ‰ ì¤‘...")
            MODEL_PATH, MODEL_INFO_PATH = self.find_latest_model()
        
        self.model_path = MODEL_PATH
        self.model_info_path = MODEL_INFO_PATH
        
        # LSTM ëª¨ë¸ ë¡œë“œ
        print("ğŸ§  LSTM ëª¨ë¸ ë¡œë“œ ì¤‘...")
        from tensorflow.keras.models import load_model
        self.lstm_model = load_model(self.model_path)
        print(f"âœ… LSTM ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {os.path.basename(self.model_path)}")
        
        # ëª¨ë¸ ì •ë³´ ë¡œë“œ
        with open(self.model_info_path, 'rb') as f:
            self.model_info = pickle.load(f)
        
        # YAMNet ëª¨ë¸ ë¡œë“œ
        print("ğŸµ YAMNet ëª¨ë¸ ë¡œë“œ ì¤‘...")
        yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'
        self.yamnet_model = hub.load(yamnet_model_handle)
        print("âœ… YAMNet ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    def extract_yamnet_embeddings(self, audio):
        """YAMNet ì„ë² ë”© ì¶”ì¶œ"""
        try:
            # ì˜¤ë””ì˜¤ë¥¼ í…ì„œë¡œ ë³€í™˜
            waveform = tf.convert_to_tensor(audio, dtype=tf.float32)
            waveform = tf.squeeze(waveform)
            
            # YAMNet ì¶”ë¡ 
            yamnet_fn = self.yamnet_model.signatures['serving_default']
            yamnet_output = yamnet_fn(waveform=waveform)
            embeddings = yamnet_output['output_1'].numpy()  # (frames, 1024)
            
            return embeddings
        except Exception as e:
            print(f"âš ï¸ YAMNet ì„ë² ë”© ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return None
    
    def get_audio_volume(self, audio):
        """ì˜¤ë””ì˜¤ì˜ RMS ë³¼ë¥¨ê³¼ ìµœëŒ€ ì ˆëŒ“ê°’ ê³„ì‚°"""
        rms = np.sqrt(np.mean(audio**2))
        max_val = np.max(np.abs(audio))
        return rms, max_val
    
    def detect_clipping(self, audio, threshold=0.95):
        """ì˜¤ë””ì˜¤ í´ë¦¬í•‘ ê°ì§€"""
        clipped_samples = np.sum(np.abs(audio) >= threshold)
        clipping_ratio = clipped_samples / len(audio)
        return clipping_ratio > 0.01  # 1% ì´ìƒ í´ë¦¬í•‘ë˜ë©´ True
    
    def apply_compressor(self, audio, threshold=0.7, ratio=4.0, attack=0.003, release=0.1, sample_rate=16000):
        """ê°„ë‹¨í•œ ì»´í”„ë ˆì„œ ì ìš© (ê³¼ë„í•œ ë³¼ë¥¨ ì œì–´)"""
        # ê°„ë‹¨í•œ í”¼í¬ ì œí•œ ì»´í”„ë ˆì„œ
        compressed = audio.copy()
        
        # ì„ê³„ê°’ì„ ë„˜ëŠ” ë¶€ë¶„ì„ ì••ì¶•
        mask = np.abs(audio) > threshold
        if np.any(mask):
            # ì••ì¶• ë¹„ìœ¨ ì ìš©
            compressed[mask] = np.sign(audio[mask]) * (
                threshold + (np.abs(audio[mask]) - threshold) / ratio
            )
        
        return compressed
    
    def normalize_audio_adaptive(self, audio, target_rms=0.1, max_gain=3.0):
        """ì ì‘í˜• ì˜¤ë””ì˜¤ ì •ê·œí™”"""
        current_rms = np.sqrt(np.mean(audio**2))
        
        if current_rms < 1e-6:  # ê±°ì˜ ë¬´ìŒì¸ ê²½ìš°
            return audio
        
        # ëª©í‘œ RMSì— ë§ì¶° ê²Œì¸ ê³„ì‚°
        gain = target_rms / current_rms
        
        # ìµœëŒ€ ê²Œì¸ ì œí•œ
        gain = min(gain, max_gain)
        
        normalized = audio * gain
        
        # ìµœì¢… í´ë¦¬í•‘ ë°©ì§€
        max_val = np.max(np.abs(normalized))
        if max_val > 0.95:
            normalized = normalized * (0.95 / max_val)
        
        return normalized
    
    def preprocess_audio(self, audio, sample_rate=16000):
        """í†µí•© ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ í•¨ìˆ˜"""
        original_rms, original_max = self.get_audio_volume(audio)
        
        # 1. í´ë¦¬í•‘ ê°ì§€
        is_clipped = self.detect_clipping(audio)
        
        # 2. ì»´í”„ë ˆì„œ ì ìš© (ê³¼ë„í•œ ë³¼ë¥¨ ì œì–´)
        if original_max > 0.8 or is_clipped:
            audio = self.apply_compressor(audio, threshold=0.6, ratio=6.0)
        
        # 3. ì ì‘í˜• ì •ê·œí™”
        if original_rms > 0.001:  # ë¬´ìŒì´ ì•„ë‹Œ ê²½ìš°ë§Œ
            # ë³¼ë¥¨ì´ ë§¤ìš° ë†’ì€ ê²½ìš° ë” ë³´ìˆ˜ì ìœ¼ë¡œ ì •ê·œí™”
            if original_rms > 0.3:
                target_rms = 0.05
                max_gain = 1.5
            else:
                target_rms = 0.1
                max_gain = 3.0
                
            audio = self.normalize_audio_adaptive(audio, target_rms, max_gain)
        
        # 4. ìµœì¢… ì•ˆì „ì¥ì¹˜ (í•˜ë“œ ë¦¬ë¯¸í„°)
        audio = np.clip(audio, -0.95, 0.95)
        
        # ì „ì²˜ë¦¬ ì •ë³´ ë°˜í™˜
        processed_rms, processed_max = self.get_audio_volume(audio)
        preprocessing_info = {
            'original_rms': original_rms,
            'original_max': original_max,
            'processed_rms': processed_rms,
            'processed_max': processed_max,
            'was_clipped': is_clipped,
            'volume_reduced': original_rms > processed_rms * 1.5
        }
        
        return audio, preprocessing_info
    
    def is_silence(self, audio, rms_threshold=None, max_threshold=None):
        """ì˜¤ë””ì˜¤ê°€ ë¬´ìŒì¸ì§€ íŒë‹¨"""
        if rms_threshold is None:
            rms_threshold = self.current_silence_rms_threshold
        if max_threshold is None:
            max_threshold = self.current_silence_max_threshold
            
        rms, max_val = self.get_audio_volume(audio)
        return rms < rms_threshold and max_val < max_threshold
    
    def perform_calibration(self):
        """ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìˆ˜í–‰"""
        if AUTO_CALIBRATION_MODE:
            print("ğŸ”§ ìë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ëª¨ë“œ")
            self.calibration_results = self.calibrate_microphone()
            
            if self.calibration_results and self.calibration_results['factory_detected']:
                # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì„±ê³µ ì‹œ ì„¤ì •ê°’ ì—…ë°ì´íŠ¸
                self.current_mic_gain = self.calibration_results['optimal_gain']
                self.current_silence_rms_threshold = self.calibration_results['dynamic_silence_rms_threshold']
                self.current_silence_max_threshold = self.calibration_results['dynamic_silence_max_threshold']
                self.current_force_rms_threshold = self.calibration_results['force_silence_rms_threshold']
                self.current_force_max_threshold = self.calibration_results['force_silence_max_threshold']
                self.current_factory_rms_threshold = self.calibration_results['factory_rms_threshold']
                self.current_factory_max_threshold = self.calibration_results['factory_max_threshold']
            else:
                print("âš ï¸ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹¤íŒ¨, ê¸°ë³¸ ì„¤ì •ê°’ ì‚¬ìš©")
        else:
            print("âš™ï¸ ìˆ˜ë™ ì„¤ì • ëª¨ë“œ")
            self.current_mic_gain = MIC_GAIN
            self.current_silence_rms_threshold = SILENCE_RMS_THRESHOLD
            self.current_silence_max_threshold = SILENCE_MAX_THRESHOLD
            self.current_force_rms_threshold = SILENCE_FORCE_RMS_THRESHOLD
            self.current_force_max_threshold = SILENCE_FORCE_MAX_THRESHOLD
            self.current_factory_rms_threshold = FACTORY_SILENCE_RMS_THRESHOLD
            self.current_factory_max_threshold = FACTORY_SILENCE_MAX_THRESHOLD
    
    def calibrate_microphone(self):
        """ë§ˆì´í¬ ìë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìˆ˜í–‰"""
        print("ğŸ”§ ë§ˆì´í¬ ìë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹œì‘")
        print("=" * 50)
        
        # 1ë‹¨ê³„: ê³µì¥ ì†Œë¦¬ ê°ì§€ ìº˜ë¦¬ë¸Œë ˆì´ì…˜
        print(f"ğŸ“ 1ë‹¨ê³„: ê³µì¥ ì†Œë¦¬ ê°ì§€ ìº˜ë¦¬ë¸Œë ˆì´ì…˜")
        print("ğŸ’¡ ì •ìƒì ì¸ ê³µì¥ ì†Œë¦¬(ê¸°ê³„ ì†ŒìŒ)ë¥¼ ë‚´ì£¼ì„¸ìš”...")
        print("   ì‹œìŠ¤í…œì´ ê³µì¥ ì†Œë¦¬ë¥¼ ì¸ì‹í•  ë•Œê¹Œì§€ ë§ˆì´í¬ ê°ë„ë¥¼ ìë™ ì¡°ì •í•©ë‹ˆë‹¤.")
        
        time.sleep(3)  # ì¤€ë¹„ ì‹œê°„
        
        optimal_gain = CALIBRATION_MIN_GAIN
        factory_detected = False
        attempt = 0
        calibration_results = {
            'optimal_gain': optimal_gain,
            'factory_detected': False,
            'attempts': 0,
            'calibration_history': []
        }
        
        while attempt < CALIBRATION_MAX_ATTEMPTS and not factory_detected:
            attempt += 1
            current_gain = CALIBRATION_MIN_GAIN + (attempt - 1) * CALIBRATION_GAIN_STEP
            
            if current_gain > CALIBRATION_MAX_GAIN:
                break
                
            print(f"\nğŸ¤ ì‹œë„ {attempt}/{CALIBRATION_MAX_ATTEMPTS} - ë§ˆì´í¬ ê°ë„: {current_gain:.1f}x")
            
            # ê³µì¥ ì†Œë¦¬ ë…¹ìŒ
            factory_audio = sd.rec(int(CALIBRATION_FACTORY_DURATION * SAMPLE_RATE), 
                                 samplerate=SAMPLE_RATE, channels=1, dtype='float32')
            sd.wait()
            factory_audio = factory_audio.flatten()
            
            # ê°ë„ ì ìš©
            factory_audio = factory_audio * current_gain
            
            # í´ë¦¬í•‘ ë°©ì§€
            max_val = np.max(np.abs(factory_audio))
            if max_val > 1.0:
                factory_audio = factory_audio / max_val
            
            # ì „ì²˜ë¦¬
            processed_audio, preprocessing_info = self.preprocess_audio(factory_audio, SAMPLE_RATE)
            
            # ì˜¤ë””ì˜¤ ë¶„ì„
            rms, max_audio = self.get_audio_volume(processed_audio)
            
            # ê¸°ë³¸ ë¬´ìŒì´ ì•„ë‹Œì§€ í™•ì¸ (ì„ì‹œ ê¸°ì¤€ê°’ ì‚¬ìš©)
            is_not_silence = not self.is_silence(processed_audio, 
                                               rms_threshold=0.005,
                                               max_threshold=0.01)
            
            attempt_result = {
                'attempt': attempt,
                'gain': current_gain,
                'rms': rms,
                'max_val': max_audio,
                'is_not_silence': is_not_silence,
                'preprocessing_info': preprocessing_info
            }
            
            print(f"   ğŸ“Š ì˜¤ë””ì˜¤ ë¶„ì„: RMS={rms:.4f}, Max={max_audio:.4f}")
            print(f"   ğŸ” ë¬´ìŒ ì—¬ë¶€: {'ì•„ë‹ˆì˜¤' if is_not_silence else 'ì˜ˆ'}")
            
            if is_not_silence:
                print(f"   âœ… ê³µì¥ ì†Œë¦¬ ì¸ì‹ë¨!")
                optimal_gain = current_gain
                factory_detected = True
                attempt_result['factory_audio_levels'] = {'rms': rms, 'max_val': max_audio}
            else:
                print(f"   âŒ ì†Œë¦¬ê°€ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤. ê°ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.")
            
            calibration_results['calibration_history'].append(attempt_result)
            
            time.sleep(1)  # ë‹¤ìŒ ì‹œë„ ì „ ì ì‹œ ëŒ€ê¸°
        
        calibration_results['attempts'] = attempt
        calibration_results['factory_detected'] = factory_detected
        calibration_results['optimal_gain'] = optimal_gain
        
        if not factory_detected:
            print(f"\nâŒ 1ë‹¨ê³„ ì‹¤íŒ¨: ê³µì¥ ì†Œë¦¬ë¥¼ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return calibration_results
        
        # 2ë‹¨ê³„: ìµœì  ê°ë„ë¡œ ë¬´ìŒ ìƒíƒœ ì¸¡ì •
        print(f"\nğŸ“ 2ë‹¨ê³„: ë¬´ìŒ ìƒíƒœ ì¸¡ì • (ê°ë„: {optimal_gain:.1f}x, {CALIBRATION_SILENCE_DURATION}ì´ˆ)")
        print("ğŸ’¡ ì´ì œ ê³µì¥ ì†Œë¦¬ë¥¼ ì™„ì „íˆ ë„ê³  ì£¼ë³€ì„ ìµœëŒ€í•œ ì¡°ìš©í•˜ê²Œ ìœ ì§€í•´ì£¼ì„¸ìš”...")
        
        # ê³µì¥ ì†Œë¦¬ë¥¼ ëŒ ì‹œê°„ì„ ì¶©ë¶„íˆ ì œê³µ
        for i in range(5, 0, -1):
            print(f"   {i}ì´ˆ í›„ ë¬´ìŒ ì¸¡ì •ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            time.sleep(1)
        
        print("ğŸ”‡ ë¬´ìŒ ì¸¡ì •ì„ ì‹œì‘í•©ë‹ˆë‹¤!")
        
        # ìµœì  ê°ë„ë¡œ ë¬´ìŒ ë…¹ìŒ
        silence_audio = sd.rec(int(CALIBRATION_SILENCE_DURATION * SAMPLE_RATE), 
                              samplerate=SAMPLE_RATE, channels=1, dtype='float32')
        sd.wait()
        silence_audio = silence_audio.flatten()
        
        # ìµœì  ê°ë„ ì ìš©
        silence_audio = silence_audio * optimal_gain
        
        # í´ë¦¬í•‘ ë°©ì§€
        max_val = np.max(np.abs(silence_audio))
        if max_val > 1.0:
            silence_audio = silence_audio / max_val
        
        # ì „ì²˜ë¦¬
        processed_silence, _ = self.preprocess_audio(silence_audio, SAMPLE_RATE)
        
        # ë¬´ìŒ ê¸°ì¤€ê°’ ê³„ì‚°
        silence_rms = np.sqrt(np.mean(processed_silence**2))
        silence_max = np.max(np.abs(processed_silence))
        
        print(f"âœ… ë¬´ìŒ ê¸°ì¤€ê°’ ì¸¡ì • ì™„ë£Œ:")
        print(f"   - RMS: {silence_rms:.6f}")
        print(f"   - Max: {silence_max:.6f}")
        
        # ë™ì  ì„ê³„ê°’ ê³„ì‚°
        dynamic_silence_rms = silence_rms * 2.0  # ë¬´ìŒ ê¸°ì¤€ì˜ 2ë°°
        dynamic_silence_max = silence_max * 2.0
        
        # ë¬´ìŒ ì²˜ë¦¬ ëª¨ë“œìš© ê°•ì œ ì„ê³„ê°’ ê³„ì‚° (ë¬´ìŒ ê¸°ì¤€ì˜ 3~4ë°°)
        force_silence_rms = silence_rms * 3.0
        force_silence_max = silence_max * 4.0
        
        # ê³µì¥ ì†Œë¦¬ ê¸°ì¤€ ë¬´ìŒ ì²˜ë¦¬ ì„ê³„ê°’ ê³„ì‚°
        factory_audio_levels = None
        for result in calibration_results['calibration_history']:
            if result.get('factory_audio_levels'):
                factory_audio_levels = result['factory_audio_levels']
                break
        
        if factory_audio_levels:
            factory_rms_threshold = factory_audio_levels['rms'] * FACTORY_SILENCE_RATIO
            factory_max_threshold = factory_audio_levels['max_val'] * FACTORY_SILENCE_RATIO
        else:
            factory_rms_threshold = dynamic_silence_rms
            factory_max_threshold = dynamic_silence_max
        
        calibration_results.update({
            'silence_rms': silence_rms,
            'silence_max': silence_max,
            'dynamic_silence_rms_threshold': dynamic_silence_rms,
            'dynamic_silence_max_threshold': dynamic_silence_max, 
            'force_silence_rms_threshold': force_silence_rms,
            'force_silence_max_threshold': force_silence_max,
            'factory_rms_threshold': factory_rms_threshold,
            'factory_max_threshold': factory_max_threshold,
            'factory_audio_levels': factory_audio_levels
        })
        
        print(f"\nğŸ‰ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ!")
        print("=" * 50)
        print(f"âœ… ì„±ê³µ: ìµœì  ë§ˆì´í¬ ê°ë„ = {optimal_gain:.1f}x")
        print(f"ğŸ“Š ë¬´ìŒ ê¸°ì¤€ê°’: RMS={silence_rms:.6f}, Max={silence_max:.6f}")
        
        return calibration_results
    
    def audio_callback(self, indata, frames, time_info, status):
        """ì˜¤ë””ì˜¤ ì…ë ¥ ì½œë°± í•¨ìˆ˜ (ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰)"""
        if status:
            print(f"âš ï¸ ì˜¤ë””ì˜¤ ìƒíƒœ: {status}")
        
        # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ë²„í¼ì— ì¶”ê°€
        audio_chunk = indata[:, 0]  # ëª¨ë…¸ë¡œ ë³€í™˜
        
        # ë§ˆì´í¬ ê°ë„ ì ìš©
        audio_chunk = audio_chunk * self.current_mic_gain
        
        # í´ë¦¬í•‘ ë°©ì§€
        max_val = np.max(np.abs(audio_chunk))
        if max_val > 1.0:
            audio_chunk = audio_chunk / max_val
        
        with self.buffer_lock:
            self.audio_buffer.extend(audio_chunk)
            
            # ì„¸ê·¸ë¨¼íŠ¸ê°€ ì¤€ë¹„ë˜ì—ˆëŠ”ì§€ í™•ì¸
            if len(self.audio_buffer) >= self.segment_length:
                # ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œ
                segment = np.array(list(self.audio_buffer)[-self.segment_length:])
                
                # ì¶”ë¡  íì— ì¶”ê°€ (íê°€ ê°€ë“ ì°¨ë©´ ê°€ì¥ ì˜¤ë˜ëœ ê²ƒ ì œê±°)
                try:
                    self.inference_queue.put_nowait(segment.copy())
                except queue.Full:
                    try:
                        self.inference_queue.get_nowait()  # ì˜¤ë˜ëœ ê²ƒ ì œê±°
                        self.inference_queue.put_nowait(segment.copy())  # ìƒˆë¡œìš´ ê²ƒ ì¶”ê°€
                    except queue.Empty:
                        pass
                
                # ë²„í¼ì—ì„œ step_lengthë§Œí¼ ì œê±° (ê²¹ì¹¨ êµ¬í˜„)
                for _ in range(min(self.step_length, len(self.audio_buffer))):
                    if self.audio_buffer:
                        self.audio_buffer.popleft()
    
    def inference_worker(self):
        """ëª¨ë¸ ì¶”ë¡  ì›Œì»¤ ìŠ¤ë ˆë“œ"""
        while self.is_running:
            try:
                # íì—ì„œ ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ê°€ì ¸ì˜¤ê¸° (1ì´ˆ íƒ€ì„ì•„ì›ƒ)
                segment = self.inference_queue.get(timeout=1.0)
                
                # ëª¨ë¸ ì¶”ë¡  ìˆ˜í–‰
                self.process_audio_segment(segment)
                
                # í ì‘ì—… ì™„ë£Œ í‘œì‹œ
                self.inference_queue.task_done()
                
            except queue.Empty:
                continue  # íƒ€ì„ì•„ì›ƒì‹œ ê³„ì† ì§„í–‰
            except Exception as e:
                print(f"âš ï¸ ì¶”ë¡  ì˜¤ë¥˜: {e}")
                continue
    
    def process_audio_segment(self, audio_segment):
        """ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬ ë° ìœ„í—˜ ê°ì§€"""
        try:
            start_time = time.time()
            
            # ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬
            processed_audio, preprocessing_info = self.preprocess_audio(audio_segment, self.sample_rate)
            
            # ë¨¼ì € ì‹¤ì œ ë³¼ë¥¨ ì²´í¬
            rms, max_val = self.get_audio_volume(processed_audio)
            
            # 1. ê¸°ë³¸ ë¬´ìŒ ê°ì§€
            if self.is_silence(processed_audio):
                processing_time = time.time() - start_time
                self.handle_prediction_result(
                    np.array([1.0, 0.0, 0.0, 0.0, 0.0]), processing_time, 
                    forced_class=0, force_reason="ê¸°ë³¸ ë¬´ìŒ ê°ì§€", 
                    audio_info={'rms': rms, 'max_val': max_val}
                )
                return
            
            # 2. ë¬´ìŒ ì²˜ë¦¬ ëª¨ë“œ - ì‘ì€ ì†Œë¦¬ë¥¼ ë¬´ìŒìœ¼ë¡œ ê°•ì œ ì²˜ë¦¬
            if SILENCE_PROCESSING_MODE:
                if rms < self.current_force_rms_threshold and max_val < self.current_force_max_threshold:
                    processing_time = time.time() - start_time
                    self.handle_prediction_result(
                        np.array([1.0, 0.0, 0.0, 0.0, 0.0]), processing_time,
                        forced_class=0, force_reason="ê°•ì œ ë¬´ìŒ ì²˜ë¦¬", 
                        audio_info={'rms': rms, 'max_val': max_val}
                    )
                    return
            
            # 3. ê³µì¥ ê¸°ì¤€ ë¬´ìŒ ì²˜ë¦¬ ëª¨ë“œ
            if FACTORY_BASED_SILENCE_MODE:
                if rms < self.current_factory_rms_threshold and max_val < self.current_factory_max_threshold:
                    processing_time = time.time() - start_time
                    self.handle_prediction_result(
                        np.array([1.0, 0.0, 0.0, 0.0, 0.0]), processing_time,
                        forced_class=0, force_reason="ê³µì¥ ê¸°ì¤€ ë¬´ìŒ ì²˜ë¦¬", 
                        audio_info={'rms': rms, 'max_val': max_val}
                    )
                    return
            
            # YAMNet ì„ë² ë”© ì¶”ì¶œ
            embeddings = self.extract_yamnet_embeddings(processed_audio)
            if embeddings is None:
                return
            
            # LSTM ëª¨ë¸ ì…ë ¥ í˜•íƒœë¡œ ë³€í™˜
            # íŒ¨ë”© ë˜ëŠ” ìë¥´ê¸°
            expected_frames = self.lstm_model.input_shape[1]
            if embeddings.shape[0] < expected_frames:
                # íŒ¨ë”©
                padding_needed = expected_frames - embeddings.shape[0]
                embeddings = np.pad(embeddings, ((0, padding_needed), (0, 0)), mode='constant')
            elif embeddings.shape[0] > expected_frames:
                # ìë¥´ê¸°
                embeddings = embeddings[:expected_frames]
            
            # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
            embeddings = np.expand_dims(embeddings, axis=0)  # (1, frames, 1024)
            
            # ëª¨ë¸ ì˜ˆì¸¡
            predictions = self.lstm_model.predict(embeddings, verbose=0)
            
            # í”„ë ˆì„ë³„ ì˜ˆì¸¡ì„ í‰ê· ë‚´ì–´ ì„¸ê·¸ë¨¼íŠ¸ ë ˆë²¨ ì˜ˆì¸¡ ìƒì„±
            segment_prediction = np.mean(predictions[0], axis=0)  # (num_classes,)
            
            predicted_class = np.argmax(segment_prediction)
            
            # 4. ë¬´ìŒ ì²˜ë¦¬ ëª¨ë“œ - AI ì˜ˆì¸¡ í›„ ì¶”ê°€ ê²€ì¦
            if SILENCE_PROCESSING_MODE and predicted_class >= 2:
                if rms < self.current_force_rms_threshold * 1.5 and max_val < self.current_force_max_threshold * 1.5:
                    processing_time = time.time() - start_time
                    self.handle_prediction_result(
                        np.array([1.0, 0.0, 0.0, 0.0, 0.0]), processing_time,
                        forced_class=0, force_reason="AI í›„ ê°•ì œ ë¬´ìŒ ì²˜ë¦¬", 
                        audio_info={'rms': rms, 'max_val': max_val}
                    )
                    return
            
            # 5. ê³µì¥ ê¸°ì¤€ ë¬´ìŒ ì²˜ë¦¬ ëª¨ë“œ - AI ì˜ˆì¸¡ í›„ ì¶”ê°€ ê²€ì¦
            if FACTORY_BASED_SILENCE_MODE and predicted_class >= 2:
                if rms < self.current_factory_rms_threshold * 1.2 and max_val < self.current_factory_max_threshold * 1.2:
                    processing_time = time.time() - start_time
                    self.handle_prediction_result(
                        np.array([1.0, 0.0, 0.0, 0.0, 0.0]), processing_time,
                        forced_class=0, force_reason="AI í›„ ê³µì¥ ê¸°ì¤€ ë¬´ìŒ ì²˜ë¦¬", 
                        audio_info={'rms': rms, 'max_val': max_val}
                    )
                    return
            
            # ê²°ê³¼ ì²˜ë¦¬
            processing_time = time.time() - start_time
            self.handle_prediction_result(segment_prediction, processing_time,
                                        audio_info={'rms': rms, 'max_val': max_val},
                                        preprocessing_info=preprocessing_info)
            
        except Exception as e:
            print(f"âš ï¸ ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
    
    def handle_prediction_result(self, prediction, processing_time, forced_class=None, force_reason=None, 
                               audio_info=None, preprocessing_info=None):
        """ì˜ˆì¸¡ ê²°ê³¼ ì²˜ë¦¬ ë° ì¶œë ¥"""
        current_time = datetime.now().strftime("%H:%M:%S")
        
        if forced_class is not None:
            predicted_class = forced_class
            confidence = 1.0
            class_icon = CLASS_COLORS.get(int(predicted_class), 'â“')
            
            # ê°•ì œ ë¶„ë¥˜ ì •ë³´ ì¶œë ¥
            audio_str = ""
            if audio_info:
                audio_str = f" | ğŸ”Š RMS={audio_info['rms']:.4f}, Max={audio_info['max_val']:.4f}"
            
            prob_str = " ".join([f"{p:.2f}" for p in prediction])
            print(f"ğŸ•’ {current_time} | ğŸ“Š í™•ë¥ : [{prob_str}]{audio_str} | âš¡ ì²˜ë¦¬ì‹œê°„: {processing_time:.3f}ì´ˆ")
            print(f"ğŸ”§ ê°•ì œ ë¶„ë¥˜: {class_icon} {CLASS_NAMES[predicted_class]} (ì‚¬ìœ : {force_reason})")
            
            if predicted_class == 0:  # ë¬´ìŒ
                print(f"ğŸ”‡ ë¬´ìŒ ìƒíƒœ")
        else:
            predicted_class = np.argmax(prediction)
            confidence = prediction[predicted_class]
            class_icon = CLASS_COLORS.get(int(predicted_class), 'â“')
            
            # ì˜¤ë””ì˜¤ ì •ë³´ ë¬¸ìì—´ ìƒì„±
            audio_str = ""
            if audio_info:
                audio_str = f" | ğŸ”Š RMS={audio_info['rms']:.4f}, Max={audio_info['max_val']:.4f}"
            
            # ì „ì²˜ë¦¬ ì •ë³´ ë¬¸ìì—´ ìƒì„±
            preprocess_str = ""
            if preprocessing_info:
                if preprocessing_info.get('was_clipped'):
                    preprocess_str += " | ğŸ“ í´ë¦¬í•‘ê°ì§€"
                if preprocessing_info.get('volume_reduced'):
                    preprocess_str += " | ğŸ“‰ ë³¼ë¥¨ì¡°ì •"
            
            # ê¸°ë³¸ ì •ë³´ ì¶œë ¥
            prob_str = " ".join([f"{p:.2f}" for p in prediction])
            print(f"ğŸ•’ {current_time} | ğŸ“Š í™•ë¥ : [{prob_str}]{audio_str}{preprocess_str} | âš¡ ì²˜ë¦¬ì‹œê°„: {processing_time:.3f}ì´ˆ")
            
            # ìœ„í—˜ ê°ì§€ í™•ì¸
            if predicted_class in DANGER_CLASSES and confidence >= DANGER_THRESHOLD:
                danger_type = CLASS_NAMES[predicted_class]
                print(f"ğŸš¨ ìœ„í—˜ ê°ì§€: {class_icon} {danger_type} ({confidence*100:.1f}% í™•ë¥ )")
                print("=" * 80)
            elif predicted_class == 1 and confidence >= 0.8:  # ì •ìƒ ì†Œë¦¬ë„ ë†’ì€ í™•ë¥ ì´ë©´ í‘œì‹œ
                print(f"âœ… ì •ìƒ: {class_icon} {CLASS_NAMES[predicted_class]} ({confidence*100:.1f}% í™•ë¥ )")
            elif predicted_class == 0 and confidence >= 0.9:  # ë¬´ìŒë„ ë†’ì€ í™•ë¥ ì´ë©´ í‘œì‹œ
                print(f"ğŸ”‡ ë¬´ìŒ ìƒíƒœ ({confidence*100:.1f}% í™•ë¥ )")
    
    def start_detection(self):
        """ì‹¤ì‹œê°„ ê°ì§€ ì‹œì‘"""
        if self.is_running:
            print("âš ï¸ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.")
            return
        
        self.is_running = True
        
        # ì¶”ë¡  ì›Œì»¤ ìŠ¤ë ˆë“œ ì‹œì‘
        self.inference_thread = threading.Thread(target=self.inference_worker, daemon=True)
        self.inference_thread.start()
        
        print("ğŸ¤ ì˜¤ë””ì˜¤ ì…ë ¥ ì‹œì‘...")
        print("ğŸ“¡ ì‹¤ì‹œê°„ ê°ì§€ í™œì„±í™”")
        print("ğŸ›‘ ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”")
        print("-" * 60)
        
        try:
            # ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì‹œì‘
            with sd.InputStream(
                channels=1,
                samplerate=self.sample_rate,
                blocksize=self.chunk_length,
                callback=self.audio_callback,
                dtype=np.float32
            ):
                # ë©”ì¸ ìŠ¤ë ˆë“œëŠ” ì¢…ë£Œ ì‹ í˜¸ ëŒ€ê¸°
                while self.is_running:
                    time.sleep(0.1)
                    
        except KeyboardInterrupt:
            print("\nğŸ›‘ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        except Exception as e:
            print(f"âŒ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì˜¤ë¥˜: {e}")
        finally:
            self.stop_detection()
    
    def stop_detection(self):
        """ì‹¤ì‹œê°„ ê°ì§€ ì¤‘ì§€"""
        if not self.is_running:
            return
        
        print("\nğŸ”„ ì‹œìŠ¤í…œ ì¢…ë£Œ ì¤‘...")
        self.is_running = False
        
        # ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°
        if self.inference_thread and self.inference_thread.is_alive():
            self.inference_thread.join(timeout=2.0)
        
        # í ì •ë¦¬
        while not self.inference_queue.empty():
            try:
                self.inference_queue.get_nowait()
            except queue.Empty:
                break
        
        print("âœ… ì‹œìŠ¤í…œ ì¢…ë£Œ ì™„ë£Œ")
    
    def get_system_info(self):
        """ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥"""
        mode_name = "ìë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜" if AUTO_CALIBRATION_MODE else "ìˆ˜ë™ ì„¤ì •"
        
        print("\nğŸ“‹ ì‹œìŠ¤í…œ ì •ë³´:")
        print(f"  - ìƒ˜í”Œë§ ì£¼íŒŒìˆ˜: {self.sample_rate} Hz")
        print(f"  - ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´: {SEGMENT_DURATION}ì´ˆ ({self.segment_length:,}ìƒ˜í”Œ)")
        print(f"  - ì²­í¬ ê¸¸ì´: {CHUNK_DURATION}ì´ˆ ({self.chunk_length:,}ìƒ˜í”Œ)")
        print(f"  - ê²¹ì¹¨ ë¹„ìœ¨: {OVERLAP_RATIO*100}%")
        print(f"  - ìŠ¤í… ê¸¸ì´: {self.step_length:,}ìƒ˜í”Œ")
        print(f"  - ë²„í¼ ìµœëŒ€ í¬ê¸°: {self.audio_buffer.maxlen:,}ìƒ˜í”Œ")
        print(f"  - ì¶”ë¡  í í¬ê¸°: {self.inference_queue.maxsize}")
        print(f"\nğŸ“Š ì‚¬ìš© ì¤‘ì¸ ì„¤ì •ê°’ ({mode_name}):")
        print(f"  - ë§ˆì´í¬ ê°ë„: {self.current_mic_gain:.1f}x")
        print(f"  - ë¬´ìŒ RMS ì„ê³„ê°’: {self.current_silence_rms_threshold:.6f}")
        print(f"  - ë¬´ìŒ Max ì„ê³„ê°’: {self.current_silence_max_threshold:.6f}")
        print(f"  - ë¬´ìŒ ì²˜ë¦¬ ëª¨ë“œ: {'ì¼œì§' if SILENCE_PROCESSING_MODE else 'êº¼ì§'}")
        if SILENCE_PROCESSING_MODE:
            print(f"    * ê°•ì œ ë¬´ìŒ RMS ì„ê³„ê°’: {self.current_force_rms_threshold:.6f}")
            print(f"    * ê°•ì œ ë¬´ìŒ Max ì„ê³„ê°’: {self.current_force_max_threshold:.6f}")
        print(f"  - ê³µì¥ ê¸°ì¤€ ë¬´ìŒ ì²˜ë¦¬: {'ì¼œì§' if FACTORY_BASED_SILENCE_MODE else 'êº¼ì§'}")
        if FACTORY_BASED_SILENCE_MODE:
            print(f"    * ê³µì¥ ê¸°ì¤€ RMS ì„ê³„ê°’: {self.current_factory_rms_threshold:.6f}")
            print(f"    * ê³µì¥ ê¸°ì¤€ Max ì„ê³„ê°’: {self.current_factory_max_threshold:.6f}")
            print(f"    * ê³µì¥ ì†Œë¦¬ ë¹„ìœ¨: {FACTORY_SILENCE_RATIO*100:.0f}%")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        # ê°ì§€ê¸° ì´ˆê¸°í™”
        detector = RealTimeAudioDetector()
        
        # ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥
        detector.get_system_info()
        
        # ì‹¤ì‹œê°„ ê°ì§€ ì‹œì‘
        detector.start_detection()
        
    except FileNotFoundError as e:
        print(f"âŒ íŒŒì¼ ì˜¤ë¥˜: {e}")
        print("ğŸ’¡ í•´ê²° ë°©ë²•: ë¨¼ì € LSTM_Train_5Class.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í›ˆë ¨í•˜ì„¸ìš”.")
    except Exception as e:
        print(f"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
