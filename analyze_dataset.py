"""
ë°ì´í„°ì…‹ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
====================

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” dataset_info_5class.json íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ 
í›ˆë ¨/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì— ì‚¬ìš©ëœ ì˜¤ë””ì˜¤ íŒŒì¼ë“¤ì˜ ìƒì„¸ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

import json
import os
import glob
from collections import Counter, defaultdict

def load_dataset_info(filename=None, version=None, folder=None):
    """
    ë°ì´í„°ì…‹ ì •ë³´ íŒŒì¼ ë¡œë“œ
    
    Args:
        filename: ì§ì ‘ íŒŒì¼ëª… ì§€ì • (ìš°ì„ ìˆœìœ„ 1)
        version: ë²„ì „ë³„ ìžë™ íŒŒì¼ëª… ìƒì„± (ìš°ì„ ìˆœìœ„ 2)
        folder: íŠ¹ì • í´ë”ì—ì„œ ê²€ìƒ‰ (ìš°ì„ ìˆœìœ„ 3)
    """
    # 1. ì§ì ‘ íŒŒì¼ëª…ì´ ì§€ì •ëœ ê²½ìš°
    if filename:
        if os.path.exists(filename):
            with open(filename, 'r', encoding='utf-8') as f:
                return json.load(f), filename
        else:
            print(f"âŒ {filename} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None, None
    
    # 2. ë²„ì „ì´ ì§€ì •ëœ ê²½ìš° - ìµœì‹  ê²°ê³¼ë¬¼ í´ë”ì—ì„œ ê²€ìƒ‰
    if version:
        pattern = f"model_results_{version}_*"
        matching_folders = glob.glob(pattern)
        if matching_folders:
            # ê°€ìž¥ ìµœì‹  í´ë” ì„ íƒ (íƒ€ìž„ìŠ¤íƒ¬í”„ ê¸°ì¤€)
            latest_folder = sorted(matching_folders)[-1]
            dataset_file = os.path.join(latest_folder, f'dataset_info_{version}.json')
            if os.path.exists(dataset_file):
                with open(dataset_file, 'r', encoding='utf-8') as f:
                    return json.load(f), dataset_file
            else:
                print(f"âŒ {dataset_file} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            print(f"âŒ ë²„ì „ {version}ì— í•´ë‹¹í•˜ëŠ” ê²°ê³¼ë¬¼ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # 3. íŠ¹ì • í´ë”ê°€ ì§€ì •ëœ ê²½ìš°
    if folder:
        json_files = glob.glob(os.path.join(folder, "dataset_info_*.json"))
        if json_files:
            dataset_file = json_files[0]  # ì²« ë²ˆì§¸ íŒŒì¼ ì‚¬ìš©
            with open(dataset_file, 'r', encoding='utf-8') as f:
                return json.load(f), dataset_file
        else:
            print(f"âŒ {folder} í´ë”ì—ì„œ dataset_info íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # 4. ê¸°ë³¸ê°’: í˜„ìž¬ ë””ë ‰í† ë¦¬ì—ì„œ ê²€ìƒ‰
    default_files = ['dataset_info_5class.json']  # ì´ì „ ë²„ì „ í˜¸í™˜ì„±
    json_files = glob.glob("dataset_info_*.json")
    all_files = default_files + json_files
    
    for file in all_files:
        if os.path.exists(file):
            with open(file, 'r', encoding='utf-8') as f:
                return json.load(f), file
    
    print("âŒ ë°ì´í„°ì…‹ ì •ë³´ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜:")
    print("  - analyze_dataset.py --version v1.0")
    print("  - analyze_dataset.py --folder model_results_v1.0_20250808_123456")
    print("  - analyze_dataset.py --file dataset_info_v1.0.json")
    return None, None

def analyze_dataset_distribution(dataset_info):
    """ë°ì´í„°ì…‹ ë¶„í¬ ë¶„ì„"""
    class_names = ['ë¬´ìŒ', 'ì •ìƒ(ê³µìž¥)', 'í™”ìž¬', 'ê°€ìŠ¤ëˆ„ì¶œ', 'ë¹„ëª…']
    
    print("=" * 60)
    print("ðŸ“Š ë°ì´í„°ì…‹ ë¶„í¬ ë¶„ì„")
    print("=" * 60)
    
    for dataset_type in ['train', 'validation', 'test']:
        data = dataset_info[dataset_type]
        print(f"\nðŸ” {dataset_type.upper()} ë°ì´í„°ì…‹ ({len(data)}ê°œ ìƒ˜í”Œ)")
        print("-" * 40)
        
        # í´ëž˜ìŠ¤ë³„ ê°œìˆ˜
        class_counts = Counter([item['class_id'] for item in data])
        total = len(data)
        
        for class_id in range(5):
            count = class_counts.get(class_id, 0)
            percentage = (count / total * 100) if total > 0 else 0
            print(f"  {class_names[class_id]}: {count}ê°œ ({percentage:.1f}%)")

def analyze_audio_files(dataset_info):
    """ì‚¬ìš©ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„ì„"""
    print("\n" + "=" * 60)
    print("ðŸŽµ ì‚¬ìš©ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„ì„")
    print("=" * 60)
    
    for dataset_type in ['train', 'validation', 'test']:
        data = dataset_info[dataset_type]
        print(f"\nðŸ“ {dataset_type.upper()} ë°ì´í„°ì…‹")
        print("-" * 40)
        
        # ê³µìž¥ ì†Œë¦¬ íŒŒì¼ ë¶„ì„
        factory_files = [item['factory_file'] for item in data if item['factory_file']]
        factory_counts = Counter(factory_files)
        
        print(f"ðŸ­ ê³µìž¥ ì†Œë¦¬ íŒŒì¼ ({len(factory_counts)}ê°œ ê³ ìœ  íŒŒì¼):")
        for filename, count in factory_counts.most_common(5):
            print(f"  {filename}: {count}ë²ˆ ì‚¬ìš©")
        if len(factory_counts) > 5:
            print(f"  ... ê·¸ ì™¸ {len(factory_counts) - 5}ê°œ íŒŒì¼")
        
        # ìœ„í—˜ ì†Œë¦¬ íŒŒì¼ ë¶„ì„
        event_files = [item['event_file'] for item in data if item['event_file']]
        event_counts = Counter(event_files)
        
        print(f"\nâš ï¸ ìœ„í—˜ ì†Œë¦¬ íŒŒì¼ ({len(event_counts)}ê°œ ê³ ìœ  íŒŒì¼):")
        for filename, count in event_counts.most_common(5):
            print(f"  {filename}: {count}ë²ˆ ì‚¬ìš©")
        if len(event_counts) > 5:
            print(f"  ... ê·¸ ì™¸ {len(event_counts) - 5}ê°œ íŒŒì¼")
        
        # í´ëž˜ìŠ¤ë³„ ìœ„í—˜ ì†Œë¦¬ íŒŒì¼
        class_event_files = defaultdict(list)
        for item in data:
            if item['event_file'] and item['class'] != 'normal':
                class_event_files[item['class']].append(item['event_file'])
        
        print(f"\nðŸ“‹ í´ëž˜ìŠ¤ë³„ ìœ„í—˜ ì†Œë¦¬ íŒŒì¼:")
        for class_name, files in class_event_files.items():
            unique_files = len(set(files))
            total_usage = len(files)
            print(f"  {class_name}: {unique_files}ê°œ ê³ ìœ  íŒŒì¼ (ì´ {total_usage}ë²ˆ ì‚¬ìš©)")

def analyze_data_overlap(dataset_info):
    """ë°ì´í„°ì…‹ ê°„ íŒŒì¼ ì¤‘ë³µ ë¶„ì„"""
    print("\n" + "=" * 60)
    print("ðŸ”„ ë°ì´í„°ì…‹ ê°„ íŒŒì¼ ì¤‘ë³µ ë¶„ì„")
    print("=" * 60)
    
    # ê° ë°ì´í„°ì…‹ì—ì„œ ì‚¬ìš©ëœ íŒŒì¼ë“¤ ìˆ˜ì§‘
    datasets = {}
    for dataset_type in ['train', 'validation', 'test']:
        data = dataset_info[dataset_type]
        factory_files = set([item['factory_file'] for item in data if item['factory_file']])
        event_files = set([item['event_file'] for item in data if item['event_file']])
        datasets[dataset_type] = {
            'factory': factory_files,
            'event': event_files
        }
    
    # ì¤‘ë³µ ê²€ì‚¬
    print("ðŸ­ ê³µìž¥ ì†Œë¦¬ íŒŒì¼ ì¤‘ë³µ:")
    train_factory = datasets['train']['factory']
    val_factory = datasets['validation']['factory']
    test_factory = datasets['test']['factory']
    
    print(f"  í›ˆë ¨-ê²€ì¦ ì¤‘ë³µ: {len(train_factory & val_factory)}ê°œ")
    print(f"  í›ˆë ¨-í…ŒìŠ¤íŠ¸ ì¤‘ë³µ: {len(train_factory & test_factory)}ê°œ")
    print(f"  ê²€ì¦-í…ŒìŠ¤íŠ¸ ì¤‘ë³µ: {len(val_factory & test_factory)}ê°œ")
    
    print("\nâš ï¸ ìœ„í—˜ ì†Œë¦¬ íŒŒì¼ ì¤‘ë³µ:")
    train_event = datasets['train']['event']
    val_event = datasets['validation']['event']
    test_event = datasets['test']['event']
    
    print(f"  í›ˆë ¨-ê²€ì¦ ì¤‘ë³µ: {len(train_event & val_event)}ê°œ")
    print(f"  í›ˆë ¨-í…ŒìŠ¤íŠ¸ ì¤‘ë³µ: {len(train_event & test_event)}ê°œ")
    print(f"  ê²€ì¦-í…ŒìŠ¤íŠ¸ ì¤‘ë³µ: {len(val_event & test_event)}ê°œ")
    
    # ì¤‘ë³µëœ íŒŒì¼ ëª©ë¡ í‘œì‹œ (ì²˜ìŒ 3ê°œë§Œ)
    overlaps = {
        'í›ˆë ¨-ê²€ì¦ ê³µìž¥íŒŒì¼': train_factory & val_factory,
        'í›ˆë ¨-í…ŒìŠ¤íŠ¸ ê³µìž¥íŒŒì¼': train_factory & test_factory,
        'í›ˆë ¨-ê²€ì¦ ìœ„í—˜íŒŒì¼': train_event & val_event,
        'í›ˆë ¨-í…ŒìŠ¤íŠ¸ ìœ„í—˜íŒŒì¼': train_event & test_event
    }
    
    for overlap_type, files in overlaps.items():
        if files:
            print(f"\nðŸ” {overlap_type} ì¤‘ë³µ íŒŒì¼ ì˜ˆì‹œ:")
            for i, filename in enumerate(list(files)[:3]):
                print(f"  {i+1}. {filename}")
            if len(files) > 3:
                print(f"  ... ì´ {len(files)}ê°œ")

def generate_summary_report(dataset_info):
    """ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
    print("\n" + "=" * 60)
    print("ðŸ“‹ ë°ì´í„°ì…‹ ìš”ì•½ ë³´ê³ ì„œ")
    print("=" * 60)
    
    total_samples = sum(len(dataset_info[dt]) for dt in ['train', 'validation', 'test'])
    
    print(f"ðŸ“Š ì „ì²´ í†µê³„:")
    print(f"  ì´ ìƒ˜í”Œ ìˆ˜: {total_samples:,}ê°œ")
    print(f"  í›ˆë ¨ ìƒ˜í”Œ: {len(dataset_info['train']):,}ê°œ ({len(dataset_info['train'])/total_samples*100:.1f}%)")
    print(f"  ê²€ì¦ ìƒ˜í”Œ: {len(dataset_info['validation']):,}ê°œ ({len(dataset_info['validation'])/total_samples*100:.1f}%)")
    print(f"  í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: {len(dataset_info['test']):,}ê°œ ({len(dataset_info['test'])/total_samples*100:.1f}%)")
    
    # ì „ì²´ ì‚¬ìš©ëœ íŒŒì¼ ìˆ˜
    all_factory_files = set()
    all_event_files = set()
    
    for dataset_type in ['train', 'validation', 'test']:
        data = dataset_info[dataset_type]
        all_factory_files.update([item['factory_file'] for item in data if item['factory_file']])
        all_event_files.update([item['event_file'] for item in data if item['event_file']])
    
    print(f"\nðŸŽµ ì‚¬ìš©ëœ ì˜¤ë””ì˜¤ íŒŒì¼:")
    print(f"  ê³µìž¥ ì†Œë¦¬ íŒŒì¼: {len(all_factory_files)}ê°œ")
    print(f"  ìœ„í—˜ ì†Œë¦¬ íŒŒì¼: {len(all_event_files)}ê°œ")
    print(f"  ì´ ê³ ìœ  íŒŒì¼: {len(all_factory_files) + len(all_event_files)}ê°œ")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import sys
    
    # ëª…ë ¹í–‰ ì¸ìˆ˜ ì²˜ë¦¬
    version = None
    folder = None
    filename = None
    
    if len(sys.argv) > 1:
        for i, arg in enumerate(sys.argv[1:], 1):
            if arg == '--version' and i + 1 < len(sys.argv):
                version = sys.argv[i + 1]
            elif arg == '--folder' and i + 1 < len(sys.argv):
                folder = sys.argv[i + 1]
            elif arg == '--file' and i + 1 < len(sys.argv):
                filename = sys.argv[i + 1]
    
    print("ðŸ” ë°ì´í„°ì…‹ ë¶„ì„ ì‹œìž‘...")
    
    # ë°ì´í„°ì…‹ ì •ë³´ ë¡œë“œ
    dataset_info, used_file = load_dataset_info(filename=filename, version=version, folder=folder)
    if dataset_info is None:
        return
    
    print(f"ðŸ“‚ ì‚¬ìš©ëœ íŒŒì¼: {used_file}")
    
    # ê°ì¢… ë¶„ì„ ì‹¤í–‰
    analyze_dataset_distribution(dataset_info)
    analyze_audio_files(dataset_info)
    analyze_data_overlap(dataset_info)
    generate_summary_report(dataset_info)
    
    print("\nâœ… ë°ì´í„°ì…‹ ë¶„ì„ ì™„ë£Œ!")
    
    # ì‚¬ìš©ë²• ì•ˆë‚´
    if not any([filename, version, folder]):
        print("\nðŸ’¡ ì‚¬ìš©ë²•:")
        print("  python analyze_dataset.py --version v1.0")
        print("  python analyze_dataset.py --folder model_results_v1.0_20250808_123456")
        print("  python analyze_dataset.py --file dataset_info_v1.0.json")

if __name__ == '__main__':
    main()
