"""
ì‹¤ì‹œê°„ ìœ„í—˜ ì†Œë¦¬ ê°ì§€ ì‹œìŠ¤í…œ

ë§ˆì´í¬ ê°ë„ ë° ë¬´ìŒ ê°ì§€ ì„¤ì • ê°€ì´ë“œ:
========================================

1. RECORD_DURATION: ë…¹ìŒ ì‹œê°„ (ì´ˆ)
   - 10.0: ê¸°ë³¸ê°’ (10ì´ˆ ë…¹ìŒ)
   - 5.0: ë¹ ë¥¸ ë°˜ì‘ (5ì´ˆ ë…¹ìŒ)
   - 15.0: ë” ê¸´ ë¶„ì„ (15ì´ˆ ë…¹ìŒ)
   
2. ANALYSIS_WAIT_TIME: ë¶„ì„ ì™„ë£Œ í›„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
   - 5.0: ê¸°ë³¸ê°’ (ë¶„ì„ í›„ 5ì´ˆ ëŒ€ê¸°)
   - 2.0: ë” ë¹ˆë²ˆí•œ ê°ì§€ (2ì´ˆ ëŒ€ê¸°)
   - 10.0: ëœ ë¹ˆë²ˆí•œ ê°ì§€ (10ì´ˆ ëŒ€ê¸°)

3. MIC_GAIN: ë§ˆì´í¬ ì…ë ¥ ê°ë„
   - 1.0: ê¸°ë³¸ ê°ë„ (ë³€ê²½ ì—†ìŒ)
   - 2.0: 2ë°° ì¦í­ (ì‘ì€ ì†Œë¦¬ë„ ì˜ ë“¤ë¦¼)
   - 0.5: ì ˆë°˜ìœ¼ë¡œ ê°ì†Œ (í° ì†Œë¦¬ë§Œ ê°ì§€)
   
4. SILENCE_RMS_THRESHOLD: ë¬´ìŒ íŒë‹¨ RMS ê¸°ì¤€
   - 0.005: ê¸°ë³¸ê°’ (ë§¤ìš° ì¡°ìš©í•œ ì†Œë¦¬ê¹Œì§€ ê°ì§€)
   - 0.001: ë” ë¯¼ê° (ë” ì‘ì€ ì†Œë¦¬ë„ ê°ì§€)
   - 0.01: ëœ ë¯¼ê° (ì–´ëŠ ì •ë„ í° ì†Œë¦¬ë§Œ ê°ì§€)
   
5. SILENCE_MAX_THRESHOLD: ë¬´ìŒ íŒë‹¨ ìµœëŒ€ê°’ ê¸°ì¤€
   - 0.01: ê¸°ë³¸ê°’

6. SILENCE_PROCESSING_MODE: ë¬´ìŒ ì²˜ë¦¬ ëª¨ë“œ
   - True: ì‘ì€ ì†Œë¦¬ë¥¼ ë¬´ìŒìœ¼ë¡œ ê°•ì œ ì²˜ë¦¬ (ê¶Œì¥)
   - False: ë¹„í™œì„±í™”
   
7. SILENCE_FORCE_RMS_THRESHOLD / SILENCE_FORCE_MAX_THRESHOLD: ê°•ì œ ë¬´ìŒ ì„ê³„ê°’
   - 0.02 / 0.05: ê¸°ë³¸ê°’ (ì´ë³´ë‹¤ ì‘ìœ¼ë©´ ë¬´ìŒìœ¼ë¡œ ê°•ì œ ë¶„ë¥˜)

ë¬´ìŒ ì²˜ë¦¬ ëª¨ë“œ ê¸°ëŠ¥:
- ê³µì¥ ì†Œë¦¬ â†’ ë¬´ìŒ ì „í™˜ ì‹œ ì˜¤ì¸ì‹ ë°©ì§€
- ì‘ì€ ì†Œë¦¬ë¡œ ì¸í•œ ìœ„í—˜ ì†Œë¦¬ ì˜¤íƒì§€ ë°©ì§€
- AI ì˜ˆì¸¡ë³´ë‹¤ ë¬¼ë¦¬ì  ë³¼ë¥¨ì„ ìš°ì„ í•˜ì—¬ ë¬´ìŒ íŒë‹¨

ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
- ë¹ ë¥¸ ë°˜ì‘ì´ í•„ìš”í•œ ê²½ìš°: RECORD_DURATION=5.0, ANALYSIS_WAIT_TIME=2.0
- ì •í™•í•œ ë¶„ì„ì´ í•„ìš”í•œ ê²½ìš°: RECORD_DURATION=15.0, ANALYSIS_WAIT_TIME=10.0
- ë§ˆì´í¬ê°€ ì‘ê²Œ ë…¹ìŒë˜ëŠ” ê²½ìš°: MIC_GAINì„ 2.0~5.0ìœ¼ë¡œ ì¦ê°€
- ë„ˆë¬´ ë¯¼ê°í•˜ê²Œ ë°˜ì‘í•˜ëŠ” ê²½ìš°: SILENCE_RMS_THRESHOLDë¥¼ 0.01~0.02ë¡œ ì¦ê°€
"""

import numpy as np
import sounddevice as sd
import tensorflow as tf
import tensorflow_hub as hub
from tensorflow.keras.models import load_model
import time
import os
import json
from scipy import signal

# --- ì„¤ì • ---
SAMPLE_RATE = 16000
DURATION = 10.0  # LSTM ëª¨ë¸ ì…ë ¥ ê¸¸ì´ (10ì´ˆ)
THRESHOLD = 0.7  # ìœ„í—˜ ì†Œë¦¬ ê°ì§€ ì„ê³„ê°’

# --- ëª¨ë¸ ê²½ë¡œ ì„¤ì • ---
MODEL_PATH = 'results/version_v2.25/models/yamnet_lstm_model_20250812_173732.h5'  # ê¸°ë³¸ ëª¨ë¸ ê²½ë¡œ
# MODEL_PATH = 'model_results_v1.2_20250808_170648/yamnet_lstm_model_v1.2.h5'
# MODEL_PATH = 'model_results_v1.0_20250808_123555/yamnet_lstm_model_v1.0.h5'  # ë²„ì „ë³„ ëª¨ë¸ ê²½ë¡œ ì˜ˆì‹œ

# --- ë…¹ìŒ ë° ë¶„ì„ ì£¼ê¸° ì„¤ì • ---
RECORD_DURATION = 5.0      # ë…¹ìŒ ì‹œê°„ (ì´ˆ) - ëª¨ë¸ ì…ë ¥ ê¸¸ì´ì™€ ë™ì¼í•˜ê²Œ ì„¤ì • ê¶Œì¥
ANALYSIS_WAIT_TIME = 1.0    # ë¶„ì„ ì™„ë£Œ í›„ ë‹¤ìŒ ë…¹ìŒê¹Œì§€ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)

# --- ë§ˆì´í¬ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì„¤ì • ---
AUTO_CALIBRATION_MODE = True    # True: ìë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜, False: ìˆ˜ë™ ì„¤ì • ì‚¬ìš©
CALIBRATION_SILENCE_DURATION = 5.0      # ë¬´ìŒ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹œê°„ (ì´ˆ)
CALIBRATION_FACTORY_DURATION = 3.0      # ê³µì¥ì†Œë¦¬ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë…¹ìŒ ì‹œê°„ (ì´ˆ)
CALIBRATION_MAX_ATTEMPTS = 10           # ê³µì¥ì†Œë¦¬ ì¸ì‹ ìµœëŒ€ ì‹œë„ íšŸìˆ˜
CALIBRATION_MIN_GAIN = 1.0              # ìµœì†Œ ë§ˆì´í¬ ê°ë„
CALIBRATION_MAX_GAIN = 10.0             # ìµœëŒ€ ë§ˆì´í¬ ê°ë„
CALIBRATION_GAIN_STEP = 0.5             # ê°ë„ ì¦ê°€ ë‹¨ê³„

# --- ë§ˆì´í¬ ë° ë¬´ìŒ ê°ì§€ ì„¤ì • (ìˆ˜ë™ ëª¨ë“œìš©) ---
MIC_GAIN = 3.0              # ë§ˆì´í¬ ì…ë ¥ ê°ë„ (1.0 = ê¸°ë³¸, 2.0 = 2ë°° ì¦í­)
SILENCE_RMS_THRESHOLD = 0.005   # ë¬´ìŒ íŒë‹¨ RMS ì„ê³„ê°’ (ë‚®ì„ìˆ˜ë¡ ë” ì‘ì€ ì†Œë¦¬ë„ ê°ì§€)
SILENCE_MAX_THRESHOLD = 0.01    # ë¬´ìŒ íŒë‹¨ ìµœëŒ€ê°’ ì„ê³„ê°’

# --- ë¬´ìŒ ì²˜ë¦¬ ëª¨ë“œ ì„¤ì • ---
SILENCE_PROCESSING_MODE = False  # True: ì‘ì€ ì†Œë¦¬ë¥¼ ë¬´ìŒìœ¼ë¡œ ê°•ì œ ì²˜ë¦¬, False: ë¹„í™œì„±í™”
SILENCE_FORCE_RMS_THRESHOLD = 0.02  # ì´ ê°’ë³´ë‹¤ ì‘ìœ¼ë©´ ë¬´ìŒìœ¼ë¡œ ê°•ì œ ë¶„ë¥˜ (ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹œ ë™ì  ë³€ê²½ë¨)
SILENCE_FORCE_MAX_THRESHOLD = 0.05  # ì´ ê°’ë³´ë‹¤ ì‘ìœ¼ë©´ ë¬´ìŒìœ¼ë¡œ ê°•ì œ ë¶„ë¥˜ (ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹œ ë™ì  ë³€ê²½ë¨)

# --- ê³µì¥ ì†Œë¦¬ ê¸°ì¤€ ë¬´ìŒ ì²˜ë¦¬ ì„¤ì • ---
FACTORY_BASED_SILENCE_MODE = False   # True: ê³µì¥ ì†Œë¦¬ í¬ê¸° ê¸°ì¤€ ë¬´ìŒ ì²˜ë¦¬, False: ë¹„í™œì„±í™”
FACTORY_SILENCE_RATIO = 0.5         # ê³µì¥ ì†Œë¦¬ì˜ ëª‡ % ì´í•˜ë¥¼ ë¬´ìŒìœ¼ë¡œ ì²˜ë¦¬í• ì§€ (0.5 = 50%)
FACTORY_SILENCE_RMS_THRESHOLD = 0.0 # ê³µì¥ ì†Œë¦¬ RMS ê¸°ì¤€ê°’ (ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹œ ë™ì  ì„¤ì •ë¨)
FACTORY_SILENCE_MAX_THRESHOLD = 0.0 # ê³µì¥ ì†Œë¦¬ Max ê¸°ì¤€ê°’ (ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹œ ë™ì  ì„¤ì •ë¨)

# --- í´ë˜ìŠ¤ ì •ë³´ (5-í´ë˜ìŠ¤) ---
CLASS_NAMES = ['ë¬´ìŒ', 'ì •ìƒ(ê³µì¥)', 'í™”ì¬', 'ê°€ìŠ¤ëˆ„ì¶œ', 'ë¹„ëª…']
CLASS_COLORS = {
    0: 'ğŸ”‡',  # ë¬´ìŒ
    1: 'ğŸŸ¢',  # ì •ìƒ(ê³µì¥)
    2: 'ğŸ”¥',  # í™”ì¬
    3: 'âš ï¸',  # ê°€ìŠ¤ëˆ„ì¶œ
    4: 'ğŸ˜±'   # ë¹„ëª…
}

# --- YAMNet ëª¨ë¸ ë¡œë“œ ---
print("YAMNet ëª¨ë¸ ë¡œë”© ì¤‘...")
YAMNET_MODEL_HANDLE = 'https://tfhub.dev/google/yamnet/1'
yamnet_model = hub.load(YAMNET_MODEL_HANDLE)
yamnet_fn = yamnet_model.signatures['serving_default']
print("YAMNet ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

# --- í•™ìŠµëœ LSTM ëª¨ë¸ ë¡œë“œ ---
if os.path.exists(MODEL_PATH):
    print(f"LSTM ëª¨ë¸ ë¡œë”© ì¤‘: {MODEL_PATH}")
    lstm_model = load_model(MODEL_PATH)
    print("LSTM ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
else:
    print(f"ì˜¤ë¥˜: {MODEL_PATH} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    print("ë¨¼ì € LSTM_Train_5Class.pyë¥¼ ì‹¤í–‰í•˜ê±°ë‚˜ MODEL_PATH ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    exit(1)

def get_yamnet_embedding(audio):
    waveform = tf.convert_to_tensor(audio, dtype=tf.float32)
    waveform = tf.squeeze(waveform)
    yamnet_output = yamnet_fn(waveform=waveform)
    embeddings = yamnet_output['output_1'].numpy()  # (frames, 1024)
    return embeddings

def get_audio_volume(audio):
    """ì˜¤ë””ì˜¤ì˜ RMS ë³¼ë¥¨ê³¼ ìµœëŒ€ ì ˆëŒ“ê°’ ê³„ì‚°"""
    rms = np.sqrt(np.mean(audio**2))
    max_val = np.max(np.abs(audio))
    return rms, max_val

def detect_clipping(audio, threshold=0.95):
    """ì˜¤ë””ì˜¤ í´ë¦¬í•‘ ê°ì§€"""
    clipped_samples = np.sum(np.abs(audio) >= threshold)
    clipping_ratio = clipped_samples / len(audio)
    return clipping_ratio > 0.01  # 1% ì´ìƒ í´ë¦¬í•‘ë˜ë©´ True

def apply_compressor(audio, threshold=0.7, ratio=4.0, attack=0.003, release=0.1, sample_rate=16000):
    """ê°„ë‹¨í•œ ì»´í”„ë ˆì„œ ì ìš© (ê³¼ë„í•œ ë³¼ë¥¨ ì œì–´)"""
    # ê°„ë‹¨í•œ í”¼í¬ ì œí•œ ì»´í”„ë ˆì„œ
    compressed = audio.copy()
    
    # ì„ê³„ê°’ì„ ë„˜ëŠ” ë¶€ë¶„ì„ ì••ì¶•
    mask = np.abs(audio) > threshold
    if np.any(mask):
        # ì••ì¶• ë¹„ìœ¨ ì ìš©
        compressed[mask] = np.sign(audio[mask]) * (
            threshold + (np.abs(audio[mask]) - threshold) / ratio
        )
    
    return compressed

def normalize_audio_adaptive(audio, target_rms=0.1, max_gain=3.0):
    """ì ì‘í˜• ì˜¤ë””ì˜¤ ì •ê·œí™”"""
    current_rms = np.sqrt(np.mean(audio**2))
    
    if current_rms < 1e-6:  # ê±°ì˜ ë¬´ìŒì¸ ê²½ìš°
        return audio
    
    # ëª©í‘œ RMSì— ë§ì¶° ê²Œì¸ ê³„ì‚°
    gain = target_rms / current_rms
    
    # ìµœëŒ€ ê²Œì¸ ì œí•œ
    gain = min(gain, max_gain)
    
    normalized = audio * gain
    
    # ìµœì¢… í´ë¦¬í•‘ ë°©ì§€
    max_val = np.max(np.abs(normalized))
    if max_val > 0.95:
        normalized = normalized * (0.95 / max_val)
    
    return normalized

def analyze_frequency_content(audio, sample_rate=16000):
    """ì£¼íŒŒìˆ˜ ë¶„ì„ìœ¼ë¡œ ì†Œë¦¬ íŠ¹ì„± íŒŒì•…"""
    # FFT ìˆ˜í–‰
    fft = np.fft.rfft(audio)
    freqs = np.fft.rfftfreq(len(audio), 1/sample_rate)
    magnitude = np.abs(fft)
    
    # ì£¼ìš” ì£¼íŒŒìˆ˜ ëŒ€ì—­ë³„ ì—ë„ˆì§€ ê³„ì‚°
    low_freq_energy = np.sum(magnitude[(freqs >= 50) & (freqs <= 500)])    # ì €ì£¼íŒŒ (ê¸°ê³„ìŒ)
    mid_freq_energy = np.sum(magnitude[(freqs >= 500) & (freqs <= 2000)])   # ì¤‘ì£¼íŒŒ (ì¼ë°˜ ì†ŒìŒ)
    high_freq_energy = np.sum(magnitude[(freqs >= 2000) & (freqs <= 8000)]) # ê³ ì£¼íŒŒ (ë¹„ëª… ë“±)
    
    total_energy = low_freq_energy + mid_freq_energy + high_freq_energy
    
    if total_energy < 1e-6:
        return 0.33, 0.33, 0.34  # ê· ë“± ë¶„ë°°
    
    # ë¹„ìœ¨ ê³„ì‚°
    low_ratio = low_freq_energy / total_energy
    mid_ratio = mid_freq_energy / total_energy
    high_ratio = high_freq_energy / total_energy
    
    return low_ratio, mid_ratio, high_ratio

def preprocess_audio(audio, sample_rate=16000):
    """í†µí•© ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ í•¨ìˆ˜"""
    original_rms, original_max = get_audio_volume(audio)
    
    # 1. í´ë¦¬í•‘ ê°ì§€
    is_clipped = detect_clipping(audio)
    
    # 2. ì»´í”„ë ˆì„œ ì ìš© (ê³¼ë„í•œ ë³¼ë¥¨ ì œì–´)
    if original_max > 0.8 or is_clipped:
        audio = apply_compressor(audio, threshold=0.6, ratio=6.0)
    
    # 3. ì ì‘í˜• ì •ê·œí™”
    if original_rms > 0.001:  # ë¬´ìŒì´ ì•„ë‹Œ ê²½ìš°ë§Œ
        # ë³¼ë¥¨ì´ ë§¤ìš° ë†’ì€ ê²½ìš° ë” ë³´ìˆ˜ì ìœ¼ë¡œ ì •ê·œí™”
        if original_rms > 0.3:
            target_rms = 0.08  # ë” ë‚®ì€ ëª©í‘œ
            max_gain = 1.5     # ê²Œì¸ ì œí•œ
        else:
            target_rms = 0.1
            max_gain = 3.0
            
        audio = normalize_audio_adaptive(audio, target_rms, max_gain)
    
    # 4. ìµœì¢… ì•ˆì „ì¥ì¹˜ (í•˜ë“œ ë¦¬ë¯¸í„°)
    audio = np.clip(audio, -0.95, 0.95)
    
    # ì „ì²˜ë¦¬ ì •ë³´ ë°˜í™˜
    processed_rms, processed_max = get_audio_volume(audio)
    preprocessing_info = {
        'original_rms': original_rms,
        'original_max': original_max,
        'processed_rms': processed_rms,
        'processed_max': processed_max,
        'was_clipped': is_clipped,
        'volume_reduced': original_rms > processed_rms * 1.5
    }
    
    return audio, preprocessing_info

def is_silence(audio, rms_threshold=None, max_threshold=None):
    """ì˜¤ë””ì˜¤ê°€ ë¬´ìŒì¸ì§€ íŒë‹¨"""
    if rms_threshold is None:
        rms_threshold = SILENCE_RMS_THRESHOLD
    if max_threshold is None:
        max_threshold = SILENCE_MAX_THRESHOLD
        
    rms, max_val = get_audio_volume(audio)
    return rms < rms_threshold and max_val < max_threshold

def record_audio(duration, sample_rate, mic_gain=None):
    """ë§ˆì´í¬ë¡œë¶€í„° ì˜¤ë””ì˜¤ ë…¹ìŒ (ê°ë„ ì¡°ì ˆ í¬í•¨)"""
    if mic_gain is None:
        mic_gain = MIC_GAIN
        
    print(f"{duration}ì´ˆ ë™ì•ˆ ë…¹ìŒ ì¤‘... (ë§ˆì´í¬ ê°ë„: {mic_gain}x)")
    audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype='float32')
    sd.wait()
    audio = audio.flatten()
    
    # ë§ˆì´í¬ ê°ë„ ì ìš© (ì¦í­)
    audio = audio * mic_gain
    
    # í´ë¦¬í•‘ ë°©ì§€ (ê°ë„ ì¦í­ í›„)
    max_val = np.max(np.abs(audio))
    if max_val > 1.0:
        audio = audio / max_val
        print(f"âš ï¸ ë§ˆì´í¬ ê°ë„ë¡œ ì¸í•œ í´ë¦¬í•‘ ë°©ì§€: {max_val:.3f} â†’ 1.0")
    
    # ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ì ìš©
    processed_audio, preprocessing_info = preprocess_audio(audio, sample_rate)
    
    # ì „ì²˜ë¦¬ ì •ë³´ì— ë§ˆì´í¬ ê°ë„ ì •ë³´ ì¶”ê°€
    preprocessing_info['mic_gain'] = mic_gain
    preprocessing_info['was_mic_amplified'] = mic_gain > 1.0
    
    return processed_audio, preprocessing_info

def calibrate_microphone():
    """
    ë§ˆì´í¬ ìë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìˆ˜í–‰
    1. ê³µì¥ ì†Œë¦¬ë¥¼ ê°ì§€í•  ìˆ˜ ìˆëŠ” ìµœì  ê°ë„ ì°¾ê¸°
    2. ìµœì  ê°ë„ë¡œ ë¬´ìŒ ìƒíƒœì—ì„œ ë°°ê²½ ë…¸ì´ì¦ˆ ë ˆë²¨ ì¸¡ì •
    
    Returns:
        dict: ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê²°ê³¼ (optimal_gain, silence_baseline, etc.)
    """
    print("ğŸ”§ ë§ˆì´í¬ ìë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹œì‘")
    print("=" * 50)
    
    # 1ë‹¨ê³„: ê³µì¥ ì†Œë¦¬ ê°ì§€ ìº˜ë¦¬ë¸Œë ˆì´ì…˜
    print(f"ğŸ“ 1ë‹¨ê³„: ê³µì¥ ì†Œë¦¬ ê°ì§€ ìº˜ë¦¬ë¸Œë ˆì´ì…˜")
    print("ğŸ’¡ ì •ìƒì ì¸ ê³µì¥ ì†Œë¦¬(ê¸°ê³„ ì†ŒìŒ)ë¥¼ ë‚´ì£¼ì„¸ìš”...")
    print("   ì‹œìŠ¤í…œì´ ê³µì¥ ì†Œë¦¬ë¥¼ ì¸ì‹í•  ë•Œê¹Œì§€ ë§ˆì´í¬ ê°ë„ë¥¼ ìë™ ì¡°ì •í•©ë‹ˆë‹¤.")
    
    time.sleep(3)  # ì¤€ë¹„ ì‹œê°„
    
    optimal_gain = CALIBRATION_MIN_GAIN
    factory_detected = False
    attempt = 0
    calibration_results = {
        'optimal_gain': optimal_gain,
        'factory_detected': False,
        'attempts': 0,
        'calibration_history': []
    }
    
    while attempt < CALIBRATION_MAX_ATTEMPTS and not factory_detected:
        attempt += 1
        current_gain = CALIBRATION_MIN_GAIN + (attempt - 1) * CALIBRATION_GAIN_STEP
        
        if current_gain > CALIBRATION_MAX_GAIN:
            break
            
        print(f"\nğŸ¤ ì‹œë„ {attempt}/{CALIBRATION_MAX_ATTEMPTS} - ë§ˆì´í¬ ê°ë„: {current_gain:.1f}x")
        
        # ê³µì¥ ì†Œë¦¬ ë…¹ìŒ
        factory_audio = sd.rec(int(CALIBRATION_FACTORY_DURATION * SAMPLE_RATE), 
                             samplerate=SAMPLE_RATE, channels=1, dtype='float32')
        sd.wait()
        factory_audio = factory_audio.flatten()
        
        # ê°ë„ ì ìš©
        factory_audio = factory_audio * current_gain
        
        # í´ë¦¬í•‘ ë°©ì§€
        max_val = np.max(np.abs(factory_audio))
        if max_val > 1.0:
            factory_audio = factory_audio / max_val
        
        # ì „ì²˜ë¦¬
        processed_audio, preprocessing_info = preprocess_audio(factory_audio, SAMPLE_RATE)
        
        # ì˜¤ë””ì˜¤ ë¶„ì„
        rms, max_audio = get_audio_volume(processed_audio)
        
        # ê¸°ë³¸ ë¬´ìŒì´ ì•„ë‹Œì§€ í™•ì¸ (ì„ì‹œ ê¸°ì¤€ê°’ ì‚¬ìš©)
        is_not_silence = not is_silence(processed_audio, 
                                       rms_threshold=0.005,  # ì„ì‹œ ê¸°ì¤€ê°’
                                       max_threshold=0.01)   # ì„ì‹œ ê¸°ì¤€ê°’
        
        attempt_result = {
            'attempt': attempt,
            'gain': current_gain,
            'rms': rms,
            'max_val': max_audio,
            'is_not_silence': is_not_silence,
            'preprocessing_info': preprocessing_info
        }
        
        print(f"   ğŸ“Š ì˜¤ë””ì˜¤ ë¶„ì„: RMS={rms:.4f}, Max={max_audio:.4f}")
        print(f"   ğŸ” ë¬´ìŒ ì—¬ë¶€: {'ì•„ë‹ˆì˜¤' if is_not_silence else 'ì˜ˆ'}")
        
        if is_not_silence:
            # AI ëª¨ë¸ë¡œ ê³µì¥ ì†Œë¦¬ì¸ì§€ í™•ì¸
            try:
                predicted_class, max_prob, frame_predictions, _, _, _ = predict_risk(processed_audio, preprocessing_info)
                
                # ì •ìƒ(ê³µì¥) ì†Œë¦¬(í´ë˜ìŠ¤ 1)ë¡œ ë¶„ë¥˜ë˜ëŠ”ì§€ í™•ì¸
                if predicted_class == 1 and max_prob > 0.5:  # ê³µì¥ ì†Œë¦¬ë¡œ ì¸ì‹
                    factory_detected = True
                    optimal_gain = current_gain
                    attempt_result['ai_prediction'] = {
                        'class': predicted_class,
                        'probability': max_prob,
                        'class_name': CLASS_NAMES[predicted_class]
                    }
                    # ê³µì¥ ì†Œë¦¬ í¬ê¸° ê¸°ë¡
                    attempt_result['factory_audio_levels'] = {
                        'rms': rms,
                        'max_val': max_audio
                    }
                    print(f"   ğŸ¯ AI ì˜ˆì¸¡: {CLASS_NAMES[predicted_class]} (í™•ë¥ : {max_prob:.3f})")
                    print(f"   ğŸ“Š ê³µì¥ ì†Œë¦¬ í¬ê¸°: RMS={rms:.4f}, Max={max_audio:.4f}")
                    print(f"   âœ… ê³µì¥ ì†Œë¦¬ ì¸ì‹ ì„±ê³µ!")
                    break
                else:
                    attempt_result['ai_prediction'] = {
                        'class': predicted_class,
                        'probability': max_prob,
                        'class_name': CLASS_NAMES[predicted_class] if predicted_class < len(CLASS_NAMES) else f"í´ë˜ìŠ¤{predicted_class}"
                    }
                    print(f"   ğŸ¯ AI ì˜ˆì¸¡: {attempt_result['ai_prediction']['class_name']} (í™•ë¥ : {max_prob:.3f})")
                    print(f"   âš ï¸ ê³µì¥ ì†Œë¦¬ë¡œ ì¸ì‹ë˜ì§€ ì•ŠìŒ. ê°ë„ë¥¼ ë†’ì…ë‹ˆë‹¤...")
                    
            except Exception as e:
                print(f"   âŒ AI ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
                attempt_result['ai_prediction'] = None
        else:
            print(f"   âš ï¸ ì—¬ì „íˆ ë¬´ìŒìœ¼ë¡œ ê°ì§€ë¨. ê°ë„ë¥¼ ë†’ì…ë‹ˆë‹¤...")
            attempt_result['ai_prediction'] = None
        
        calibration_results['calibration_history'].append(attempt_result)
        
        time.sleep(1)  # ë‹¤ìŒ ì‹œë„ ì „ ì ì‹œ ëŒ€ê¸°
    
    calibration_results['attempts'] = attempt
    calibration_results['factory_detected'] = factory_detected
    calibration_results['optimal_gain'] = optimal_gain
    
    if not factory_detected:
        print(f"\nâŒ 1ë‹¨ê³„ ì‹¤íŒ¨: ê³µì¥ ì†Œë¦¬ë¥¼ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        print(f"ğŸ’¡ ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
        print(f"   - ë§ˆì´í¬ê°€ ì˜¬ë°”ë¥´ê²Œ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€")
        print(f"   - ê³µì¥ ì†ŒìŒì´ ì¶©ë¶„íˆ í¬ê²Œ ë“¤ë¦¬ëŠ”ì§€")
        print(f"   - ìµœëŒ€ ê°ë„({CALIBRATION_MAX_GAIN}x)ë¡œë„ ì¸ì‹ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print(f"ğŸ“ ìˆ˜ë™ ì„¤ì •ì„ ì‚¬ìš©í•˜ê±°ë‚˜ í™˜ê²½ì„ í™•ì¸ í›„ ì¬ì‹œë„í•˜ì„¸ìš”.")
        
        # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©
        calibration_results.update({
            'optimal_gain': MIC_GAIN,
            'silence_rms': SILENCE_RMS_THRESHOLD,
            'silence_max': SILENCE_MAX_THRESHOLD,
            'dynamic_silence_rms_threshold': SILENCE_RMS_THRESHOLD,
            'dynamic_silence_max_threshold': SILENCE_MAX_THRESHOLD
        })
        return calibration_results
    
    # 2ë‹¨ê³„: ìµœì  ê°ë„ë¡œ ë¬´ìŒ ìƒíƒœ ì¸¡ì •
    print(f"\nğŸ“ 2ë‹¨ê³„: ë¬´ìŒ ìƒíƒœ ì¸¡ì • (ê°ë„: {optimal_gain:.1f}x, {CALIBRATION_SILENCE_DURATION}ì´ˆ)")
    print("ğŸ’¡ ì´ì œ ê³µì¥ ì†Œë¦¬ë¥¼ ì™„ì „íˆ ë„ê³  ì£¼ë³€ì„ ìµœëŒ€í•œ ì¡°ìš©í•˜ê²Œ ìœ ì§€í•´ì£¼ì„¸ìš”...")
    print("â±ï¸ ê³µì¥ ì†Œë¦¬ë¥¼ ëŒ ì‹œê°„ì„ ë“œë¦½ë‹ˆë‹¤...")
    
    # ê³µì¥ ì†Œë¦¬ë¥¼ ëŒ ì‹œê°„ì„ ì¶©ë¶„íˆ ì œê³µ
    for i in range(5, 0, -1):
        print(f"   {i}ì´ˆ í›„ ë¬´ìŒ ì¸¡ì •ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        time.sleep(1)
    
    print("ğŸ”‡ ë¬´ìŒ ì¸¡ì •ì„ ì‹œì‘í•©ë‹ˆë‹¤!")
    
    # ìµœì  ê°ë„ë¡œ ë¬´ìŒ ë…¹ìŒ
    silence_audio = sd.rec(int(CALIBRATION_SILENCE_DURATION * SAMPLE_RATE), 
                          samplerate=SAMPLE_RATE, channels=1, dtype='float32')
    sd.wait()
    silence_audio = silence_audio.flatten()
    
    # ìµœì  ê°ë„ ì ìš©
    silence_audio = silence_audio * optimal_gain
    
    # í´ë¦¬í•‘ ë°©ì§€
    max_val = np.max(np.abs(silence_audio))
    if max_val > 1.0:
        silence_audio = silence_audio / max_val
    
    # ì „ì²˜ë¦¬
    processed_silence, _ = preprocess_audio(silence_audio, SAMPLE_RATE)
    
    # ë¬´ìŒ ê¸°ì¤€ê°’ ê³„ì‚°
    silence_rms = np.sqrt(np.mean(processed_silence**2))
    silence_max = np.max(np.abs(processed_silence))
    
    print(f"âœ… ë¬´ìŒ ê¸°ì¤€ê°’ ì¸¡ì • ì™„ë£Œ:")
    print(f"   - RMS: {silence_rms:.6f}")
    print(f"   - Max: {silence_max:.6f}")
    
    # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ‰ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ!")
    print("=" * 50)
    print(f"âœ… ì„±ê³µ: ìµœì  ë§ˆì´í¬ ê°ë„ = {optimal_gain:.1f}x")
    print(f"ğŸ“Š ë¬´ìŒ ê¸°ì¤€ê°’: RMS={silence_rms:.6f}, Max={silence_max:.6f}")
    print(f"ğŸ­ ê³µì¥ ì†Œë¦¬ ì¸ì‹ë¨ ({attempt}ë²ˆì§¸ ì‹œë„)")
    
    # ë™ì  ì„ê³„ê°’ ê³„ì‚°
    dynamic_silence_rms = silence_rms * 2.0  # ë¬´ìŒ ê¸°ì¤€ì˜ 2ë°°
    dynamic_silence_max = silence_max * 2.0
    
    # ë¬´ìŒ ì²˜ë¦¬ ëª¨ë“œìš© ê°•ì œ ì„ê³„ê°’ ê³„ì‚° (ë¬´ìŒ ê¸°ì¤€ì˜ 3~4ë°°)
    force_silence_rms = silence_rms * 3.0
    force_silence_max = silence_max * 4.0
    
    # ê³µì¥ ì†Œë¦¬ ê¸°ì¤€ ë¬´ìŒ ì²˜ë¦¬ ì„ê³„ê°’ ê³„ì‚°
    factory_audio_levels = None
    for result in calibration_results['calibration_history']:
        if result.get('factory_audio_levels'):
            factory_audio_levels = result['factory_audio_levels']
            break
    
    if factory_audio_levels:
        factory_rms_threshold = factory_audio_levels['rms'] * FACTORY_SILENCE_RATIO
        factory_max_threshold = factory_audio_levels['max_val'] * FACTORY_SILENCE_RATIO
    else:
        # ê³µì¥ ì†Œë¦¬ í¬ê¸°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
        factory_rms_threshold = dynamic_silence_rms
        factory_max_threshold = dynamic_silence_max
    
    calibration_results.update({
        'silence_rms': silence_rms,
        'silence_max': silence_max,
        'dynamic_silence_rms_threshold': dynamic_silence_rms,
        'dynamic_silence_max_threshold': dynamic_silence_max, 
        'force_silence_rms_threshold': force_silence_rms,
        'force_silence_max_threshold': force_silence_max,
        'factory_rms_threshold': factory_rms_threshold,
        'factory_max_threshold': factory_max_threshold,
        'factory_audio_levels': factory_audio_levels
    })
    
    print(f"ğŸ”§ ë™ì  ì„ê³„ê°’:")
    print(f"   - ë¬´ìŒ RMS ì„ê³„ê°’: {dynamic_silence_rms:.6f}")
    print(f"   - ë¬´ìŒ Max ì„ê³„ê°’: {dynamic_silence_max:.6f}")
    print(f"   - ê°•ì œ ë¬´ìŒ RMS ì„ê³„ê°’: {force_silence_rms:.6f}")
    print(f"   - ê°•ì œ ë¬´ìŒ Max ì„ê³„ê°’: {force_silence_max:.6f}")
    if factory_audio_levels:
        print(f"   - ê³µì¥ ê¸°ì¤€ ë¬´ìŒ RMS ì„ê³„ê°’: {factory_rms_threshold:.6f} (ê³µì¥ ì†Œë¦¬ì˜ {FACTORY_SILENCE_RATIO*100:.0f}%)")
        print(f"   - ê³µì¥ ê¸°ì¤€ ë¬´ìŒ Max ì„ê³„ê°’: {factory_max_threshold:.6f} (ê³µì¥ ì†Œë¦¬ì˜ {FACTORY_SILENCE_RATIO*100:.0f}%)")
    else:
        print(f"   - ê³µì¥ ê¸°ì¤€ ë¬´ìŒ ì„ê³„ê°’: ê³µì¥ ì†Œë¦¬ í¬ê¸°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ê°’ ì‚¬ìš©")
    
    return calibration_results

def predict_risk(audio, preprocessing_info):
    # ë¨¼ì € ì‹¤ì œ ë³¼ë¥¨ ì²´í¬
    rms, max_val = get_audio_volume(audio)
    
    # 1. ê¸°ë³¸ ë¬´ìŒ ê°ì§€
    if is_silence(audio):
        # ë¬´ìŒìœ¼ë¡œ ì§ì ‘ íŒë‹¨
        return 0, 0.95, np.array([0.95, 0.01, 0.01, 0.01, 0.01]), 0, rms, max_val
    
    # 2. ë¬´ìŒ ì²˜ë¦¬ ëª¨ë“œ - ì‘ì€ ì†Œë¦¬ë¥¼ ë¬´ìŒìœ¼ë¡œ ê°•ì œ ì²˜ë¦¬
    if SILENCE_PROCESSING_MODE:
        if rms < SILENCE_FORCE_RMS_THRESHOLD and max_val < SILENCE_FORCE_MAX_THRESHOLD:
            print(f"ğŸ”‡ ë¬´ìŒ ì²˜ë¦¬ ëª¨ë“œ: ì‘ì€ ì†Œë¦¬ë¥¼ ë¬´ìŒìœ¼ë¡œ ê°•ì œ ì²˜ë¦¬ (RMS: {rms:.4f}, Max: {max_val:.4f})")
            return 0, 0.90, np.array([0.90, 0.05, 0.02, 0.02, 0.01]), 0, rms, max_val
    
    # 3. ê³µì¥ ê¸°ì¤€ ë¬´ìŒ ì²˜ë¦¬ ëª¨ë“œ - ê³µì¥ ì†Œë¦¬ì˜ ì¼ì • ë¹„ìœ¨ ì´í•˜ ë¬´ìŒ ì²˜ë¦¬
    if FACTORY_BASED_SILENCE_MODE:
        if rms < FACTORY_SILENCE_RMS_THRESHOLD and max_val < FACTORY_SILENCE_MAX_THRESHOLD:
            print(f"ğŸ­ ê³µì¥ ê¸°ì¤€ ë¬´ìŒ ì²˜ë¦¬: ê³µì¥ ì†Œë¦¬ì˜ {FACTORY_SILENCE_RATIO*100:.0f}% ì´í•˜ë¡œ ë¬´ìŒ ì²˜ë¦¬")
            print(f"   í˜„ì¬: RMS={rms:.4f}, Max={max_val:.4f}")
            print(f"   ì„ê³„ê°’: RMS<{FACTORY_SILENCE_RMS_THRESHOLD:.4f}, Max<{FACTORY_SILENCE_MAX_THRESHOLD:.4f}")
            return 0, 0.88, np.array([0.88, 0.07, 0.02, 0.02, 0.01]), 0, rms, max_val
    
    embeddings = get_yamnet_embedding(audio)  # (time_steps, 1024)
    
    # ëª¨ë¸ ì…ë ¥ í˜•íƒœ í™•ì¸ ë° ì°¨ì› ì¡°ì •
    print(f"ğŸ” YAMNet ì„ë² ë”© í˜•íƒœ: {embeddings.shape}")
    print(f"ğŸ” LSTM ëª¨ë¸ ì…ë ¥ í˜•íƒœ: {lstm_model.input_shape}")
    
    # LSTM ëª¨ë¸ì˜ ì…ë ¥ ì°¨ì›ì— ë”°ë¼ ì²˜ë¦¬ ë°©ì‹ ê²°ì •
    if len(lstm_model.input_shape) == 2:  # Dense ë ˆì´ì–´ ê¸°ë°˜ ëª¨ë¸ (batch, features)
        # ì‹œê°„ì¶• í‰ê· ìœ¼ë¡œ ë‹¨ì¼ ë²¡í„° ìƒì„±
        embeddings_avg = np.mean(embeddings, axis=0)  # (1024,)
        embeddings_input = np.expand_dims(embeddings_avg, axis=0)  # (1, 1024)
        print(f"ğŸ“ Dense ëª¨ë¸ìš© ì„ë² ë”©: {embeddings_input.shape}")
        
    elif len(lstm_model.input_shape) == 3:  # LSTM ê¸°ë°˜ ëª¨ë¸ (batch, time_steps, features)
        # ëª¨ë¸ ì…ë ¥ì— ë§ê²Œ íŒ¨ë”©/ìë¥´ê¸°
        target_length = lstm_model.input_shape[1]  # ëª¨ë¸ì˜ time_steps ì°¨ì›
        current_length = embeddings.shape[0]
        
        if current_length < target_length:
            # íŒ¨ë”©
            pad_length = target_length - current_length
            embeddings = np.pad(embeddings, ((0, pad_length), (0, 0)), mode='constant')
            print(f"ğŸ“ ì„ë² ë”© íŒ¨ë”©: {current_length} â†’ {target_length} í”„ë ˆì„")
        elif current_length > target_length:
            # ìë¥´ê¸°
            embeddings = embeddings[:target_length]
            print(f"ğŸ“ ì„ë² ë”© ìë¥´ê¸°: {current_length} â†’ {target_length} í”„ë ˆì„")
        
        embeddings_input = np.expand_dims(embeddings, axis=0)  # (1, time_steps, 1024)
        print(f"ğŸ“ LSTM ëª¨ë¸ìš© ì„ë² ë”©: {embeddings_input.shape}")
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ ì…ë ¥ í˜•íƒœ: {lstm_model.input_shape}")
    
    # ì˜ˆì¸¡ ìˆ˜í–‰
    preds = lstm_model.predict(embeddings_input, verbose=0)
    
    # ì¶œë ¥ í˜•íƒœì— ë”°ë¼ ì²˜ë¦¬
    if len(preds.shape) == 3:  # LSTM ì¶œë ¥: (batch, time_steps, num_classes)
        preds = preds[0]  # (time_steps, num_classes)
        
        # ê° í´ë˜ìŠ¤ì˜ ìµœëŒ€ í™•ë¥ ê³¼ ìœ„ì¹˜ ì°¾ê¸°
        for i in range(len(preds)):
            print(f"{i+1}ë²ˆ í”„ë ˆì„", round(preds[i][0],2), round(preds[i][1],2), round(preds[i][2],2), round(preds[i][3],2), round(preds[i][4],2))

        max_probs = np.max(preds, axis=0)  # ê° í´ë˜ìŠ¤ë³„ ìµœëŒ€ í™•ë¥ 
        overall_max_prob = np.max(max_probs)
        predicted_class = np.argmax(max_probs)
        
        # í”„ë ˆì„ë³„ ì˜ˆì¸¡ì—ì„œ ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ í”„ë ˆì„ ì°¾ê¸°
        max_frame_idx = np.argmax(np.max(preds, axis=1))
        frame_predictions = preds[max_frame_idx]  # í•´ë‹¹ í”„ë ˆì„ì˜ í´ë˜ìŠ¤ë³„ í™•ë¥ 
        
    elif len(preds.shape) == 2:  # Dense ì¶œë ¥: (batch, num_classes)
        preds = preds[0]  # (num_classes,)
        
        print(f"ì˜ˆì¸¡ í™•ë¥ :", round(preds[0],2), round(preds[1],2), round(preds[2],2), round(preds[3],2), round(preds[4],2))
        
        overall_max_prob = np.max(preds)
        predicted_class = np.argmax(preds)
        frame_predictions = preds
        max_frame_idx = 0  # Dense ëª¨ë¸ì€ ë‹¨ì¼ ì˜ˆì¸¡
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ ì¶œë ¥ í˜•íƒœ: {preds.shape}")
    
    # 3. ë¬´ìŒ ì²˜ë¦¬ ëª¨ë“œ - AI ì˜ˆì¸¡ í›„ ì¶”ê°€ ê²€ì¦
    if SILENCE_PROCESSING_MODE and predicted_class >= 2:  # ìœ„í—˜ ì†Œë¦¬ë¡œ ì˜ˆì¸¡ëœ ê²½ìš°
        # ì‹¤ì œ ì˜¤ë””ì˜¤ ë³¼ë¥¨ì´ ë§¤ìš° ì‘ë‹¤ë©´ ë¬´ìŒìœ¼ë¡œ ì¬ë¶„ë¥˜
        if rms < SILENCE_FORCE_RMS_THRESHOLD * 1.5 and max_val < SILENCE_FORCE_MAX_THRESHOLD * 1.5:
            print(f"ğŸ”‡ ë¬´ìŒ ì²˜ë¦¬ ëª¨ë“œ: ìœ„í—˜ ì†Œë¦¬ ì˜ˆì¸¡ì´ì§€ë§Œ ë³¼ë¥¨ì´ ë„ˆë¬´ ì‘ì•„ ë¬´ìŒìœ¼ë¡œ ì¬ë¶„ë¥˜")
            print(f"   ì›ë˜ ì˜ˆì¸¡: {CLASS_NAMES[predicted_class] if predicted_class < len(CLASS_NAMES) else f'í´ë˜ìŠ¤{predicted_class}'} (í™•ë¥ : {overall_max_prob:.3f})")
            return 0, 0.85, np.array([0.85, 0.10, 0.02, 0.02, 0.01]), 0, rms, max_val
    
    # 4. ê³µì¥ ê¸°ì¤€ ë¬´ìŒ ì²˜ë¦¬ ëª¨ë“œ - AI ì˜ˆì¸¡ í›„ ì¶”ê°€ ê²€ì¦
    if FACTORY_BASED_SILENCE_MODE and predicted_class >= 2:  # ìœ„í—˜ ì†Œë¦¬ë¡œ ì˜ˆì¸¡ëœ ê²½ìš°
        # ê³µì¥ ì†Œë¦¬ ê¸°ì¤€ìœ¼ë¡œ ë³¼ë¥¨ì´ ë§¤ìš° ì‘ë‹¤ë©´ ë¬´ìŒìœ¼ë¡œ ì¬ë¶„ë¥˜
        if rms < FACTORY_SILENCE_RMS_THRESHOLD * 1.2 and max_val < FACTORY_SILENCE_MAX_THRESHOLD * 1.2:
            print(f"ğŸ­ ê³µì¥ ê¸°ì¤€ ë¬´ìŒ ì²˜ë¦¬: ìœ„í—˜ ì†Œë¦¬ ì˜ˆì¸¡ì´ì§€ë§Œ ê³µì¥ ì†Œë¦¬ ëŒ€ë¹„ ë³¼ë¥¨ì´ ë„ˆë¬´ ì‘ì•„ ë¬´ìŒìœ¼ë¡œ ì¬ë¶„ë¥˜")
            print(f"   ì›ë˜ ì˜ˆì¸¡: {CLASS_NAMES[predicted_class] if predicted_class < len(CLASS_NAMES) else f'í´ë˜ìŠ¤{predicted_class}'} (í™•ë¥ : {overall_max_prob:.3f})")
            print(f"   í˜„ì¬ ë³¼ë¥¨: RMS={rms:.4f}, Max={max_val:.4f}")
            return 0, 0.83, np.array([0.83, 0.12, 0.02, 0.02, 0.01]), 0, rms, max_val
    
    return predicted_class, overall_max_prob, frame_predictions, max_frame_idx, rms, max_val

def main():
    global MIC_GAIN, SILENCE_RMS_THRESHOLD, SILENCE_MAX_THRESHOLD
    global SILENCE_FORCE_RMS_THRESHOLD, SILENCE_FORCE_MAX_THRESHOLD
    global FACTORY_SILENCE_RMS_THRESHOLD, FACTORY_SILENCE_MAX_THRESHOLD
    
    window_length = RECORD_DURATION
    wait_time_between_recordings = ANALYSIS_WAIT_TIME
    
    print("ğŸ”Š ì‹¤ì‹œê°„ ìœ„í—˜ ì†Œë¦¬ ê°ì§€ ì‹œìŠ¤í…œ")
    print("=" * 50)
    print("ëª¨ë¸ ì •ë³´: 5ê°œ í´ë˜ìŠ¤ (5-í´ë˜ìŠ¤: ë¬´ìŒ í¬í•¨)")
    print(f"ëª¨ë¸ ê²½ë¡œ: {MODEL_PATH}")
    print(f"ë…¹ìŒ ì‹œê°„: {RECORD_DURATION}ì´ˆ")
    print(f"ë¶„ì„ í›„ ëŒ€ê¸°ì‹œê°„: {ANALYSIS_WAIT_TIME}ì´ˆ")
    
    # ì›ë³¸ ì„¤ì •ê°’ ì €ì¥
    original_mic_gain = MIC_GAIN
    original_silence_rms = SILENCE_RMS_THRESHOLD
    original_silence_max = SILENCE_MAX_THRESHOLD
    original_force_rms = SILENCE_FORCE_RMS_THRESHOLD
    original_force_max = SILENCE_FORCE_MAX_THRESHOLD
    original_factory_rms = FACTORY_SILENCE_RMS_THRESHOLD
    original_factory_max = FACTORY_SILENCE_MAX_THRESHOLD
    
    # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ëª¨ë“œ ì²˜ë¦¬
    if AUTO_CALIBRATION_MODE:
        print(f"\nğŸ”§ ìë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ëª¨ë“œ")
        print("ğŸ’¡ ë§ˆì´í¬ ê°ë„ì™€ ë¬´ìŒ ê¸°ì¤€ê°’ì„ ìë™ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
        print("âœ… ìë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        
        try:
            calibration_results = calibrate_microphone()
        except KeyboardInterrupt:
            print("\nâŒ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ë™ ì„¤ì •ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            calibration_results = None
    else:
        print(f"\nâš™ï¸ ìˆ˜ë™ ì„¤ì • ëª¨ë“œ")
        calibration_results = None
    
    # ì„¤ì •ê°’ ì—…ë°ì´íŠ¸
    if calibration_results and calibration_results['factory_detected']:
        # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì„±ê³µ - ì „ì—­ ë³€ìˆ˜ ì—…ë°ì´íŠ¸
        MIC_GAIN = calibration_results['optimal_gain']
        SILENCE_RMS_THRESHOLD = calibration_results['dynamic_silence_rms_threshold']
        SILENCE_MAX_THRESHOLD = calibration_results['dynamic_silence_max_threshold']
        SILENCE_FORCE_RMS_THRESHOLD = calibration_results['force_silence_rms_threshold']
        SILENCE_FORCE_MAX_THRESHOLD = calibration_results['force_silence_max_threshold']
        FACTORY_SILENCE_RMS_THRESHOLD = calibration_results['factory_rms_threshold']
        FACTORY_SILENCE_MAX_THRESHOLD = calibration_results['factory_max_threshold']
        mode_name = "ìë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜"
    else:
        # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹¤íŒ¨ ë˜ëŠ” ìˆ˜ë™ ëª¨ë“œ - ì›ë³¸ ì„¤ì •ê°’ ìœ ì§€
        mode_name = "ìˆ˜ë™ ì„¤ì •"
    
    print(f"\nğŸ“Š ì‚¬ìš© ì¤‘ì¸ ì„¤ì •ê°’ ({mode_name}):")
    print(f"   - ë§ˆì´í¬ ê°ë„: {MIC_GAIN:.1f}x")
    print(f"   - ë¬´ìŒ RMS ì„ê³„ê°’: {SILENCE_RMS_THRESHOLD:.6f}")
    print(f"   - ë¬´ìŒ Max ì„ê³„ê°’: {SILENCE_MAX_THRESHOLD:.6f}")
    print(f"   - ë¬´ìŒ ì²˜ë¦¬ ëª¨ë“œ: {'ì¼œì§' if SILENCE_PROCESSING_MODE else 'êº¼ì§'}")
    if SILENCE_PROCESSING_MODE:
        print(f"     â”” ê°•ì œ ë¬´ìŒ RMS ì„ê³„ê°’: {SILENCE_FORCE_RMS_THRESHOLD:.6f}")
        print(f"     â”” ê°•ì œ ë¬´ìŒ Max ì„ê³„ê°’: {SILENCE_FORCE_MAX_THRESHOLD:.6f}")
    print(f"   - ê³µì¥ ê¸°ì¤€ ë¬´ìŒ ì²˜ë¦¬: {'ì¼œì§' if FACTORY_BASED_SILENCE_MODE else 'êº¼ì§'}")
    if FACTORY_BASED_SILENCE_MODE:
        print(f"     â”” ê³µì¥ ì†Œë¦¬ ë¹„ìœ¨ ì„¤ì •: {FACTORY_SILENCE_RATIO*100:.0f}% ì´í•˜ ë¬´ìŒ ì²˜ë¦¬")
        print(f"     â”” ê³µì¥ ê¸°ì¤€ RMS ì„ê³„ê°’: {FACTORY_SILENCE_RMS_THRESHOLD:.6f}")
        print(f"     â”” ê³µì¥ ê¸°ì¤€ Max ì„ê³„ê°’: {FACTORY_SILENCE_MAX_THRESHOLD:.6f}")
    
    print(f"\nğŸš€ ì‹¤ì‹œê°„ ìœ„í—˜ ì†Œë¦¬ ê°ì§€ ì‹œì‘ (Ctrl+Cë¡œ ì¢…ë£Œ)")
    print("=" * 50)
    
    try:
        while True:
            # ì—…ë°ì´íŠ¸ëœ ì „ì—­ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë…¹ìŒ
            audio, preprocessing_info = record_audio(window_length, SAMPLE_RATE)
            
            print("ğŸ” ë¶„ì„ ì¤‘...")
            analysis_start_time = time.time()
            
            # ì˜ˆì¸¡ ìˆ˜í–‰
            predicted_class, max_prob, frame_predictions, max_frame_idx, rms, max_val = predict_risk(audio, preprocessing_info)
            
            # ì£¼íŒŒìˆ˜ ë¶„ì„ ì •ë³´ ì¶”ê°€
            low_ratio, mid_ratio, high_ratio = analyze_frequency_content(audio)
            
            analysis_end_time = time.time()
            analysis_duration = analysis_end_time - analysis_start_time
            
            # ê²°ê³¼ ì¶œë ¥
            class_name = CLASS_NAMES[predicted_class] if predicted_class < len(CLASS_NAMES) else f"í´ë˜ìŠ¤{predicted_class}"
            class_icon = CLASS_COLORS.get(int(predicted_class), 'â“')
            
            print(f"âœ… ë¶„ì„ ì™„ë£Œ! (ì†Œìš”ì‹œê°„: {analysis_duration:.2f}ì´ˆ)")
            print(f"ì‹œê°„: {time.strftime('%H:%M:%S')}")
            print(f"ì„¤ì • ëª¨ë“œ: {mode_name}")
            print(f"ì˜¤ë””ì˜¤ ë³¼ë¥¨: RMS={rms:.4f}, Max={max_val:.4f}")
            
            # ì „ì²˜ë¦¬ ì •ë³´ ì¶œë ¥
            if preprocessing_info['was_clipped']:
                print("âš ï¸ í´ë¦¬í•‘ ê°ì§€ë¨ - ì‹ ë¢°ë„ ì¡°ì •")
            if preprocessing_info['volume_reduced']:
                print(f"ğŸ”§ ë³¼ë¥¨ ì¡°ì •: {preprocessing_info['original_rms']:.3f} â†’ {preprocessing_info['processed_rms']:.3f}")
            if preprocessing_info.get('was_mic_amplified', False):
                print(f"ğŸ¤ ë§ˆì´í¬ ê°ë„ ì ìš©: {preprocessing_info['mic_gain']:.1f}x")
            
            print(f"ì£¼íŒŒìˆ˜ ë¶„ì„: ì €ìŒ{low_ratio:.2f} | ì¤‘ìŒ{mid_ratio:.2f} | ê³ ìŒ{high_ratio:.2f}")
            print(f"ì˜ˆì¸¡ ê²°ê³¼: {class_icon} {class_name} (í™•ë¥ : {max_prob:.3f})")
            print(f"ê°ì§€ í”„ë ˆì„: {max_frame_idx}")
            
            # ëª¨ë“  í´ë˜ìŠ¤ë³„ í™•ë¥  ì¶œë ¥
            print("í´ë˜ìŠ¤ë³„ í™•ë¥ :")
            for i, prob in enumerate(frame_predictions):
                if i < len(CLASS_NAMES):
                    name = CLASS_NAMES[i]
                    icon = CLASS_COLORS.get(i, 'â“')
                    print(f"  {icon} {name}: {prob:.3f}")
            
            # ìœ„í—˜ ì†Œë¦¬ ê°ì§€ ì—¬ë¶€ íŒë‹¨ (5í´ë˜ìŠ¤: ë¬´ìŒ(0), ì •ìƒ(1)ì´ ì•„ë‹Œ ê²½ìš°ê°€ ìœ„í—˜)
            is_dangerous = predicted_class >= 2 and max_prob > THRESHOLD
            
            if is_dangerous:
                print(f"\nğŸš¨ ìœ„í—˜ ê°ì§€! {class_icon} {class_name} - í™•ë¥ : {max_prob:.3f}")
                print("ğŸ”” ì•Œë¦¼: ì¦‰ì‹œ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤!")
            elif predicted_class == 0:
                print(f"\nğŸ”‡ ìƒíƒœ: ë¬´ìŒ")
            elif predicted_class == 1:
                print(f"\nâœ… ìƒíƒœ: ì •ìƒ")
            else:
                print(f"\nâš ï¸ ìƒíƒœ: {class_name} ê°ì§€ë¨ (ì„ê³„ê°’ ë¯¸ë§Œ)")
            
            print("-" * 50)
            
            # ë¶„ì„ ì™„ë£Œ í›„ ëŒ€ê¸° ì‹œê°„
            if wait_time_between_recordings > 0:
                print(f"â±ï¸ {wait_time_between_recordings:.1f}ì´ˆ ëŒ€ê¸° í›„ ë‹¤ìŒ ë…¹ìŒ ì‹œì‘...")
                time.sleep(wait_time_between_recordings)
            else:
                print("â±ï¸ ì¦‰ì‹œ ë‹¤ìŒ ë…¹ìŒ ì‹œì‘...")
                
    except KeyboardInterrupt:
        print("\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        
        # ì„¤ì •ê°’ ë³µì›
        MIC_GAIN = original_mic_gain
        SILENCE_RMS_THRESHOLD = original_silence_rms
        SILENCE_MAX_THRESHOLD = original_silence_max
        SILENCE_FORCE_RMS_THRESHOLD = original_force_rms
        SILENCE_FORCE_MAX_THRESHOLD = original_force_max
        FACTORY_SILENCE_RMS_THRESHOLD = original_factory_rms
        FACTORY_SILENCE_MAX_THRESHOLD = original_factory_max

if __name__ == '__main__':
    main()