"""
í™˜ê²½ìŒ ë¶„ë¥˜ ëª¨ë¸ í‰ê°€ ëª¨ë“ˆ (ë³µì›ëœ ë²„ì „)
"""
import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import tensorflow as tf
from tensorflow import keras
import librosa
from tqdm import tqdm
import json
from datetime import datetime
import warnings
import glob

import config
from config import CLASS_NAMES, MODEL_CONFIG, initialize_paths

# ì´ˆê¸°í™”
initialize_paths()

# ì´ˆê¸°í™” í›„ ë³€ìˆ˜ë“¤ ì„í¬íŠ¸
from config import MODEL_SAVE_DIR, DATASET_SAVE_DIR, AUDIO_DATA_DIR, EVALUATION_RESULTS_DIR

warnings.filterwarnings('ignore')

# ì˜ì–´ í´ë˜ìŠ¤ëª… ë¦¬ìŠ¤íŠ¸
CLASS_NAMES_EN_LIST = ['Silence', 'Factory', 'Fire', 'Gas Leak', 'Scream']

class ModelEvaluator:
    """ëª¨ë¸ í‰ê°€ë¥¼ ìœ„í•œ í´ë˜ìŠ¤"""
    
    def __init__(self, model_path=None):
        """
        ì´ˆê¸°í™”
        Args:
            model_path: í‰ê°€í•  ëª¨ë¸ì˜ ê²½ë¡œ
        """
        self.model = None
        self.model_path = model_path
        self.evaluation_results = {}
        
        # í•œê¸€ í°íŠ¸ ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ì˜ì–´ í´ë˜ìŠ¤ëª… ì‚¬ìš©
        plt.rcParams['font.family'] = ['DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
    def load_model(self, model_path=None):
        """ëª¨ë¸ ë¡œë“œ"""
        if model_path:
            self.model_path = model_path
            
        try:
            # ëª¨ë¸ ë¡œë“œ (ì—¬ëŸ¬ ë°©ë²• ì‹œë„)
            try:
                self.model = tf.keras.models.load_model(self.model_path)
            except AttributeError:
                # TensorFlow ë²„ì „ì´ ë‹¤ë¥¸ ê²½ìš°
                from tensorflow.keras.models import load_model
                self.model = load_model(self.model_path)
            print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {self.model_path}")
            return True
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def preprocess_audio_for_yamnet(self, audio_file):
        """YAMNetì„ ìœ„í•œ ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ (í›ˆë ¨ ì‹œì™€ ë™ì¼í•œ ë°©ì‹)"""
        import tensorflow_hub as hub
        
        if not hasattr(self, 'yamnet_model'):
            self.yamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')
        
        # ì˜¤ë””ì˜¤ ë¡œë“œ
        audio, sr = librosa.load(audio_file, sr=16000)
        
        # ì˜¬ë°”ë¥¸ ê¸¸ì´ë¡œ ìë¥´ê±°ë‚˜ íŒ¨ë”©
        target_length = int(MODEL_CONFIG['audio_duration'] * 16000)
        if len(audio) > target_length:
            audio = audio[:target_length]
        else:
            audio = np.pad(audio, (0, target_length - len(audio)))
        
        # TensorFlow í…ì„œë¡œ ë³€í™˜
        audio_tensor = tf.convert_to_tensor(audio, dtype=tf.float32)
        
        # YAMNet íŠ¹ì§• ì¶”ì¶œ
        _, embeddings, _ = self.yamnet_model(audio_tensor)
        
        # í›ˆë ¨ ì‹œì™€ ë™ì¼í•˜ê²Œ ëª¨ë“  ì„ë² ë”© í”„ë ˆì„ ë°˜í™˜
        return embeddings.numpy()
    
    def create_test_dataset(self):
        """í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„± (3-way splitëœ ë°ì´í„° ì‚¬ìš©)"""
        print("ğŸ” í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
        
        # split_dataset_ë²„ì „ëª…_íƒ€ì„ìŠ¤íƒ¬í”„_test.npz í˜•ì‹ì˜ íŒŒì¼ ì°¾ê¸°
        test_files = glob.glob(os.path.join(DATASET_SAVE_DIR, 'split_dataset_*_test.npz'))
        
        if test_files:
            # ê°€ì¥ ìµœê·¼ íŒŒì¼ ì„ íƒ
            latest_test_file = max(test_files, key=os.path.getctime)
            print(f"ğŸ“‚ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì¤‘: {latest_test_file}")
            
            # npz íŒŒì¼ ë¡œë“œ
            test_data = np.load(latest_test_file)
            X_test = test_data['X']
            y_test = test_data['y']
            
            print(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {X_test.shape}")
            return X_test, y_test
        
        print("âŒ ë¯¸ë¦¬ ë¶„í• ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ data_generator.pyë¥¼ í†µí•´ 3-way split ë°ì´í„°ë¥¼ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”.")
        return None, None
    
    def evaluate_model(self, X_test, y_test):
        """ëª¨ë¸ í‰ê°€ ìˆ˜í–‰"""
        if self.model is None:
            print("âŒ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
        
        if X_test is None or y_test is None:
            print("âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        print("ğŸ” ëª¨ë¸ í‰ê°€ ìˆ˜í–‰ ì¤‘...")
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        predictions = self.model.predict(X_test, verbose=0)
        y_pred = np.argmax(predictions, axis=1)
        
        # ì •í™•ë„ ê³„ì‚°
        accuracy = accuracy_score(y_test, y_pred)
        
        # ë¶„ë¥˜ ë¦¬í¬íŠ¸
        report = classification_report(
            y_test, y_pred, 
            target_names=CLASS_NAMES_EN_LIST,
            output_dict=True
        )
        
        # í˜¼ë™ í–‰ë ¬
        cm = confusion_matrix(y_test, y_pred)
        
        self.evaluation_results = {
            'accuracy': accuracy,
            'classification_report': report,
            'confusion_matrix': cm,
            'predictions': predictions,
            'y_true': y_test,
            'y_pred': y_pred
        }
        
        print(f"âœ… ëª¨ë¸ í‰ê°€ ì™„ë£Œ - ì •í™•ë„: {accuracy:.4f}")
        return self.evaluation_results
    
    def plot_confusion_matrix(self, save_path=None):
        """í˜¼ë™ í–‰ë ¬ ì‹œê°í™” (ì˜ì–´ ë²„ì „)"""
        if 'confusion_matrix' not in self.evaluation_results:
            print("âŒ í‰ê°€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € evaluate_modelì„ ì‹¤í–‰í•˜ì„¸ìš”.")
            return
        
        cm = self.evaluation_results['confusion_matrix']
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(
            cm, 
            annot=True, 
            fmt='d', 
            cmap='Blues',
            xticklabels=CLASS_NAMES_EN_LIST,
            yticklabels=CLASS_NAMES_EN_LIST
        )
        plt.title('Confusion Matrix', fontsize=16, fontweight='bold')
        plt.xlabel('Predicted Label', fontsize=12)
        plt.ylabel('True Label', fontsize=12)
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š í˜¼ë™ í–‰ë ¬ ì €ì¥ ì™„ë£Œ: {save_path}")
        
    
    def plot_class_accuracy(self, save_path=None):
        """í´ë˜ìŠ¤ë³„ ì •í™•ë„ ì‹œê°í™” (ì˜ì–´ ë²„ì „)"""
        if 'classification_report' not in self.evaluation_results:
            print("âŒ í‰ê°€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        report = self.evaluation_results['classification_report']
        
        # í´ë˜ìŠ¤ë³„ ì •í™•ë„ ì¶”ì¶œ
        class_accuracies = []
        for class_name in CLASS_NAMES_EN_LIST:
            if class_name in report:
                class_accuracies.append(report[class_name]['f1-score'])
            else:
                class_accuracies.append(0)
        
        plt.figure(figsize=(12, 6))
        bars = plt.bar(CLASS_NAMES_EN_LIST, class_accuracies, 
                      color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'])
        
        plt.title('F1-Score by Class', fontsize=16, fontweight='bold')
        plt.xlabel('Class', fontsize=12)
        plt.ylabel('F1-Score', fontsize=12)
        plt.ylim(0, 1)
        
        # ë§‰ëŒ€ ìœ„ì— ê°’ í‘œì‹œ
        for bar, accuracy in zip(bars, class_accuracies):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{accuracy:.3f}', ha='center', va='bottom', fontweight='bold')
        
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š í´ë˜ìŠ¤ë³„ ì •í™•ë„ ì €ì¥ ì™„ë£Œ: {save_path}")
        
    
    def save_evaluation_report(self, save_dir=None):
        """í‰ê°€ ê²°ê³¼ ì €ì¥"""
        if not self.evaluation_results:
            print("âŒ ì €ì¥í•  í‰ê°€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        if save_dir is None:
            save_dir = EVALUATION_RESULTS_DIR
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = os.path.join(save_dir, f'evaluation_report_{timestamp}.json')
        
        # JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
        report_data = {}
        
        for key, value in self.evaluation_results.items():
            if key == 'confusion_matrix':
                report_data[key] = value.tolist()
            elif key == 'predictions':
                report_data[key] = value.tolist()
            elif key in ['y_true', 'y_pred']:
                report_data[key] = value.tolist()
            else:
                report_data[key] = value
        
        # ëª¨ë¸ ê²½ë¡œì™€ í‰ê°€ ì‹œê°„ ì¶”ê°€
        report_data['model_path'] = self.model_path
        report_data['evaluation_time'] = timestamp
        
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, indent=2, ensure_ascii=False)
            print(f"ğŸ“„ í‰ê°€ ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ: {report_path}")
        except Exception as e:
            print(f"âŒ ë³´ê³ ì„œ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def print_summary(self):
        """í‰ê°€ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        if not self.evaluation_results:
            print("âŒ í‰ê°€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print("\n" + "="*60)
        print("ğŸ“Š ëª¨ë¸ í‰ê°€ ê²°ê³¼ ìš”ì•½")
        print("="*60)
        
        if 'accuracy' in self.evaluation_results:
            print(f"ğŸ¯ ì „ì²´ ì •í™•ë„: {self.evaluation_results['accuracy']:.4f}")
        
        if 'classification_report' in self.evaluation_results:
            report = self.evaluation_results['classification_report']
            print(f"ğŸ“ˆ ë§¤í¬ë¡œ í‰ê·  F1-Score: {report['macro avg']['f1-score']:.4f}")
            print(f"ğŸ“ˆ ê°€ì¤‘ í‰ê·  F1-Score: {report['weighted avg']['f1-score']:.4f}")
        
        print("="*60)

def find_latest_model(model_dir=None):
    """ê°€ì¥ ìµœê·¼ ëª¨ë¸ íŒŒì¼ ì°¾ê¸°"""
    if model_dir is None:
        model_dir = MODEL_SAVE_DIR
    
    # .h5 íŒŒì¼ ê²€ìƒ‰
    model_files = glob.glob(os.path.join(model_dir, "*.h5"))
    
    if not model_files:
        # training í´ë”ì—ì„œë„ ê²€ìƒ‰
        training_dir = os.path.join(os.path.dirname(model_dir), 'training')
        if os.path.exists(training_dir):
            # ë²„ì „ë³„ í´ë”ì—ì„œ ê²€ìƒ‰
            version_dirs = []
            try:
                dirs = os.listdir(training_dir)
                version_dirs = [d for d in dirs if d.startswith('v')]
            except:
                pass
                
            for version_dir in sorted(version_dirs, reverse=True):
                version_path = os.path.join(training_dir, version_dir)
                if os.path.isdir(version_path):
                    version_models = glob.glob(os.path.join(version_path, "*.h5"))
                    if version_models:
                        model_files.extend(version_models)
                        break  # ê°€ì¥ ìµœì‹  ë²„ì „ì—ì„œ ì°¾ìœ¼ë©´ ì¤‘ë‹¨
    
    if not model_files:
        print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_dir}")
        return None
    
    # ê°€ì¥ ìµœê·¼ íŒŒì¼ ë°˜í™˜
    latest_model = max(model_files, key=os.path.getctime)
    print(f"ğŸ“‚ ë°œê²¬ëœ ëª¨ë¸ íŒŒì¼: {latest_model}")
    return latest_model

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ëª¨ë¸ í‰ê°€ ì‹œì‘")
    
    # ëª¨ë¸ ê²½ë¡œ ì°¾ê¸°
    model_path = find_latest_model()
    
    if not model_path:
        print("âŒ í‰ê°€í•  ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í‰ê°€ê¸° ì´ˆê¸°í™”
    evaluator = ModelEvaluator(model_path)
    
    # ëª¨ë¸ ë¡œë“œ
    if not evaluator.load_model():
        return
    
    try:
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±
        X_test, y_test = evaluator.create_test_dataset()
        
        # ëª¨ë¸ í‰ê°€
        results = evaluator.evaluate_model(X_test, y_test)
        
        if results:
            # ê²°ê³¼ ì¶œë ¥
            evaluator.print_summary()
            
            # í‰ê°€ ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ ì„¤ì •
            confusion_matrix_path = os.path.join(EVALUATION_RESULTS_DIR, f'confusion_matrix_{timestamp}.png')
            f1_score_path = os.path.join(EVALUATION_RESULTS_DIR, f'f1_score_by_class_{timestamp}.png')
            
            # ì‹œê°í™” (ì´ë¯¸ì§€ ì €ì¥)
            evaluator.plot_confusion_matrix(save_path=confusion_matrix_path)
            evaluator.plot_class_accuracy(save_path=f1_score_path)
            
            # ë³´ê³ ì„œ ì €ì¥
            evaluator.save_evaluation_report()
            
            print("âœ… ëª¨ë¸ í‰ê°€ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
