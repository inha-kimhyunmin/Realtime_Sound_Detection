"""
YAMNet + LSTM í›ˆë ¨ ì„¤ì • íŒŒì¼
============================

ëª¨ë“  í›ˆë ¨ ê´€ë ¨ ì„¤ì •ì„ ì´ íŒŒì¼ì—ì„œ ê´€ë¦¬í•©ë‹ˆë‹¤.
ê° ë‹¨ê³„ë³„ë¡œ í•„ìš”í•œ ì„¤ì •ë“¤ì„ ì •ì˜í•˜ê³ , ë°ì´í„° ìƒì„±ë¶€í„° ëª¨ë¸ í›ˆë ¨, í‰ê°€ê¹Œì§€ì˜ 
ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ ì¤‘ì•™ì—ì„œ ì œì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""

import os
from datetime import datetime
import json
import numpy as np

# ================================
# ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
# ================================
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
ENVSOUND_DIR = os.path.join(BASE_DIR, 'envsound')
MIXTURE_DIR = os.path.join(BASE_DIR, 'mixture')

# í˜¸í™˜ì„±ì„ ìœ„í•œ AUDIO_DATA_DIR (evaluation.pyì—ì„œ ì‚¬ìš©)
AUDIO_DATA_DIR = ENVSOUND_DIR

# ================================
# í‰ê°€ìš© ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ì„¤ì •
# ================================
EVALUATION_AUDIO_PATHS = {
    'silence': None,  # ë¬´ìŒì€ ìŠ¤í‚µ
    'factory': MIXTURE_DIR,  # ê³µì¥ì†Œë¦¬ëŠ” mixture í´ë”ì—ì„œ
    'fire': os.path.join(ENVSOUND_DIR, 'fire'),
    'gas': os.path.join(ENVSOUND_DIR, 'gas'), 
    'scream': os.path.join(ENVSOUND_DIR, 'scream'),
    'spark': os.path.join(ENVSOUND_DIR, 'spark'),
}

# ê²°ê³¼ ì €ì¥ ê²½ë¡œ - ë²„ì „ë³„ ì²´ê³„ì  ê´€ë¦¬
RESULTS_BASE_DIR = os.path.join(BASE_DIR, 'results')

# ë²„ì „ë³„ í´ë” êµ¬ì¡°
def get_version_dir():
    """í˜„ì¬ ëª¨ë¸ ë²„ì „ì— ë”°ë¥¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ"""
    try:
        version = MODEL_CONFIG['version']
        return os.path.join(RESULTS_BASE_DIR, f"version_{version}")
    except NameError:
        # MODEL_CONFIGê°€ ì•„ì§ ì •ì˜ë˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
        return os.path.join(RESULTS_BASE_DIR, 'version_default')

def get_experiment_dir():
    """ì‹¤í—˜ë³„ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ë²„ì „ + íƒ€ì„ìŠ¤íƒ¬í”„)"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    experiment_name = f"exp_{timestamp}"
    return os.path.join(get_version_dir(), experiment_name)

# ëª¨ë“  ì„¤ì •ì´ ì •ì˜ëœ í›„ ë™ì  ê²½ë¡œ ì´ˆê¸°í™”
def initialize_paths():
    """ëª¨ë“  ì„¤ì •ì´ ì •ì˜ëœ í›„ ê²½ë¡œë“¤ì„ ì´ˆê¸°í™”"""
    global VERSION_DIR, TRAINING_RESULTS_DIR, EVALUATION_RESULTS_DIR
    global MODEL_SAVE_DIR, REPORT_SAVE_DIR, DATASET_SAVE_DIR
    
    VERSION_DIR = get_version_dir()
    TRAINING_RESULTS_DIR = os.path.join(VERSION_DIR, 'training')
    EVALUATION_RESULTS_DIR = os.path.join(VERSION_DIR, 'evaluation')
    MODEL_SAVE_DIR = os.path.join(VERSION_DIR, 'models')
    REPORT_SAVE_DIR = os.path.join(VERSION_DIR, 'reports')
    DATASET_SAVE_DIR = os.path.join(VERSION_DIR, 'datasets')

# ================================
# ëª¨ë¸ ë° í›ˆë ¨ ì„¤ì •
# ================================
MODEL_CONFIG = {
    'version': 'v2.031',                    # ëª¨ë¸ ë²„ì „
    'audio_duration': 10.0,                # ì˜¤ë””ì˜¤ ì…ë ¥ ê¸¸ì´ (ì´ˆ) [5.0 ~ 10.0]
    'sample_rate': 16000,                 # ìƒ˜í”Œë§ ì£¼íŒŒìˆ˜
}

TRAINING_CONFIG = {
    'epochs': 50,                         # í›ˆë ¨ ì—í¬í¬ ìˆ˜
    'batch_size': 16,                     # ë°°ì¹˜ í¬ê¸°
    'learning_rate': 0.001,               # í•™ìŠµë¥ 
    'validation_split': 0.2,              # ê²€ì¦ ë°ì´í„° ë¹„ìœ¨ (ë ˆê±°ì‹œ - train/valë§Œ ì‚¬ìš©ì‹œ)
    'random_seed': 42,                    # ëœë¤ ì‹œë“œ
    'normalize_input': True,              # ì…ë ¥ ì •ê·œí™”
    'use_class_weights': True,            # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì‚¬ìš©
    
    # 3-way ë°ì´í„° ë¶„í•  ì„¤ì • (train/validation/test)
    'data_split': {
        'train_ratio': 0.7,               # í›ˆë ¨ ë°ì´í„° ë¹„ìœ¨ (70%)
        'validation_ratio': 0.15,         # ê²€ì¦ ë°ì´í„° ë¹„ìœ¨ (15%)  
        'test_ratio': 0.15,               # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨ (15%)
        'stratify': True,                 # í´ë˜ìŠ¤ë³„ ê· ë“± ë¶„í• 
        'shuffle': True,                  # ë°ì´í„° ì…”í”Œ
    },
    'dense_units': 256,                   # Dense ë ˆì´ì–´ ìœ ë‹› ìˆ˜
    'lstm_units': 128,                    # LSTM ë ˆì´ì–´ ìœ ë‹› ìˆ˜
    'dropout_rate': 0.3,                  # ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨
    'save_checkpoints': True,             # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
    'early_stopping': {
        'enabled': True,
        'patience': 10
    },
    'learning_rate_schedule': {
        'enabled': True,
        'factor': 0.5,
        'patience': 5,
        'min_lr': 1e-7
    }
}

# ================================
# ì‚¬ìš©í•  ìœ„í—˜ ì†Œë¦¬ í´ë˜ìŠ¤ ì„¤ì •
# ================================
DANGER_CLASSES = {
    'fire': True,        # í™”ì¬ ì†Œë¦¬ ì‚¬ìš© ì—¬ë¶€
    'gas': True,         # ê°€ìŠ¤ëˆ„ì¶œ ì†Œë¦¬ ì‚¬ìš© ì—¬ë¶€
    'scream': True,      # ë¹„ëª… ì†Œë¦¬ ì‚¬ìš© ì—¬ë¶€
}

# í´ë˜ìŠ¤ ì •ë³´ ìë™ ìƒì„±
BASE_CLASSES = ['silence', 'factory']
ACTIVE_DANGER_CLASSES = [name for name, enabled in DANGER_CLASSES.items() if enabled]
ALL_CLASSES = BASE_CLASSES + ACTIVE_DANGER_CLASSES
NUM_CLASSES = len(ALL_CLASSES)

CLASS_NAMES = {
    'silence': 'ë¬´ìŒ',
    'factory': 'ì •ìƒ(ê³µì¥)',
    'fire': 'í™”ì¬',
    'gas': 'ê°€ìŠ¤ëˆ„ì¶œ',
    'scream': 'ë¹„ëª…'
}

# ì˜ì–´ í´ë˜ìŠ¤ ì´ë¦„ (ì°¨íŠ¸ ë° ê·¸ë˜í”„ìš©)
CLASS_NAMES_EN = {
    'silence': 'Silence',
    'factory': 'Factory',
    'fire': 'Fire',
    'gas': 'Gas Leak',
    'scream': 'Scream'
}

# ================================
# ë°ì´í„° ì¦ê°• ì„¤ì •
# ================================
AUGMENTATION_CONFIG = {
    'silence': {
        'enabled': True,
        'methods': ['noise_variation', 'volume_change'],
        'noise_types': ['white', 'pink', 'brown'],        # ë…¸ì´ì¦ˆ ì¢…ë¥˜
        'volume_range': (0.1, 0.8),                       # ë³¼ë¥¨ ë²”ìœ„
    },
    'factory': {
        'enabled': True,
        'methods': ['volume_change', 'reverb', 'room_effect', 'speed_change'],
        'volume_range': (0.7, 1.3),                       # ë³¼ë¥¨ ë²”ìœ„
        'reverb_decay': (0.1, 0.5),                       # ë¦¬ë²„ë¸Œ ê°ì‡  ì‹œê°„
        'room_size': (0.1, 0.9),                          # ë£¸ í¬ê¸°
        'speed_range': (0.9, 1.1),                        # ì†ë„ ë³€í™” ë²”ìœ„
    },
    'fire': {
        'enabled': True,
        'methods': ['factory_mix', 'volume_change', 'noise_add'],
        'snr_range': (5, 20),                             # SNR ë²”ìœ„ (dB)
        'volume_range': (0.8, 1.2),                       # ë³¼ë¥¨ ë²”ìœ„
        'noise_level': (0.01, 0.05),                      # ë…¸ì´ì¦ˆ ë ˆë²¨
    },
    'gas': {
        'enabled': True,
        'methods': ['factory_mix', 'volume_change', 'noise_add'],
        'snr_range': (8, 25),                             # SNR ë²”ìœ„ (dB)
        'volume_range': (0.8, 1.2),                       # ë³¼ë¥¨ ë²”ìœ„
        'noise_level': (0.01, 0.05),                      # ë…¸ì´ì¦ˆ ë ˆë²¨
    },
    'scream': {
        'enabled': True,
        'methods': ['factory_mix', 'volume_change', 'reverb', 'room_effect'],
        'snr_range': (10, 30),                            # SNR ë²”ìœ„ (dB)
        'volume_range': (0.7, 1.3),                       # ë³¼ë¥¨ ë²”ìœ„
        'room_size': (0.1, 0.9),                          # ë£¸ í¬ê¸°
        'reverb_decay': (0.1, 0.3),                       # ë¦¬ë²„ë¸Œ ê°ì‡  ì‹œê°„
    }
}

# ================================
# ì „í™˜ ë°ì´í„° ì„¤ì •
# ================================
TRANSITION_CONFIG = {
    'enabled': True,
    'fade_duration': 0.2,                                 # í˜ì´ë“œ ì „í™˜ ì‹œê°„ (ì´ˆ)
    
    # ì „í™˜ íƒ€ì…ë³„ ì„¤ì •
    'types': {
        'silence_to_silence': {
            'enabled': True,
            'description': 'ë¬´ìŒ â†’ ë‹¤ë¥¸ ë¬´ìŒ (ë°°ê²½ë…¸ì´ì¦ˆ ë³€í™”)',
            'transition_point_range': (0.2, 0.8),         # ì „í™˜ ì‹œì  ë²”ìœ„ (ë¹„ìœ¨)
            'weight': 1.0,                                 # ìƒì„± ê°€ì¤‘ì¹˜
        },
        'silence_to_factory': {
            'enabled': True,
            'description': 'ë¬´ìŒ â†’ ê³µì¥ì†Œë¦¬ (ê¸°ê³„ ì‹œì‘)',
            'transition_point_range': (0.2, 0.7),         # ì „í™˜ ì‹œì  ë²”ìœ„
            'weight': 1.5,                                 # ìƒì„± ê°€ì¤‘ì¹˜
        },
        'silence_to_danger': {
            'enabled': True,
            'description': 'ë¬´ìŒ â†’ ìœ„í—˜ì†Œë¦¬ (ê¸´ê¸‰ìƒí™©)',
            'transition_point_range': (0.1, 0.6),         # ì „í™˜ ì‹œì  ë²”ìœ„
            'weight': 2.0,                                 # ìƒì„± ê°€ì¤‘ì¹˜
        },
        'factory_to_factory': {
            'enabled': True,
            'description': 'ê³µì¥ì†Œë¦¬ â†’ ë‹¤ë¥¸ ê³µì¥ì†Œë¦¬ (ê¸°ê³„ ë³€ê²½)',
            'transition_point_range': (0.3, 0.7),         # ì „í™˜ ì‹œì  ë²”ìœ„
            'weight': 1.0,                                 # ìƒì„± ê°€ì¤‘ì¹˜
        },
        'factory_to_danger': {
            'enabled': True,
            'description': 'ê³µì¥ì†Œë¦¬ â†’ ìœ„í—˜ì†Œë¦¬ (ì‚¬ê³  ë°œìƒ)',
            'transition_point_range': (0.2, 0.8),         # ì „í™˜ ì‹œì  ë²”ìœ„
            'danger_volume_ratio': (0.8, 1.5),            # ìœ„í—˜ì†Œë¦¬ ë³¼ë¥¨ ë¹„ìœ¨
            'weight': 3.0,                                 # ìƒì„± ê°€ì¤‘ì¹˜ (ê°€ì¥ ì¤‘ìš”)
        }
    }
}

# ================================
# ë°ì´í„° ìƒì„± ëª©í‘œ ì„¤ì •
# ================================
DATA_GENERATION_CONFIG = {
    'target_frames_per_class': 1000,                      # í´ë˜ìŠ¤ë‹¹ ëª©í‘œ í”„ë ˆì„ ìˆ˜ (ìˆ˜ì •: 2000 â†’ 1000)
    'min_frames_for_augmentation': 500,                   # ë°ì´í„° ì¦ê°• ì‹œì‘ ì„ê³„ê°’
    'transition_data_ratio': 0.2,                         # ì „í™˜ ë°ì´í„° ë¹„ìœ¨ (ì „ì²´ì˜ 20%)
    'auto_balance': True,                                  # ìë™ í´ë˜ìŠ¤ ê· í˜• ì¡°ì •
    'allow_user_input': True,                             # ì‚¬ìš©ì ì…ë ¥ í—ˆìš© (ìˆ˜ì •: True â†’ False)
}

# ================================
# ì¶œë ¥ ë° ë¡œê¹… ì„¤ì •
# ================================
OUTPUT_CONFIG = {
    'verbose': True,                                       # ìƒì„¸ ì¶œë ¥ ì—¬ë¶€
    'save_dataset_info': True,                            # ë°ì´í„°ì…‹ ì •ë³´ ì €ì¥
    'save_model_summary': True,                           # ëª¨ë¸ ìš”ì•½ ì €ì¥
    'save_training_history': True,                        # í›ˆë ¨ íˆìŠ¤í† ë¦¬ ì €ì¥
    'save_confusion_matrix': True,                        # í˜¼ë™í–‰ë ¬ ì €ì¥
    'save_classification_report': True,                   # ë¶„ë¥˜ ë³´ê³ ì„œ ì €ì¥
    'plot_training_curves': True,                         # í›ˆë ¨ ê³¡ì„  ê·¸ë˜í”„ ì €ì¥
    'plot_confusion_matrix': True,                        # í˜¼ë™í–‰ë ¬ ì‹œê°í™” ì €ì¥
}

# ================================
# ê³„ì‚°ëœ ì„¤ì •ê°’ë“¤ (ìë™ ìƒì„±)
# ================================
def get_audio_frames_count(duration=None):
    """ì˜¤ë””ì˜¤ ê¸¸ì´ì— ë”°ë¥¸ YAMNet í”„ë ˆì„ ìˆ˜ ê³„ì‚°"""
    if duration is None:
        duration = MODEL_CONFIG['audio_duration']
    # YAMNetì€ 0.48ì´ˆë§ˆë‹¤ í•˜ë‚˜ì˜ í”„ë ˆì„ ìƒì„±
    return int(duration / 0.48)

def get_transition_frame_counts():
    """ì „í™˜ ë°ì´í„°ë¡œ ìƒì„±ë  í”„ë ˆì„ ìˆ˜ ê³„ì‚°"""
    if not TRANSITION_CONFIG['enabled']:
        return {}
    
    total_frames = get_audio_frames_count()
    transition_counts = {}
    
    for trans_type, config in TRANSITION_CONFIG['types'].items():
        if config['enabled']:
            # ì „í™˜ ë°ì´í„°ëŠ” ì „ì²´ ê¸¸ì´ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ full frame count
            transition_counts[trans_type] = total_frames * config['weight']
    
    return transition_counts

def get_recommended_samples():
    """ê¶Œì¥ ìƒ˜í”Œ ìˆ˜ ê³„ì‚°"""
    target_frames = DATA_GENERATION_CONFIG['target_frames_per_class']
    frames_per_audio = get_audio_frames_count()
    
    # ê¸°ë³¸ ë°ì´í„° í•„ìš” ìƒ˜í”Œ ìˆ˜
    base_samples_needed = target_frames // frames_per_audio
    
    # ì „í™˜ ë°ì´í„°ë¡œ ì–»ì„ ìˆ˜ ìˆëŠ” í”„ë ˆì„ ìˆ˜ ê³ ë ¤
    transition_frames = get_transition_frame_counts()
    total_transition_frames = sum(transition_frames.values()) if transition_frames else 0
    
    # ì „í™˜ ë°ì´í„° ë¹„ìœ¨ ê³ ë ¤
    transition_ratio = DATA_GENERATION_CONFIG['transition_data_ratio']
    transition_contribution = total_transition_frames * transition_ratio
    
    # ì‹¤ì œ í•„ìš”í•œ ê¸°ë³¸ ìƒ˜í”Œ ìˆ˜
    actual_samples_needed = max(1, int((target_frames - transition_contribution) // frames_per_audio))
    
    return {
        'frames_per_audio': frames_per_audio,
        'target_frames_per_class': target_frames,
        'base_samples_needed': base_samples_needed,
        'transition_contribution': transition_contribution,
        'recommended_samples': actual_samples_needed,
        'total_classes': NUM_CLASSES,
        'active_classes': ALL_CLASSES
    }

def create_output_directories():
    """ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„± - ë²„ì „ë³„ ì²´ê³„ì  êµ¬ì¡°"""
    directories = [
        RESULTS_BASE_DIR,
        VERSION_DIR,
        TRAINING_RESULTS_DIR,
        EVALUATION_RESULTS_DIR,
        MODEL_SAVE_DIR,
        REPORT_SAVE_DIR,
        DATASET_SAVE_DIR
    ]
    
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
    
    # ì‹¤í—˜ ê¸°ë¡ íŒŒì¼ ìƒì„±
    create_experiment_log()

def create_experiment_log():
    """ì‹¤í—˜ ë¡œê·¸ íŒŒì¼ ìƒì„± ë° ì—…ë°ì´íŠ¸"""
    log_file = os.path.join(VERSION_DIR, 'experiment_log.txt')
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    # ì‹¤í—˜ ì •ë³´ ìˆ˜ì§‘
    experiment_info = f"""
========================================
ì‹¤í—˜ ì‹œì‘: {timestamp}
ëª¨ë¸ ë²„ì „: {MODEL_CONFIG['version']}
ì˜¤ë””ì˜¤ ê¸¸ì´: {MODEL_CONFIG['audio_duration']}ì´ˆ
í›ˆë ¨ ì—í¬í¬: {TRAINING_CONFIG['epochs']}
ë°°ì¹˜ í¬ê¸°: {TRAINING_CONFIG['batch_size']}
í•™ìŠµë¥ : {TRAINING_CONFIG['learning_rate']}
ëª©í‘œ í”„ë ˆì„/í´ë˜ìŠ¤: {DATA_GENERATION_CONFIG['target_frames_per_class']}
í™œì„± í´ë˜ìŠ¤: {', '.join(ALL_CLASSES)}
========================================
"""
    
    # ë¡œê·¸ íŒŒì¼ì— ì¶”ê°€
    with open(log_file, 'a', encoding='utf-8') as f:
        f.write(experiment_info)

def get_experiment_save_path(file_type='model', custom_name=None):
    """ì‹¤í—˜ë³„ ì €ì¥ ê²½ë¡œ ìƒì„±"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    version = MODEL_CONFIG['version']
    
    if custom_name:
        base_name = custom_name
    else:
        base_name = f"yamnet_lstm_{version}_{timestamp}"
    
    if file_type == 'model':
        return os.path.join(MODEL_SAVE_DIR, f"{base_name}.h5")
    elif file_type == 'dataset':
        return os.path.join(DATASET_SAVE_DIR, f"dataset_{base_name}.npz")
    elif file_type == 'dataset_info':
        return os.path.join(DATASET_SAVE_DIR, f"dataset_info_{base_name}.json")
    elif file_type == 'training_report':
        return os.path.join(REPORT_SAVE_DIR, f"training_report_{base_name}.json")
    elif file_type == 'evaluation_report':
        return os.path.join(REPORT_SAVE_DIR, f"evaluation_report_{base_name}.md")
    elif file_type == 'experiment_summary':
        return os.path.join(VERSION_DIR, f"experiment_summary_{timestamp}.json")
    else:
        return os.path.join(REPORT_SAVE_DIR, f"{file_type}_{base_name}")

def save_experiment_summary(results_dict):
    """ì‹¤í—˜ ê²°ê³¼ ìš”ì•½ ì €ì¥"""
    summary_path = get_experiment_save_path('experiment_summary')
    
    summary = {
        'experiment_info': {
            'timestamp': datetime.now().isoformat(),
            'version': MODEL_CONFIG['version'],
            'config': {
                'model_config': MODEL_CONFIG,
                'training_config': TRAINING_CONFIG,
                'data_generation_config': DATA_GENERATION_CONFIG
            }
        },
        'results': results_dict
    }
    
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“‹ ì‹¤í—˜ ìš”ì•½ ì €ì¥: {summary_path}")
    return summary_path

def get_model_save_path():
    """ëª¨ë¸ ì €ì¥ ê²½ë¡œ ìƒì„±"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    model_name = f"yamnet_lstm_{MODEL_CONFIG['version']}_{timestamp}"
    return os.path.join(MODEL_SAVE_DIR, f"{model_name}.h5")

def get_report_save_path():
    """ë³´ê³ ì„œ ì €ì¥ ê²½ë¡œ ìƒì„±"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_name = f"training_report_{MODEL_CONFIG['version']}_{timestamp}"
    return os.path.join(REPORT_SAVE_DIR, f"{report_name}.txt")

def get_dataset_save_path():
    """ë°ì´í„°ì…‹ ì €ì¥ ê²½ë¡œ ìƒì„±"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    dataset_name = f"dataset_info_{MODEL_CONFIG['version']}_{timestamp}"
    return os.path.join(DATASET_SAVE_DIR, f"{dataset_name}.json")

# ================================
# ì„¤ì • ê²€ì¦ í•¨ìˆ˜
# ================================
def validate_config():
    """ì„¤ì •ê°’ ê²€ì¦"""
    errors = []
    
    # ì˜¤ë””ì˜¤ ê¸¸ì´ ê²€ì¦
    if not (5.0 <= MODEL_CONFIG['audio_duration'] <= 10.0):
        errors.append("audio_durationì€ 5.0~10.0 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.")
    
    # ìœ„í—˜ í´ë˜ìŠ¤ ìµœì†Œ í•˜ë‚˜ í™œì„±í™” ê²€ì¦
    if not any(DANGER_CLASSES.values()):
        errors.append("ìµœì†Œ í•˜ë‚˜ì˜ ìœ„í—˜ í´ë˜ìŠ¤ëŠ” í™œì„±í™”ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
    
    # ê²½ë¡œ ì¡´ì¬ ì—¬ë¶€ ê²€ì¦
    if not os.path.exists(ENVSOUND_DIR):
        errors.append(f"envsound í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {ENVSOUND_DIR}")
    
    if not os.path.exists(MIXTURE_DIR):
        errors.append(f"mixture í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {MIXTURE_DIR}")
    
    # ì „í™˜ ë°ì´í„° ê°€ì¤‘ì¹˜ ê²€ì¦
    if TRANSITION_CONFIG['enabled']:
        total_weight = sum(config['weight'] for config in TRANSITION_CONFIG['types'].values() if config['enabled'])
        if total_weight == 0:
            errors.append("í™œì„±í™”ëœ ì „í™˜ íƒ€ì…ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # ë°ì´í„° ë¶„í•  ë¹„ìœ¨ ê²€ì¦
    split_config = TRAINING_CONFIG['data_split']
    total_ratio = split_config['train_ratio'] + split_config['validation_ratio'] + split_config['test_ratio']
    if abs(total_ratio - 1.0) > 0.001:
        errors.append(f"ë°ì´í„° ë¶„í•  ë¹„ìœ¨ì˜ í•©ì´ 1.0ì´ ì•„ë‹™ë‹ˆë‹¤: {total_ratio:.3f}")
    
    if split_config['train_ratio'] <= 0 or split_config['validation_ratio'] <= 0 or split_config['test_ratio'] <= 0:
        errors.append("ëª¨ë“  ë°ì´í„° ë¶„í•  ë¹„ìœ¨ì€ 0ë³´ë‹¤ ì»¤ì•¼ í•©ë‹ˆë‹¤.")
    
    return errors

def split_dataset_3way(X, y, random_seed=None):
    """ë°ì´í„°ë¥¼ train/validation/testë¡œ 3-way ë¶„í•  (ì¤‘ë³µ ì—†ìŒ)"""
    from sklearn.model_selection import train_test_split
    
    if random_seed is None:
        random_seed = TRAINING_CONFIG['random_seed']
    
    split_config = TRAINING_CONFIG['data_split']
    train_ratio = split_config['train_ratio']
    val_ratio = split_config['validation_ratio'] 
    test_ratio = split_config['test_ratio']
    stratify = split_config['stratify']
    shuffle = split_config['shuffle']
    
    print(f"ğŸ“Š ë°ì´í„° 3-way ë¶„í•  (Train:{train_ratio:.1%} / Val:{val_ratio:.1%} / Test:{test_ratio:.1%})")
    print(f"  - ì´ ë°ì´í„°: {len(X):,}ê°œ")
    
    # 1ë‹¨ê³„: Train + Validation vs Test ë¶„í• 
    train_val_ratio = train_ratio + val_ratio  # ë‚¨ì€ ë¹„ìœ¨
    test_size_step1 = test_ratio
    
    stratify_step1 = y if stratify else None
    
    X_train_val, X_test, y_train_val, y_test = train_test_split(
        X, y,
        test_size=test_size_step1,
        random_state=random_seed,
        stratify=stratify_step1,
        shuffle=shuffle
    )
    
    # 2ë‹¨ê³„: Train vs Validation ë¶„í• 
    val_size_step2 = val_ratio / train_val_ratio  # train_val ë‚´ì—ì„œì˜ validation ë¹„ìœ¨
    
    stratify_step2 = y_train_val if stratify else None
    
    X_train, X_val, y_train, y_val = train_test_split(
        X_train_val, y_train_val,
        test_size=val_size_step2,
        random_state=random_seed + 1,  # ë‹¤ë¥¸ ì‹œë“œ ì‚¬ìš©
        stratify=stratify_step2,
        shuffle=shuffle
    )
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"  - Train: {len(X_train):,}ê°œ ({len(X_train)/len(X):.1%})")
    print(f"  - Validation: {len(X_val):,}ê°œ ({len(X_val)/len(X):.1%})")
    print(f"  - Test: {len(X_test):,}ê°œ ({len(X_test)/len(X):.1%})")
    
    # í´ë˜ìŠ¤ë³„ ë¶„í¬ í™•ì¸
    if hasattr(y, '__iter__'):
        print(f"\nğŸ“ˆ í´ë˜ìŠ¤ë³„ ë¶„í¬ í™•ì¸:")
        unique_classes = np.unique(y)
        for class_idx in unique_classes:
            train_count = np.sum(y_train == class_idx)
            val_count = np.sum(y_val == class_idx)
            test_count = np.sum(y_test == class_idx)
            total_count = train_count + val_count + test_count
            
            class_name = ALL_CLASSES[class_idx] if class_idx < len(ALL_CLASSES) else f"Class_{class_idx}"
            print(f"  - {class_name}: Train {train_count}, Val {val_count}, Test {test_count} (ì´ {total_count})")
    
    return X_train, X_val, X_test, y_train, y_val, y_test

def save_dataset_splits(X_train, X_val, X_test, y_train, y_val, y_test, base_name=None):
    """ë¶„í• ëœ ë°ì´í„°ì…‹ì„ ê°œë³„ íŒŒì¼ë¡œ ì €ì¥"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    if base_name is None:
        base_name = f"split_dataset_{MODEL_CONFIG['version']}_{timestamp}"
    
    # ê° ë¶„í• ì„ ê°œë³„ íŒŒì¼ë¡œ ì €ì¥
    train_path = os.path.join(DATASET_SAVE_DIR, f"{base_name}_train.npz")
    val_path = os.path.join(DATASET_SAVE_DIR, f"{base_name}_val.npz")
    test_path = os.path.join(DATASET_SAVE_DIR, f"{base_name}_test.npz")
    
    np.savez_compressed(train_path, X=X_train, y=y_train)
    np.savez_compressed(val_path, X=X_val, y=y_val)
    np.savez_compressed(test_path, X=X_test, y=y_test)
    
    # ë©”íƒ€ë°ì´í„° ì €ì¥
    metadata = {
        'split_info': {
            'train_ratio': TRAINING_CONFIG['data_split']['train_ratio'],
            'validation_ratio': TRAINING_CONFIG['data_split']['validation_ratio'],
            'test_ratio': TRAINING_CONFIG['data_split']['test_ratio'],
            'stratify': TRAINING_CONFIG['data_split']['stratify'],
            'random_seed': TRAINING_CONFIG['random_seed']
        },
        'data_counts': {
            'train': len(X_train),
            'validation': len(X_val),
            'test': len(X_test),
            'total': len(X_train) + len(X_val) + len(X_test)
        },
        'files': {
            'train': train_path,
            'validation': val_path,
            'test': test_path
        },
        'creation_time': datetime.now().isoformat(),
        'model_version': MODEL_CONFIG['version']
    }
    
    metadata_path = os.path.join(DATASET_SAVE_DIR, f"{base_name}_metadata.json")
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ’¾ ë¶„í• ëœ ë°ì´í„°ì…‹ ì €ì¥:")
    print(f"  - Train: {train_path}")
    print(f"  - Validation: {val_path}")
    print(f"  - Test: {test_path}")
    print(f"  - Metadata: {metadata_path}")
    
    return {
        'train': train_path,
        'validation': val_path,
        'test': test_path,
        'metadata': metadata_path
    }

def print_config_summary():
    """ì„¤ì • ìš”ì•½ ì¶œë ¥"""
    # ê²½ë¡œ ì´ˆê¸°í™” í™•ì¸
    if 'MODEL_SAVE_DIR' not in globals():
        initialize_paths()
    
    print("=" * 60)
    print("ğŸ”§ YAMNet + LSTM í›ˆë ¨ ì„¤ì • ìš”ì•½")
    print("=" * 60)
    
    print(f"ğŸ“± ëª¨ë¸ ë²„ì „: {MODEL_CONFIG['version']}")
    print(f"ğŸµ ì˜¤ë””ì˜¤ ê¸¸ì´: {MODEL_CONFIG['audio_duration']}ì´ˆ")
    print(f"ğŸ“Š ì´ í´ë˜ìŠ¤ ìˆ˜: {NUM_CLASSES}ê°œ")
    print(f"ğŸ¯ í™œì„± í´ë˜ìŠ¤: {', '.join(ALL_CLASSES)}")
    
    print(f"\nğŸ“ˆ í›ˆë ¨ ì„¤ì •:")
    print(f"  - ì—í¬í¬: {TRAINING_CONFIG['epochs']}")
    print(f"  - ë°°ì¹˜ í¬ê¸°: {TRAINING_CONFIG['batch_size']}")
    print(f"  - í•™ìŠµë¥ : {TRAINING_CONFIG['learning_rate']}")
    
    # ë°ì´í„° ë¶„í•  ë¹„ìœ¨ ì •ë³´ ì¶”ê°€
    split_config = TRAINING_CONFIG['data_split']
    print(f"\nğŸ“Š ë°ì´í„° ë¶„í•  ë¹„ìœ¨:")
    print(f"  - Train: {split_config['train_ratio']:.1%}")
    print(f"  - Validation: {split_config['validation_ratio']:.1%}")
    print(f"  - Test: {split_config['test_ratio']:.1%}")
    print(f"  - í´ë˜ìŠ¤ë³„ ê· ë“±ë¶„í• : {'âœ…' if split_config['stratify'] else 'âŒ'}")
    print(f"  - ë°ì´í„° ì…”í”Œ: {'âœ…' if split_config['shuffle'] else 'âŒ'}")
    
    print(f"\nğŸ”„ ë°ì´í„° ì¦ê°• í™œì„±í™”:")
    for class_name, config in AUGMENTATION_CONFIG.items():
        if class_name in ALL_CLASSES and config['enabled']:
            methods = ', '.join(config['methods'])
            print(f"  - {class_name}: {methods}")
    
    print(f"\nâ†”ï¸ ì „í™˜ ë°ì´í„° ì„¤ì •:")
    if TRANSITION_CONFIG['enabled']:
        for trans_type, config in TRANSITION_CONFIG['types'].items():
            if config['enabled']:
                print(f"  - {config['description']}: ê°€ì¤‘ì¹˜ {config['weight']}")
    else:
        print("  - ë¹„í™œì„±í™”")
    
    print(f"\nğŸ’¾ ì¶œë ¥ ê²½ë¡œ:")
    print(f"  - ëª¨ë¸: {MODEL_SAVE_DIR}")
    print(f"  - ë³´ê³ ì„œ: {REPORT_SAVE_DIR}")
    print(f"  - ë°ì´í„°ì…‹: {DATASET_SAVE_DIR}")
    
    print(f"\nğŸµ í‰ê°€ìš© ì˜¤ë””ì˜¤ ê²½ë¡œ:")
    for class_name, path in EVALUATION_AUDIO_PATHS.items():
        if path is not None:
            status = "âœ…" if os.path.exists(path) else "âŒ"
            print(f"  - {class_name}: {status} {path}")
        else:
            print(f"  - {class_name}: â­ï¸ ìŠ¤í‚µ")
    
    print("=" * 60)

if __name__ == "__main__":
    # ì„¤ì • ê²€ì¦
    errors = validate_config()
    if errors:
        print("âŒ ì„¤ì • ì˜¤ë¥˜:")
        for error in errors:
            print(f"  - {error}")
    else:
        print("âœ… ì„¤ì • ê²€ì¦ ì™„ë£Œ")
        
    # ì„¤ì • ìš”ì•½ ì¶œë ¥
    print_config_summary()
    
    # ê¶Œì¥ ìƒ˜í”Œ ìˆ˜ ì¶œë ¥
    recommendations = get_recommended_samples()
    print(f"\nğŸ“Š ê¶Œì¥ ë°ì´í„° êµ¬ì„±:")
    print(f"  - ì˜¤ë””ì˜¤ë‹¹ í”„ë ˆì„ ìˆ˜: {recommendations['frames_per_audio']}")
    print(f"  - í´ë˜ìŠ¤ë‹¹ ëª©í‘œ í”„ë ˆì„: {recommendations['target_frames_per_class']}")
    print(f"  - ê¶Œì¥ ê¸°ë³¸ ìƒ˜í”Œ ìˆ˜: {recommendations['recommended_samples']}ê°œ/í´ë˜ìŠ¤")

    print(f"  - ì „í™˜ ë°ì´í„° ê¸°ì—¬ë¶„: {recommendations['transition_contribution']:.0f} í”„ë ˆì„")

# ëª¨ë“  ì„¤ì •ì´ ì •ì˜ëœ í›„ ê²½ë¡œ ì´ˆê¸°í™”
initialize_paths()

def update_evaluation_path(class_name, new_path):
    """í‰ê°€ìš© ì˜¤ë””ì˜¤ ê²½ë¡œ ì—…ë°ì´íŠ¸"""
    global EVALUATION_AUDIO_PATHS
    if class_name in EVALUATION_AUDIO_PATHS:
        EVALUATION_AUDIO_PATHS[class_name] = new_path
        print(f"âœ… {class_name} í´ë˜ìŠ¤ ê²½ë¡œ ì—…ë°ì´íŠ¸: {new_path}")
    else:
        print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” í´ë˜ìŠ¤: {class_name}")

def get_evaluation_path(class_name):
    """íŠ¹ì • í´ë˜ìŠ¤ì˜ í‰ê°€ìš© ì˜¤ë””ì˜¤ ê²½ë¡œ ë°˜í™˜"""
    return EVALUATION_AUDIO_PATHS.get(class_name, os.path.join(ENVSOUND_DIR, class_name))

def print_evaluation_paths():
    """í‰ê°€ìš© ê²½ë¡œ í™•ì¸ ë° ì¶œë ¥"""
    print(f"\nğŸµ í‰ê°€ìš© ì˜¤ë””ì˜¤ ê²½ë¡œ í™•ì¸:")
    for class_name, path in EVALUATION_AUDIO_PATHS.items():
        if path is not None:
            exists = os.path.exists(path)
            status = "âœ…" if exists else "âŒ"
            if exists:
                file_count = len([f for f in os.listdir(path) 
                                if f.endswith(('.wav', '.mp3', '.flac'))]) if os.path.isdir(path) else 0
                print(f"  {status} {class_name}: {path} ({file_count}ê°œ íŒŒì¼)")
            else:
                print(f"  {status} {class_name}: {path} (ê²½ë¡œ ì—†ìŒ)")
        else:
            print(f"  â­ï¸ {class_name}: ìŠ¤í‚µ")
