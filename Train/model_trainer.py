"""
ëª¨ë¸ í›ˆë ¨ ëª¨ë“ˆ
=============

ì´ ëª¨ë“ˆì€ YAMNet + LSTM ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤.
- ìƒì„±ëœ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ í›ˆë ¨
- ëª¨ë¸ ì•„í‚¤í…ì²˜ ì •ì˜ ë° ì»´íŒŒì¼
- í›ˆë ¨ ê³¼ì • ëª¨ë‹ˆí„°ë§ ë° ì²´í¬í¬ì¸íŠ¸
- ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ë° ì €ì¥
"""

import os
import json
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight
import matplotlib.pyplot as plt
try:
    import seaborn as sns
    HAS_SEABORN = True
except ImportError:
    HAS_SEABORN = False
from tqdm import tqdm
from datetime import datetime
from config import *

class ModelTrainer:
    def __init__(self):
        """ëª¨ë¸ í›ˆë ¨ê¸° ì´ˆê¸°í™”"""
        self.model = None
        self.history = None
        self.class_weights = None
        self.training_info = {
            'start_time': None,
            'end_time': None,
            'config': TRAINING_CONFIG.copy(),
            'model_config': MODEL_CONFIG.copy(),
            'performance': {}
        }
        
    def load_dataset(self, data_path, dataset_info_path=None):
        """ìƒì„±ëœ ë°ì´í„°ì…‹ ë¡œë“œ"""
        print("ğŸ“‚ ë°ì´í„°ì…‹ ë¡œë”© ì¤‘...")
        
        if not os.path.exists(data_path):
            raise FileNotFoundError(f"ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {data_path}")
        
        # ë°ì´í„° ë¡œë“œ
        data = np.load(data_path)
        X = data['X']
        y = data['y']
        
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ:")
        print(f"  - ì„ë² ë”© í˜•íƒœ: {X.shape}")
        print(f"  - ë¼ë²¨ í˜•íƒœ: {y.shape}")
        
        # ë°ì´í„°ì…‹ ì •ë³´ ë¡œë“œ (ìˆëŠ” ê²½ìš°)
        if dataset_info_path and os.path.exists(dataset_info_path):
            with open(dataset_info_path, 'r', encoding='utf-8') as f:
                dataset_info = json.load(f)
                
            print(f"\nğŸ“Š ë°ì´í„°ì…‹ ì •ë³´:")
            if 'final_stats' in dataset_info:
                for class_name, count in dataset_info['final_stats']['class_distribution'].items():
                    percentage = count / dataset_info['final_stats']['total_frames'] * 100
                    print(f"  - {class_name}: {count:,}ê°œ ({percentage:.1f}%)")
                    
            self.training_info['dataset_info'] = dataset_info
        
        return X, y
    
    def load_presplit_data(self, data_base_name=None):
        """ë¯¸ë¦¬ ë¶„í• ëœ ë°ì´í„° ë¡œë“œ"""
        print("\nğŸ“Š ë¶„í• ëœ ë°ì´í„° ë¡œë”© ì¤‘...")
        
        if data_base_name is None:
            # ê°€ì¥ ìµœê·¼ ë¶„í•  ë°ì´í„° ì°¾ê¸°
            split_files = [f for f in os.listdir(DATASET_SAVE_DIR) 
                          if f.startswith('split_dataset_') and f.endswith('_train.npz')]
            
            if not split_files:
                return None, None, None, None, None, None
            
            # ê°€ì¥ ìµœê·¼ íŒŒì¼ ì°¾ê¸°
            latest_file = max(split_files, key=lambda f: os.path.getmtime(os.path.join(DATASET_SAVE_DIR, f)))
            data_base_name = latest_file.replace('_train.npz', '').replace('split_dataset_', '')
        
        # ë¶„í• ëœ íŒŒì¼ ê²½ë¡œ
        train_path = os.path.join(DATASET_SAVE_DIR, f"split_dataset_{data_base_name}_train.npz")
        val_path = os.path.join(DATASET_SAVE_DIR, f"split_dataset_{data_base_name}_val.npz")
        
        if not (os.path.exists(train_path) and os.path.exists(val_path)):
            print(f"âš ï¸ ë¶„í• ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {train_path}, {val_path}")
            return None, None, None, None, None, None
        
        print(f"ğŸ“‚ Train ë°ì´í„°: {train_path}")
        print(f"ğŸ“‚ Validation ë°ì´í„°: {val_path}")
        
        # ë°ì´í„° ë¡œë“œ
        train_data = np.load(train_path)
        val_data = np.load(val_path)
        
        X_train, y_train = train_data['X'], train_data['y']
        X_val, y_val = val_data['X'], val_data['y']
        
        print(f"  - í›ˆë ¨ ë°ì´í„°: {X_train.shape[0]:,}ê°œ")
        print(f"  - ê²€ì¦ ë°ì´í„°: {X_val.shape[0]:,}ê°œ")
        
        # í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
        print(f"\nğŸ“Š í´ë˜ìŠ¤ë³„ ë¶„í¬:")
        for class_idx in range(NUM_CLASSES):
            train_count = np.sum(y_train == class_idx)
            val_count = np.sum(y_val == class_idx)
            class_name = ALL_CLASSES[class_idx]
            print(f"  - {class_name}: Train {train_count}, Val {val_count}")
        
        return X_train, X_val, y_train, y_val, train_path, val_path

    def prepare_data(self, X, y, use_presplit=True):
        """ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¶„í• """
        print("\nğŸ”„ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        
        # ë¶„í• ëœ ë°ì´í„° ìš°ì„  ì‚¬ìš©
        if use_presplit:
            split_data = self.load_presplit_data()
            if split_data[0] is not None:  # ë¶„í• ëœ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°
                X_train, X_val, y_train, y_val, train_path, val_path = split_data
                print("âœ… ê¸°ì¡´ ë¶„í• ëœ ë°ì´í„° ì‚¬ìš©")
                
                # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° (í›ˆë ¨ ë°ì´í„° ê¸°ì¤€)
                if TRAINING_CONFIG['use_class_weights']:
                    print("  - í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°")
                    unique_classes = np.unique(y_train)
                    class_weights_array = compute_class_weight(
                        'balanced', 
                        classes=unique_classes, 
                        y=y_train
                    )
                    self.class_weights = dict(zip(unique_classes, class_weights_array))
                    
                    print("    í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜:")
                    for class_idx, weight in self.class_weights.items():
                        class_name = ALL_CLASSES[class_idx]
                        print(f"      {class_name}: {weight:.3f}")
                
                # ì›-í•« ì¸ì½”ë”©
                y_train_onehot = keras.utils.to_categorical(y_train, num_classes=NUM_CLASSES)
                y_val_onehot = keras.utils.to_categorical(y_val, num_classes=NUM_CLASSES)
                
                return X_train, X_val, y_train_onehot, y_val_onehot, y_train, y_val
        
        # ê¸°ì¡´ ë°©ì‹: ì „ì²´ ë°ì´í„°ì—ì„œ ë¶„í• 
        print("ğŸ”„ ì „ì²´ ë°ì´í„°ì—ì„œ ë¶„í•  ì§„í–‰")
        
        # ì…ë ¥ ì •ê·œí™”
        if TRAINING_CONFIG['normalize_input']:
            print("  - ì…ë ¥ ë°ì´í„° ì •ê·œí™”")
            X_mean = np.mean(X, axis=0)
            X_std = np.std(X, axis=0)
            X = (X - X_mean) / (X_std + 1e-8)
            
            # ì •ê·œí™” íŒŒë¼ë¯¸í„° ì €ì¥
            self.training_info['normalization'] = {
                'mean': X_mean.tolist(),
                'std': X_std.tolist()
            }
        
        # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
        if TRAINING_CONFIG['use_class_weights']:
            print("  - í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°")
            unique_classes = np.unique(y)
            class_weights_array = compute_class_weight(
                'balanced', 
                classes=unique_classes, 
                y=y
            )
            self.class_weights = dict(zip(unique_classes, class_weights_array))
            
            print("    í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜:")
            for class_idx, weight in self.class_weights.items():
                class_name = ALL_CLASSES[class_idx]
                print(f"      {class_name}: {weight:.3f}")
        
        # í›ˆë ¨/ê²€ì¦ ë°ì´í„° ë¶„í• 
        test_size = TRAINING_CONFIG['validation_split']
        random_state = TRAINING_CONFIG['random_seed']
        
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, 
            test_size=test_size, 
            random_state=random_state,
            stratify=y  # í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€
        )
        
        print(f"  - í›ˆë ¨ ë°ì´í„°: {X_train.shape[0]:,}ê°œ")
        print(f"  - ê²€ì¦ ë°ì´í„°: {X_val.shape[0]:,}ê°œ")
        
        # ì›-í•« ì¸ì½”ë”©
        y_train_onehot = keras.utils.to_categorical(y_train, num_classes=NUM_CLASSES)
        y_val_onehot = keras.utils.to_categorical(y_val, num_classes=NUM_CLASSES)
        
        return X_train, X_val, y_train_onehot, y_val_onehot, y_train, y_val
    
    def create_model(self, input_shape):
        """YAMNet + LSTM ëª¨ë¸ ìƒì„±"""
        print("\nğŸ—ï¸ ëª¨ë¸ ì•„í‚¤í…ì²˜ ìƒì„± ì¤‘...")
        
        model = keras.Sequential([
            layers.Input(shape=input_shape),
            
            # Dense ë ˆì´ì–´ë“¤
            layers.Dense(
                TRAINING_CONFIG['dense_units'], 
                activation='relu',
                name='dense_1'
            ),
            layers.Dropout(TRAINING_CONFIG['dropout_rate']),
            
            layers.Dense(
                TRAINING_CONFIG['dense_units'] // 2, 
                activation='relu',
                name='dense_2'
            ),
            layers.Dropout(TRAINING_CONFIG['dropout_rate']),
            
            # LSTM ë ˆì´ì–´ë¥¼ ìœ„í•œ reshape (sequence length = 1)
            layers.Reshape((1, TRAINING_CONFIG['dense_units'] // 2)),
            
            # LSTM ë ˆì´ì–´ë“¤
            layers.LSTM(
                TRAINING_CONFIG['lstm_units'],
                return_sequences=True,
                dropout=TRAINING_CONFIG['dropout_rate'],
                recurrent_dropout=TRAINING_CONFIG['dropout_rate'],
                name='lstm_1'
            ),
            
            layers.LSTM(
                TRAINING_CONFIG['lstm_units'] // 2,
                return_sequences=False,
                dropout=TRAINING_CONFIG['dropout_rate'],
                recurrent_dropout=TRAINING_CONFIG['dropout_rate'],
                name='lstm_2'
            ),
            
            # ì¶œë ¥ ë ˆì´ì–´
            layers.Dense(NUM_CLASSES, activation='softmax', name='output')
        ])
        
        # ëª¨ë¸ ì»´íŒŒì¼
        optimizer = keras.optimizers.Adam(
            learning_rate=TRAINING_CONFIG['learning_rate']
        )
        
        model.compile(
            optimizer=optimizer,
            loss='categorical_crossentropy',
            metrics=['accuracy', 'precision', 'recall']
        )
        
        # ëª¨ë¸ êµ¬ì¡° ì¶œë ¥
        model.summary()
        
        # ëª¨ë¸ êµ¬ì¡°ë¥¼ ì´ë¯¸ì§€ë¡œ ì €ì¥
        try:
            model_plot_path = os.path.join(TRAINING_RESULTS_DIR, 'model_architecture.png')
            keras.utils.plot_model(
                model, 
                to_file=model_plot_path, 
                show_shapes=True, 
                show_layer_names=True,
                dpi=150
            )
            print(f"ğŸ“Š ëª¨ë¸ êµ¬ì¡° ì €ì¥: {model_plot_path}")
        except ImportError as e:
            if 'pydot' in str(e):
                print(f"âš ï¸ ëª¨ë¸ êµ¬ì¡° ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: pydot íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤")
                print(f"ğŸ’¡ í•´ê²° ë°©ë²•: pip install pydot graphviz")
            else:
                print(f"âš ï¸ ëª¨ë¸ êµ¬ì¡° ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
        except Exception as e:
            print(f"âš ï¸ ëª¨ë¸ êµ¬ì¡° ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
            print(f"ğŸ’¡ Graphvizê°€ ì‹œìŠ¤í…œì— ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
        
        self.model = model
        return model
    
    def create_callbacks(self):
        """í›ˆë ¨ ì½œë°± ìƒì„±"""
        callbacks = []
        
        # ì²´í¬í¬ì¸íŠ¸
        if TRAINING_CONFIG['save_checkpoints']:
            checkpoint_path = os.path.join(
                TRAINING_RESULTS_DIR, 
                'checkpoints', 
                'model_epoch_{epoch:03d}_val_acc_{val_accuracy:.4f}.h5'
            )
            os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)
            
            checkpoint_callback = keras.callbacks.ModelCheckpoint(
                filepath=checkpoint_path,
                monitor='val_accuracy',
                save_best_only=True,
                save_weights_only=False,
                mode='max',
                verbose=1
            )
            callbacks.append(checkpoint_callback)
        
        # ì¡°ê¸° ì¢…ë£Œ
        if TRAINING_CONFIG['early_stopping']['enabled']:
            early_stopping = keras.callbacks.EarlyStopping(
                monitor='val_accuracy',
                patience=TRAINING_CONFIG['early_stopping']['patience'],
                restore_best_weights=True,
                verbose=1
            )
            callbacks.append(early_stopping)
        
        # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§
        if TRAINING_CONFIG['learning_rate_schedule']['enabled']:
            lr_scheduler = keras.callbacks.ReduceLROnPlateau(
                monitor='val_loss',
                factor=TRAINING_CONFIG['learning_rate_schedule']['factor'],
                patience=TRAINING_CONFIG['learning_rate_schedule']['patience'],
                min_lr=TRAINING_CONFIG['learning_rate_schedule']['min_lr'],
                verbose=1
            )
            callbacks.append(lr_scheduler)
        
        # ì‚¬ìš©ì ì •ì˜ ë¡œê¹… ì½œë°±
        class TrainingLogger(keras.callbacks.Callback):
            def __init__(self, trainer):
                super().__init__()
                self.trainer = trainer
                
            def on_epoch_end(self, epoch, logs=None):
                logs = logs or {}
                
                # ì—í¬í¬ë³„ ì„±ëŠ¥ ê¸°ë¡
                if 'epoch_logs' not in self.trainer.training_info:
                    self.trainer.training_info['epoch_logs'] = []
                    
                epoch_info = {
                    'epoch': epoch + 1,
                    'loss': logs.get('loss', 0),
                    'accuracy': logs.get('accuracy', 0),
                    'val_loss': logs.get('val_loss', 0),
                    'val_accuracy': logs.get('val_accuracy', 0),
                    'precision': logs.get('precision', 0),
                    'recall': logs.get('recall', 0),
                    'val_precision': logs.get('val_precision', 0),
                    'val_recall': logs.get('val_recall', 0)
                }
                
                self.trainer.training_info['epoch_logs'].append(epoch_info)
                
                # ì§„í–‰ ìƒí™© ì¶œë ¥
                print(f"ì—í¬í¬ {epoch + 1}/{TRAINING_CONFIG['epochs']} - "
                      f"ì •í™•ë„: {logs.get('accuracy', 0):.4f} - "
                      f"ê²€ì¦ ì •í™•ë„: {logs.get('val_accuracy', 0):.4f}")
        
        callbacks.append(TrainingLogger(self))
        
        return callbacks
    
    def train_model(self, X_train, X_val, y_train, y_val):
        """ëª¨ë¸ í›ˆë ¨"""
        print("\nğŸš€ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
        
        self.training_info['start_time'] = datetime.now().isoformat()
        
        # ëª¨ë¸ ìƒì„±
        model = self.create_model((X_train.shape[1],))
        
        # ì½œë°± ìƒì„±
        callbacks = self.create_callbacks()
        
        # í›ˆë ¨ ì‹¤í–‰
        history = model.fit(
            X_train, y_train,
            batch_size=TRAINING_CONFIG['batch_size'],
            epochs=TRAINING_CONFIG['epochs'],
            validation_data=(X_val, y_val),
            class_weight=self.class_weights,
            callbacks=callbacks,
            verbose=1
        )
        
        self.history = history
        self.training_info['end_time'] = datetime.now().isoformat()
        
        # í›ˆë ¨ ì‹œê°„ ê³„ì‚°
        start_time = datetime.fromisoformat(self.training_info['start_time'])
        end_time = datetime.fromisoformat(self.training_info['end_time'])
        training_duration = end_time - start_time
        
        self.training_info['training_duration'] = {
            'total_seconds': training_duration.total_seconds(),
            'formatted': str(training_duration)
        }
        
        print(f"\nâœ… í›ˆë ¨ ì™„ë£Œ! ì†Œìš” ì‹œê°„: {training_duration}")
        
        return history
    
    def evaluate_model(self, X_val, y_val_onehot, y_val):
        """ëª¨ë¸ í‰ê°€"""
        print("\nğŸ“Š ëª¨ë¸ í‰ê°€ ì¤‘...")
        
        # ê¸°ë³¸ í‰ê°€
        eval_results = self.model.evaluate(X_val, y_val_onehot, verbose=0)
        
        # í‰ê°€ ê²°ê³¼ ì €ì¥
        metrics = self.model.metrics_names
        evaluation = dict(zip(metrics, eval_results))
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        y_pred_proba = self.model.predict(X_val, verbose=0)
        y_pred = np.argmax(y_pred_proba, axis=1)
        
        # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ê³„ì‚°
        from sklearn.metrics import classification_report, confusion_matrix
        
        # ë¶„ë¥˜ ë¦¬í¬íŠ¸
        class_report = classification_report(
            y_val, y_pred, 
            target_names=ALL_CLASSES,
            output_dict=True
        )
        
        # í˜¼ë™ í–‰ë ¬
        conf_matrix = confusion_matrix(y_val, y_pred)
        
        # ê²°ê³¼ ì €ì¥
        self.training_info['performance'] = {
            'overall': evaluation,
            'classification_report': class_report,
            'confusion_matrix': conf_matrix.tolist()
        }
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“ˆ ìµœì¢… ì„±ëŠ¥:")
        print(f"  ğŸ“Š í‰ê°€ ë©”íŠ¸ë¦­: {list(evaluation.keys())}")
        
        # ì•ˆì „í•œ í‚¤ ì ‘ê·¼
        loss_value = evaluation.get('loss', evaluation.get('val_loss', 0))
        accuracy_value = evaluation.get('accuracy', evaluation.get('val_accuracy', 0))
        
        print(f"  - ì†ì‹¤: {loss_value:.4f}")
        print(f"  - ì •í™•ë„: {accuracy_value:.4f}")
        
        # ì „ì²´ ì •í™•ë„ë¥¼ ê³„ì‚° (ë§Œì•½ evaluationì— ì—†ë‹¤ë©´)
        if 'accuracy' not in evaluation and 'val_accuracy' not in evaluation:
            overall_accuracy = np.mean(y_pred == y_val)
            evaluation['accuracy'] = overall_accuracy
            print(f"  - ê³„ì‚°ëœ ì •í™•ë„: {overall_accuracy:.4f}")
        
        # ê°€ì¤‘ í‰ê· ì—ì„œ ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ ê°€ì ¸ì˜¤ê¸°
        try:
            weighted_avg = class_report.get('weighted avg', {})
            if isinstance(weighted_avg, dict):
                precision = evaluation.get('precision', weighted_avg.get('precision', 0))
                recall = evaluation.get('recall', weighted_avg.get('recall', 0))
            else:
                precision = evaluation.get('precision', 0)
                recall = evaluation.get('recall', 0)
        except:
            precision = evaluation.get('precision', 0)
            recall = evaluation.get('recall', 0)
        
        print(f"  - ì •ë°€ë„: {precision:.4f}")
        print(f"  - ì¬í˜„ìœ¨: {recall:.4f}")
        
        print(f"\nğŸ“Š í´ë˜ìŠ¤ë³„ ì„±ëŠ¥:")
        for class_name in ALL_CLASSES:
            try:
                if isinstance(class_report, dict) and class_name in class_report:
                    metrics = class_report[class_name]
                    if isinstance(metrics, dict):
                        print(f"  - {class_name}:")
                        print(f"    ì •ë°€ë„: {metrics.get('precision', 0):.4f}, "
                              f"ì¬í˜„ìœ¨: {metrics.get('recall', 0):.4f}, "
                              f"F1: {metrics.get('f1-score', 0):.4f}")
            except Exception as e:
                print(f"  - {class_name}: ë©”íŠ¸ë¦­ ê³„ì‚° ì˜¤ë¥˜ ({e})")
        
        return evaluation, class_report, conf_matrix
    
    def plot_training_history(self):
        """Training process visualization (English)"""
        if self.history is None:
            print("âš ï¸ No training history available.")
            return
        
        print("\nğŸ“Š Creating training progress visualization...")
        
        # Set matplotlib to use safe fonts
        plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial', 'sans-serif']
        plt.rcParams['axes.unicode_minus'] = False
        
        history = self.history.history
        epochs = range(1, len(history['loss']) + 1)
        
        # Plot configuration
        plt.style.use('default')
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('YAMNet + LSTM Training Progress', fontsize=16, fontweight='bold')
        
        # Loss graph
        axes[0, 0].plot(epochs, history['loss'], 'b-', label='Training Loss', linewidth=2)
        axes[0, 0].plot(epochs, history['val_loss'], 'r-', label='Validation Loss', linewidth=2)
        axes[0, 0].set_title('Model Loss', fontsize=14, fontweight='bold')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Loss')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # Accuracy graph
        axes[0, 1].plot(epochs, history['accuracy'], 'b-', label='Training Accuracy', linewidth=2)
        axes[0, 1].plot(epochs, history['val_accuracy'], 'r-', label='Validation Accuracy', linewidth=2)
        axes[0, 1].set_title('Model Accuracy', fontsize=14, fontweight='bold')
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].set_ylabel('Accuracy')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        # Precision graph
        if 'precision' in history:
            axes[1, 0].plot(epochs, history['precision'], 'b-', label='Training Precision', linewidth=2)
            axes[1, 0].plot(epochs, history['val_precision'], 'r-', label='Validation Precision', linewidth=2)
            axes[1, 0].set_title('Model Precision', fontsize=14, fontweight='bold')
            axes[1, 0].set_xlabel('Epoch')
            axes[1, 0].set_ylabel('Precision')
            axes[1, 0].legend()
            axes[1, 0].grid(True, alpha=0.3)
        
        # Recall graph
        if 'recall' in history:
            axes[1, 1].plot(epochs, history['recall'], 'b-', label='Training Recall', linewidth=2)
            axes[1, 1].plot(epochs, history['val_recall'], 'r-', label='Validation Recall', linewidth=2)
            axes[1, 1].set_title('Model Recall', fontsize=14, fontweight='bold')
            axes[1, 1].set_xlabel('Epoch')
            axes[1, 1].set_ylabel('Recall')
            axes[1, 1].legend()
            axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # Save graph
        plot_path = os.path.join(TRAINING_RESULTS_DIR, 'training_history.png')
        plt.savefig(plot_path, dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()
        
        print(f"ğŸ“Š Training progress graph saved: {plot_path}")
    
    def plot_confusion_matrix(self, conf_matrix):
        """Confusion matrix visualization (English)"""
        print("\nğŸ“Š Creating confusion matrix visualization...")
        
        # Set matplotlib to use a safe font
        plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial', 'sans-serif']
        plt.rcParams['axes.unicode_minus'] = False
        
        plt.figure(figsize=(12, 10))
        
        # Normalized confusion matrix
        conf_matrix_norm = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]
        
        # Get English class names
        from config import CLASS_NAMES_EN
        english_labels = [CLASS_NAMES_EN.get(cls, cls.title()) for cls in ALL_CLASSES]
        
        if HAS_SEABORN:
            # Using seaborn
            import seaborn as sns
            sns.heatmap(
                conf_matrix_norm, 
                annot=True, 
                fmt='.3f',
                cmap='Blues',
                xticklabels=english_labels,
                yticklabels=english_labels,
                cbar_kws={'label': 'Normalized Rate'},
                square=True,
                linewidths=0.5
            )
        else:
            # Using matplotlib only
            im = plt.imshow(conf_matrix_norm, interpolation='nearest', cmap='Blues')
            plt.colorbar(im, label='Normalized Rate')
            
            # Add text annotations
            for i in range(conf_matrix_norm.shape[0]):
                for j in range(conf_matrix_norm.shape[1]):
                    plt.text(j, i, f'{conf_matrix_norm[i, j]:.3f}',
                           ha="center", va="center", 
                           color="white" if conf_matrix_norm[i, j] > 0.5 else "black",
                           fontweight='bold')
            
            plt.xticks(range(len(ALL_CLASSES)), english_labels, rotation=45)
            plt.yticks(range(len(ALL_CLASSES)), english_labels, rotation=0)
        
        plt.title('Confusion Matrix - Normalized', fontsize=16, fontweight='bold', pad=20)
        plt.xlabel('Predicted Class', fontsize=12, fontweight='bold')
        plt.ylabel('True Class', fontsize=12, fontweight='bold')
        
        # Adjust layout
        plt.tight_layout()
        
        # Save with high quality
        cm_path = os.path.join(TRAINING_RESULTS_DIR, 'confusion_matrix.png')
        plt.savefig(cm_path, dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()
        
        print(f"ğŸ“Š Confusion matrix saved: {cm_path}")
    
    def save_model(self, model_name=None):
        """ëª¨ë¸ ì €ì¥"""
        if self.model is None:
            print("âš ï¸ ì €ì¥í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        if model_name is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            model_name = f"yamnet_lstm_model_{timestamp}.h5"
        else:
            # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ëª¨ë¸ëª…ì— í™•ì¥ìê°€ ì—†ìœ¼ë©´ .h5 ì¶”ê°€
            if not model_name.endswith(('.h5', '.keras')):
                model_name = f"{model_name}.h5"
        
        model_path = os.path.join(TRAINING_RESULTS_DIR, model_name)
        
        # ëª¨ë¸ ì €ì¥
        self.model.save(model_path)
        print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥: {model_path}")
        
        # models í´ë”ì—ë„ ë³µì‚¬
        try:
            import shutil
            from config import MODEL_SAVE_DIR
            os.makedirs(MODEL_SAVE_DIR, exist_ok=True)
            model_copy_path = os.path.join(MODEL_SAVE_DIR, os.path.basename(model_path))
            shutil.copy2(model_path, model_copy_path)
            print(f"ğŸ“‹ ëª¨ë¸ ë³µì‚¬: {model_copy_path}")
        except Exception as e:
            print(f"âš ï¸ ëª¨ë¸ ë³µì‚¬ ì‹¤íŒ¨: {e}")
        
        # í›ˆë ¨ ì •ë³´ ì €ì¥ (í™•ì¥ìì— ë”°ë¥¸ ì²˜ë¦¬)
        base_name = model_path
        if model_path.endswith('.h5'):
            base_name = model_path[:-3]  # .h5 ì œê±°
        elif model_path.endswith('.keras'):
            base_name = model_path[:-6]  # .keras ì œê±°
        
        info_path = f"{base_name}_info.json"
        with open(info_path, 'w', encoding='utf-8') as f:
            json.dump(self.training_info, f, indent=2, ensure_ascii=False)
        print(f"ğŸ“„ í›ˆë ¨ ì •ë³´ ì €ì¥: {info_path}")
        
        # í´ë˜ìŠ¤ ë§¤í•‘ ì €ì¥
        class_mapping_path = f"{base_name}_classes.npy"
        np.save(class_mapping_path, ALL_CLASSES)
        print(f"ğŸ·ï¸ í´ë˜ìŠ¤ ë§¤í•‘ ì €ì¥: {class_mapping_path}")
        
        # models í´ë”ì— ì¶”ê°€ íŒŒì¼ë“¤ë„ ë³µì‚¬
        try:
            import shutil
            from config import MODEL_SAVE_DIR
            if os.path.exists(info_path):
                info_copy_path = os.path.join(MODEL_SAVE_DIR, os.path.basename(info_path))
                shutil.copy2(info_path, info_copy_path)
                print(f"ğŸ“‹ í›ˆë ¨ ì •ë³´ ë³µì‚¬: {info_copy_path}")
            
            if os.path.exists(class_mapping_path):
                mapping_copy_path = os.path.join(MODEL_SAVE_DIR, os.path.basename(class_mapping_path))
                shutil.copy2(class_mapping_path, mapping_copy_path)
                print(f"ğŸ“‹ í´ë˜ìŠ¤ ë§¤í•‘ ë³µì‚¬: {mapping_copy_path}")
        except Exception as e:
            print(f"âš ï¸ ì¶”ê°€ íŒŒì¼ ë³µì‚¬ ì‹¤íŒ¨: {e}")
        
        return model_path, info_path, class_mapping_path
    
    def train_full_pipeline(self, data_path, dataset_info_path=None, model_name=None):
        """ì „ì²´ í›ˆë ¨ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        try:
            # 1. ë°ì´í„° ë¡œë“œ
            X, y = self.load_dataset(data_path, dataset_info_path)
            
            # 2. ë°ì´í„° ì „ì²˜ë¦¬
            X_train, X_val, y_train_onehot, y_val_onehot, y_train_raw, y_val_raw = self.prepare_data(X, y)
            
            # 3. ëª¨ë¸ í›ˆë ¨
            history = self.train_model(X_train, X_val, y_train_onehot, y_val_onehot)
            
            # 4. ëª¨ë¸ í‰ê°€
            evaluation, class_report, conf_matrix = self.evaluate_model(
                X_val, y_val_onehot, y_val_raw
            )
            
            # 5. ì‹œê°í™”
            self.plot_training_history()
            self.plot_confusion_matrix(conf_matrix)
            
            # 6. ëª¨ë¸ ì €ì¥
            model_paths = self.save_model(model_name)
            
            print(f"\nğŸ‰ ëª¨ë“  í›ˆë ¨ ê³¼ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            print(f"ğŸ“ ê²°ê³¼ í´ë”: {TRAINING_RESULTS_DIR}")
            
            return {
                'model_paths': model_paths,
                'evaluation': evaluation,
                'class_report': class_report,
                'confusion_matrix': conf_matrix,
                'training_info': self.training_info
            }
            
        except Exception as e:
            print(f"âŒ í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            return None

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ YAMNet + LSTM ëª¨ë¸ í›ˆë ¨ê¸°")
    print("=" * 60)
    
    # ì„¤ì • ê²€ì¦
    errors = validate_config()
    if errors:
        print("âŒ ì„¤ì • ì˜¤ë¥˜:")
        for error in errors:
            print(f"  - {error}")
        return
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    create_output_directories()
    
    # ë°ì´í„° ê²½ë¡œ í™•ì¸
    dataset_files = [f for f in os.listdir('.') if f.endswith('.npz')]
    
    if not dataset_files:
        print("âŒ ë°ì´í„°ì…‹ íŒŒì¼(.npz)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ ë¨¼ì € data_generator.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
        return
    
    # ê°€ì¥ ìµœê·¼ ë°ì´í„°ì…‹ ì‚¬ìš©
    latest_dataset = max(dataset_files, key=os.path.getmtime)
    dataset_info_file = latest_dataset.replace('.npz', '.json')
    
    print(f"ğŸ“‚ ì‚¬ìš©í•  ë°ì´í„°ì…‹: {latest_dataset}")
    
    if os.path.exists(dataset_info_file):
        print(f"ğŸ“„ ë°ì´í„°ì…‹ ì •ë³´: {dataset_info_file}")
    else:
        dataset_info_file = None
        print("âš ï¸ ë°ì´í„°ì…‹ ì •ë³´ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # ëª¨ë¸ ì´ë¦„ ì…ë ¥
    model_name = input(f"\nğŸ’¾ ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’: ìë™ìƒì„±): ").strip()
    if not model_name:
        model_name = None
    
    # í›ˆë ¨ ì‹œì‘
    trainer = ModelTrainer()
    results = trainer.train_full_pipeline(
        data_path=latest_dataset,
        dataset_info_path=dataset_info_file,
        model_name=model_name
    )
    
    if results:
        print(f"\nâœ… í›ˆë ¨ ì„±ê³µ!")
        # ì•ˆì „í•œ ì •í™•ë„ ì ‘ê·¼
        evaluation = results['evaluation']
        accuracy = evaluation.get('accuracy', evaluation.get('val_accuracy', 0))
        print(f"ğŸ¯ ìµœì¢… ì •í™•ë„: {accuracy:.4f}")
    else:
        print(f"\nâŒ í›ˆë ¨ ì‹¤íŒ¨")

if __name__ == "__main__":
    main()
